Search.setIndex({"alltitles": {"1. Clone the Repository": [[7, "clone-the-repository"]], "2. Set up a Python Virtual Environment": [[7, "set-up-a-python-virtual-environment"]], "3. Install Dependencies": [[7, "install-dependencies"]], "3.1 System Dependencies": [[7, "system-dependencies"]], "3.2 PyTorch": [[7, "pytorch"]], "3.3 CUDA": [[7, "cuda"]], "3.4 pip": [[7, "pip"]], "4. Build fairseq2n": [[7, "build-fairseq2n"]], "4.1 CPU-Only Builds": [[7, "cpu-only-builds"]], "4.2 CUDA Builds": [[7, "cuda-builds"]], "4.3 CUDA Architectures": [[7, "cuda-architectures"]], "5. Install fairseq2": [[7, "install-fairseq2"]], "5.1 Editable Install": [[7, "editable-install"]], "6. Optional Sanity Check": [[7, "optional-sanity-check"]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-book\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M0 1.75A.75.75 0 01.75 1h4.253c1.227 0 2.317.59 3 1.501A3.744 3.744 0 0111.006 1h4.245a.75.75 0 01.75.75v10.5a.75.75 0 01-.75.75h-4.507a2.25 2.25 0 00-1.591.659l-.622.621a.75.75 0 01-1.06 0l-.622-.621A2.25 2.25 0 005.258 13H.75a.75.75 0 01-.75-.75V1.75zm8.755 3a2.25 2.25 0 012.25-2.25H14.5v9h-3.757c-.71 0-1.4.201-1.992.572l.004-7.322zm-1.504 7.324l.004-5.073-.002-2.253A2.25 2.25 0 005.003 2.5H1.5v9h3.757a3.75 3.75 0 011.994.574z\"></path></svg> Bibliography": [[13, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-bug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.72.22a.75.75 0 011.06 0l1 .999a3.492 3.492 0 012.441 0l.999-1a.75.75 0 111.06 1.061l-.775.776c.616.63.995 1.493.995 2.444v.327c0 .1-.009.197-.025.292.408.14.764.392 1.029.722l1.968-.787a.75.75 0 01.556 1.392L13 7.258V9h2.25a.75.75 0 010 1.5H13v.5c0 .409-.049.806-.141 1.186l2.17.868a.75.75 0 01-.557 1.392l-2.184-.873A4.997 4.997 0 018 16a4.997 4.997 0 01-4.288-2.427l-2.183.873a.75.75 0 01-.558-1.392l2.17-.868A5.013 5.013 0 013 11v-.5H.75a.75.75 0 010-1.5H3V7.258L.971 6.446a.75.75 0 01.558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.684 1.684 0 01-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 010-1.06zM6.173 5h3.654A.173.173 0 0010 4.827V4.5a2 2 0 10-4 0v.327c0 .096.077.173.173.173zM5.25 6.5a.75.75 0 00-.75.75V11a3.5 3.5 0 107 0V7.25a.75.75 0 00-.75-.75h-5.5z\"></path></svg> Debugging with PuDB": [[10, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-container\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.41.24l4.711 2.774A1.767 1.767 0 0116 4.54v5.01a1.77 1.77 0 01-.88 1.53l-7.753 4.521-.002.001a1.767 1.767 0 01-1.774 0H5.59L.873 12.85A1.762 1.762 0 010 11.327V6.292c0-.304.078-.598.22-.855l.004-.005.01-.019c.15-.262.369-.486.64-.643L8.641.239a1.75 1.75 0 011.765 0l.002.001zM9.397 1.534a.25.25 0 01.252 0l4.115 2.422-7.152 4.148a.267.267 0 01-.269 0L2.227 5.716l7.17-4.182zM7.365 9.402L8.73 8.61v4.46l-1.5.875V9.473a1.77 1.77 0 00.136-.071zm2.864 2.794V7.741l1.521-.882v4.45l-1.521.887zm3.021-1.762l1.115-.65h.002a.268.268 0 00.133-.232V5.264l-1.25.725v4.445zm-11.621 1.12l4.1 2.393V9.474a1.77 1.77 0 01-.138-.072L1.5 7.029v4.298c0 .095.05.181.129.227z\"></path></svg> Assets": [[0, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-download\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.47 10.78a.75.75 0 001.06 0l3.75-3.75a.75.75 0 00-1.06-1.06L8.75 8.44V1.75a.75.75 0 00-1.5 0v6.69L4.78 5.97a.75.75 0 00-1.06 1.06l3.75 3.75zM3.75 13a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5z\"></path></svg> Installation": [[6, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-file-binary\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0114.25 15h-9a.75.75 0 010-1.5h9a.25.25 0 00.25-.25V6h-2.75A1.75 1.75 0 0110 4.25V1.5H5.75a.25.25 0 00-.25.25v2a.75.75 0 01-1.5 0v-2zm7.5-.188V4.25c0 .138.112.25.25.25h2.688a.252.252 0 00-.011-.013l-2.914-2.914a.272.272 0 00-.013-.011zM0 7.75C0 6.784.784 6 1.75 6h1.5C4.216 6 5 6.784 5 7.75v2.5A1.75 1.75 0 013.25 12h-1.5A1.75 1.75 0 010 10.25v-2.5zm1.75-.25a.25.25 0 00-.25.25v2.5c0 .138.112.25.25.25h1.5a.25.25 0 00.25-.25v-2.5a.25.25 0 00-.25-.25h-1.5zm5-1.5a.75.75 0 000 1.5h.75v3h-.75a.75.75 0 000 1.5h3a.75.75 0 000-1.5H9V6.75A.75.75 0 008.25 6h-1.5z\"></path></svg> Installing from Source": [[7, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-heart\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z\"></path></svg> Contributing to fairseq2": [[14, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-infinity\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.5 6c-1.086 0-2 .914-2 2 0 1.086.914 2 2 2 .525 0 1.122-.244 1.825-.727.51-.35 1.025-.79 1.561-1.273-.536-.483-1.052-.922-1.56-1.273C4.621 6.244 4.025 6 3.5 6zm4.5.984c-.59-.533-1.204-1.066-1.825-1.493-.797-.548-1.7-.991-2.675-.991C1.586 4.5 0 6.086 0 8s1.586 3.5 3.5 3.5c.975 0 1.878-.444 2.675-.991.621-.427 1.235-.96 1.825-1.493.59.533 1.204 1.066 1.825 1.493.797.547 1.7.991 2.675.991 1.914 0 3.5-1.586 3.5-3.5s-1.586-3.5-3.5-3.5c-.975 0-1.878.443-2.675.991-.621.427-1.235.96-1.825 1.493zM9.114 8c.536.483 1.052.922 1.56 1.273.704.483 1.3.727 1.826.727 1.086 0 2-.914 2-2 0-1.086-.914-2-2-2-.525 0-1.122.244-1.825.727-.51.35-1.025.79-1.561 1.273z\"></path></svg> Design Philosophy": [[2, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-lock\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 4v2h-.25A1.75 1.75 0 002 7.75v5.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 13.25v-5.5A1.75 1.75 0 0012.25 6H12V4a4 4 0 10-8 0zm6.5 2V4a2.5 2.5 0 00-5 0v2h5zM12 7.5h.25a.25.25 0 01.25.25v5.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-5.5a.25.25 0 01.25-.25H12z\"></path></svg> UV Setup": [[8, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-plug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.276 3.09a.25.25 0 01.192-.09h.782a.25.25 0 01.25.25v8.5a.25.25 0 01-.25.25h-.782a.25.25 0 01-.192-.09l-.95-1.14a.75.75 0 00-.483-.264l-3.124-.39a.25.25 0 01-.219-.249V5.133a.25.25 0 01.219-.248l3.124-.39a.75.75 0 00.483-.265l.95-1.14zM4 8v1.867a1.75 1.75 0 001.533 1.737l2.83.354.761.912c.332.4.825.63 1.344.63h.782A1.75 1.75 0 0013 11.75V11h2.25a.75.75 0 000-1.5H13v-4h2.25a.75.75 0 000-1.5H13v-.75a1.75 1.75 0 00-1.75-1.75h-.782c-.519 0-1.012.23-1.344.63l-.76.913-2.831.353A1.75 1.75 0 004 5.133V6.5H2.5A2.5 2.5 0 000 9v5.25a.75.75 0 001.5 0V9a1 1 0 011-1H4z\"></path></svg> Runtime Extension": [[3, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-report\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M1.75 1.5a.25.25 0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 01.75.75v2.19l2.72-2.72a.75.75 0 01.53-.22h6.5a.25.25 0 00.25-.25v-9.5a.25.25 0 00-.25-.25H1.75zM0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0114.25 13H8.06l-2.573 2.573A1.457 1.457 0 013 14.543V13H1.75A1.75 1.75 0 010 11.25v-9.5zM9 9a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z\"></path></svg> What\u2019s New in v0.5": [[12, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-rocket\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z\"></path></svg> Building Recipes": [[1, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-ruby\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.637 2.291A.75.75 0 014.23 2h7.54a.75.75 0 01.593.291l3.48 4.5a.75.75 0 01-.072.999l-7.25 7a.75.75 0 01-1.042 0l-7.25-7a.75.75 0 01-.072-.999l3.48-4.5zM4.598 3.5L1.754 7.177 8 13.207l6.246-6.03L11.402 3.5H4.598z\"></path></svg> Add Your Own Model": [[9, null]], "A Detailed Project Setup": [[8, "a-detailed-project-setup"]], "API Reference": [[11, null]], "Adding a Custom Dataset": [[0, "adding-a-custom-dataset"]], "Adding a Custom Model": [[0, "adding-a-custom-model"]], "Advanced Configuration": [[0, "advanced-configuration"]], "Advanced Dataset Opening": [[20, "advanced-dataset-opening"]], "Advanced Installation": [[6, null]], "Advanced Usage": [[26, "advanced-usage"]], "Architecture Comparison": [[28, "architecture-comparison"]], "Architecture Configuration Error": [[9, "architecture-configuration-error"]], "Asset Card Reference": [[0, "asset-card-reference"]], "Asset Cards: YAML Configuration Files": [[0, "asset-cards-yaml-configuration-files"]], "Asset Source Options": [[9, "asset-source-options"]], "Asset Store Configuration": [[0, "asset-store-configuration"]], "Assets": [[4, null]], "Audio Processing": [[17, "audio-processing"]], "Available Models": [[28, "available-models"]], "Base Assets and Inheritance": [[0, "base-assets-and-inheritance"]], "Base Classes": [[18, "base-classes"]], "Basic Model Usage": [[28, "basic-model-usage"]], "Basic Usage": [[2, "basic-usage"], [3, "basic-usage"]], "Basics": [[11, null]], "Best Practices": [[0, "best-practices"]], "CLI Usage": [[0, "cli-usage"]], "Chat Template Support": [[27, "chat-template-support"]], "Check List for Pull Requests": [[14, "check-list-for-pull-requests"]], "Checkpoint Inspection": [[26, "checkpoint-inspection"]], "Classes": [[22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"]], "Common Asset Fields": [[0, "common-asset-fields"]], "Common Exceptions": [[26, "common-exceptions"]], "Common Model Parameters": [[9, "common-model-parameters"]], "Common Workflows": [[8, "common-workflows"]], "Complete Examples": [[27, "complete-examples"], [28, "complete-examples"]], "Concepts": [[11, null]], "Configuration": [[8, "configuration"]], "Configuration Overrides": [[0, "configuration-overrides"]], "Configuration Validation Errors": [[9, "configuration-validation-errors"]], "Constants": [[28, "constants"]], "Contributor License Agreement": [[14, "contributor-license-agreement"]], "Core Architecture": [[9, "core-architecture"]], "Core Classes": [[19, "core-classes"], [21, "core-classes"], [26, "core-classes"]], "Core Components": [[2, "core-components"]], "Creating BatchLayout": [[30, "creating-batchlayout"]], "Creating Custom Assets": [[0, "creating-custom-assets"]], "Creating Custom Datasets": [[20, "creating-custom-datasets"]], "Custom Architecture": [[28, "custom-architecture"]], "Custom Model Loading": [[26, "custom-model-loading"]], "Data Pipeline Components": [[17, "data-pipeline-components"]], "Dataset Registration and Asset Cards": [[20, "dataset-registration-and-asset-cards"]], "DatasetFamilyNotKnownError": [[21, "datasetfamilynotknownerror"]], "DatasetHub": [[21, "datasethub"]], "DatasetHubAccessor": [[21, "datasethubaccessor"]], "DatasetNotKnownError": [[21, "datasetnotknownerror"]], "Dependency Injection": [[2, "dependency-injection"]], "Dependency Inversion": [[2, "dependency-inversion"]], "Documenting Your Work": [[14, "documenting-your-work"]], "Download/Loading Errors": [[9, "download-loading-errors"]], "Enums": [[23, "enums"]], "Environment-Specific Assets": [[0, "environment-specific-assets"]], "Error Handling": [[3, "error-handling"], [26, "error-handling"]], "Example Error Handling": [[26, "example-error-handling"]], "Example Extension Setup": [[3, "example-extension-setup"]], "Example: Complete Implementation": [[9, "example-complete-implementation"]], "Exceptions": [[19, "exceptions"], [21, "exceptions"], [22, "exceptions"], [23, "exceptions"], [24, "exceptions"], [25, "exceptions"]], "Exiting the debugger": [[10, "exiting-the-debugger"]], "Factory Functions": [[23, "factory-functions"]], "Formatting Your Work": [[14, "formatting-your-work"]], "Functions": [[19, "functions"], [22, "functions"], [24, "functions"], [25, "functions"], [38, "functions"], [39, "functions"]], "Getting Started": [[11, null]], "Global Functions": [[26, "global-functions"]], "Guides": [[11, null]], "HTTP URLs": [[9, "http-urls"]], "How is Gang different from PyTorch DeviceMesh?": [[5, "how-is-gang-different-from-pytorch-devicemesh"]], "How is Gang different from PyTorch ProcessGroup?": [[5, "how-is-gang-different-from-pytorch-processgroup"]], "How is Gang used in fairseq2?": [[5, "how-is-gang-used-in-fairseq2"]], "How to create Gangs for data and model parallelism?": [[5, "how-to-create-gangs-for-data-and-model-parallelism"]], "How to create a Gang?": [[5, "how-to-create-a-gang"]], "How to use Gangs in deeply nested functions?": [[5, "how-to-use-gangs-in-deeply-nested-functions"]], "Hugging Face Hub (Recommended)": [[9, "hugging-face-hub-recommended"]], "Indices and tables": [[11, "indices-and-tables"]], "Initializing the socket for remote debugger": [[10, "initializing-the-socket-for-remote-debugger"]], "Integration with Neural Network Layers": [[30, "integration-with-neural-network-layers"]], "Interface/Implementation Convention": [[2, "interface-implementation-convention"]], "Interfaces": [[22, "interfaces"], [24, "interfaces"]], "Interoperability": [[28, "interoperability"]], "Issues": [[14, "issues"]], "Iterating Over Model Cards": [[26, "iterating-over-model-cards"]], "Key Concepts": [[8, "key-concepts"]], "Key Features": [[20, "key-features"]], "LLaMA Models": [[26, "llama-models"]], "LLaMAConfig": [[27, "llamaconfig"]], "LLaMATokenizerConfig": [[27, "llamatokenizerconfig"]], "Latest News": [[11, null]], "License": [[14, "license"]], "Linting Your Work": [[14, "linting-your-work"]], "Listing Available Tokenizers": [[18, "listing-available-tokenizers"]], "Loading a Specific Model\u2019s Tokenizer": [[18, "loading-a-specific-model-s-tokenizer"]], "Loading a Tokenizer": [[18, "loading-a-tokenizer"]], "Loading from Custom Checkpoint": [[28, "loading-from-custom-checkpoint"]], "Local Files": [[9, "local-files"]], "Masking Utilities": [[37, "masking-utilities"]], "Mistral Models": [[26, "mistral-models"]], "Model Configuration": [[27, "model-configuration"], [28, "model-configuration"]], "Model Factory": [[28, "model-factory"]], "Model Not Found Error": [[9, "model-not-found-error"]], "ModelHub": [[26, "modelhub"]], "ModelHubAccessor": [[26, "modelhubaccessor"]], "Other": [[11, null]], "Overview": [[1, "overview"], [3, "overview"], [8, "overview"], [9, "overview"]], "Performance Considerations": [[30, "performance-considerations"]], "Placing the debugger breakpoint in the code": [[10, "placing-the-debugger-breakpoint-in-the-code"]], "Prerequisites": [[8, "prerequisites"]], "Programmatic Asset Registration": [[0, "programmatic-asset-registration"]], "QWEN_FAMILY": [[28, "qwen-family"]], "Quick Install": [[6, "quick-install"]], "Quick Reference": [[19, "quick-reference"]], "Quick Start": [[8, "quick-start"], [18, "quick-start"], [26, "quick-start"], [27, "quick-start"], [28, "quick-start"]], "Qwen Models": [[26, "qwen-models"]], "QwenConfig": [[28, "qwenconfig"]], "QwenFactory": [[28, "qwenfactory"]], "QwenTokenizer": [[28, "qwentokenizer"]], "QwenTokenizerConfig": [[28, "qwentokenizerconfig"]], "Recipe Execution Flow": [[2, "recipe-execution-flow"]], "Running Your Recipe": [[1, "running-your-recipe"]], "Running fairseq2 with debugger": [[10, "running-fairseq2-with-debugger"]], "See Also": [[0, "see-also"], [1, "see-also"], [2, "see-also"], [3, "see-also"], [17, "see-also"], [19, "see-also"], [21, "see-also"], [26, "see-also"], [27, "see-also"], [28, "see-also"], [29, "see-also"]], "Sequence Information": [[30, "sequence-information"]], "Setting up Development Environment": [[14, "setting-up-development-environment"]], "Sharding": [[28, "sharding"]], "Special Tokens": [[27, "special-tokens"]], "Step 0: Setup the Entry Point": [[1, "step-0-setup-the-entry-point"]], "Step 1: Add Model Architecture Configuration": [[9, "step-1-add-model-architecture-configuration"]], "Step 1: Define Your Configuration": [[1, "step-1-define-your-configuration"]], "Step 2: Create Asset Card": [[9, "step-2-create-asset-card"]], "Step 2: Implement Your Dataset": [[1, "step-2-implement-your-dataset"]], "Step 3: Create Your Recipe Class": [[1, "step-3-create-your-recipe-class"]], "Step 3: Verify the Integration": [[9, "step-3-verify-the-integration"]], "Step-by-Step Guide: Adding a Model to Existing Family": [[9, "step-by-step-guide-adding-a-model-to-existing-family"]], "Structured Data": [[17, "structured-data"]], "Supported PyTorch Versions (macOS Apple Silicon)": [[6, "id2"]], "Supported PyTorch Versions and CUDA Variants (Linux)": [[6, "id1"]], "Supported Variants": [[6, "supported-variants"]], "Testing Your Work": [[14, "testing-your-work"]], "Text Processing": [[17, "text-processing"]], "The Asset Store System": [[0, "the-asset-store-system"]], "Tips & Best Practices": [[8, "tips-best-practices"]], "Tokenizer": [[27, "tokenizer"], [28, "tokenizer"]], "Tokenizer Configuration": [[27, "tokenizer-configuration"]], "Tokenizer Modes": [[27, "tokenizer-modes"]], "TokenizerFamilyNotKnownError": [[19, "tokenizerfamilynotknownerror"]], "TokenizerHub": [[19, "tokenizerhub"]], "TokenizerHubAccessor": [[19, "tokenizerhubaccessor"]], "TokenizerNotKnownError": [[19, "tokenizernotknownerror"]], "Torch.compile Integration": [[30, "torch-compile-integration"]], "Training & Architecture Details": [[9, "training-architecture-details"]], "Troubleshooting": [[0, "troubleshooting"], [8, "troubleshooting"], [9, "troubleshooting"]], "Understanding Model Families": [[9, "understanding-model-families"]], "Understanding the Asset System": [[0, "understanding-the-asset-system"]], "Using HuggingFace Tokenizer": [[27, "using-huggingface-tokenizer"]], "Using Tiktoken Implementation": [[27, "using-tiktoken-implementation"]], "Using TokenizerHub": [[18, "using-tokenizerhub"]], "Utilities": [[23, "utilities"]], "Vocabulary & Sequence": [[9, "vocabulary-sequence"]], "Welcome to fairseq2 Documentation": [[11, null]], "What is a Gang?": [[5, null]], "What\u2019s Next": [[12, "what-s-next"]], "Windows": [[6, "windows"]], "Working with Model Families": [[26, "working-with-model-families"]], "Working with Model Hubs": [[9, "working-with-model-hubs"]], "Working with Position Indices and Masks": [[30, "working-with-position-indices-and-masks"]], "convert_qwen_state_dict": [[28, "convert-qwen-state-dict"]], "create_qwen_model": [[28, "create-qwen-model"]], "export_qwen": [[28, "export-qwen"]], "fairseq2.assets": [[15, null]], "fairseq2.checkpoint": [[16, null]], "fairseq2.data": [[17, null]], "fairseq2.data.tokenizers": [[18, null]], "fairseq2.data.tokenizers.hub": [[19, null]], "fairseq2.datasets": [[20, null]], "fairseq2.datasets.hub": [[21, null]], "fairseq2.device": [[22, null]], "fairseq2.gang": [[23, null]], "fairseq2.logging": [[41, null]], "fairseq2.metrics": [[42, null]], "fairseq2.model_checkpoint": [[24, null]], "fairseq2.models": [[25, null]], "fairseq2.models.hub": [[26, null]], "fairseq2.models.llama": [[27, null]], "fairseq2.models.qwen": [[28, null]], "fairseq2.nn": [[29, null]], "fairseq2.nn.batch_layout": [[30, null]], "fairseq2.nn.embedding": [[31, null]], "fairseq2.nn.incremental_state": [[32, null]], "fairseq2.nn.normalization": [[33, null]], "fairseq2.nn.position_encoder": [[34, null]], "fairseq2.nn.projection": [[35, null]], "fairseq2.nn.residual": [[36, null]], "fairseq2.nn.utils": [[37, null]], "fairseq2.optim": [[43, null]], "fairseq2.recipe": [[44, null]], "fairseq2.recipe.composition": [[38, null]], "fairseq2.recipe.optim": [[39, null]], "fairseq2.utils.validation": [[40, null]], "get_qwen_shard_specs": [[28, "get-qwen-shard-specs"]], "get_qwen_tokenizer_hub": [[28, "get-qwen-tokenizer-hub"]], "load_model": [[26, "load-model"]], "load_tokenizer": [[19, "load-tokenizer"]], "\u2699\ufe0f Advanced Model Sharding": [[12, "advanced-model-sharding"]], "\u26a1 Performance & Memory Optimizations": [[12, "performance-memory-optimizations"]], "\ud83c\udfaf Migration Guide": [[12, "migration-guide"]], "\ud83d\udcbe Advanced Checkpoint Management": [[12, "advanced-checkpoint-management"]], "\ud83d\udcc8 Metrics & Monitoring": [[12, "metrics-monitoring"]], "\ud83d\udcca Data Processing & Batching": [[12, "data-processing-batching"]], "\ud83d\udd17 Hugging Face Integration": [[12, "hugging-face-integration"]], "\ud83d\udd27 Architecture & Maintainability": [[12, "architecture-maintainability"]], "\ud83d\ude80 Recipe Authoring & User Experience": [[12, "recipe-authoring-user-experience"]], "\ud83e\udd16 New Model Support": [[12, "new-model-support"]]}, "docnames": ["basics/assets", "basics/building_recipes", "basics/design_philosophy", "basics/runtime_extension", "concepts/assets", "concepts/gang", "getting_started/installation/index", "getting_started/installation/installation_from_source", "getting_started/installation/setup_with_uv", "guides/add_model", "guides/pudb", "index", "news/whats_new_v0_5", "other/bibliography", "other/contributing", "reference/assets", "reference/checkpoint", "reference/fairseq2.data", "reference/fairseq2.data.tokenizers", "reference/fairseq2.data.tokenizers.hub", "reference/fairseq2.datasets", "reference/fairseq2.datasets.hub", "reference/fairseq2.device", "reference/fairseq2.gang", "reference/fairseq2.model_checkpoint", "reference/fairseq2.models", "reference/fairseq2.models.hub", "reference/fairseq2.models.llama", "reference/fairseq2.models.qwen", "reference/fairseq2.nn", "reference/fairseq2.nn.batch_layout", "reference/fairseq2.nn.embedding", "reference/fairseq2.nn.incremental_state", "reference/fairseq2.nn.normalization", "reference/fairseq2.nn.position_encoder", "reference/fairseq2.nn.projection", "reference/fairseq2.nn.residual", "reference/fairseq2.nn.utils", "reference/fairseq2.recipe.composition", "reference/fairseq2.recipe.optim", "reference/fairseq2.utils.validation", "reference/logging", "reference/metrics", "reference/optim", "reference/recipe"], "envversion": {"nbsphinx": 4, "sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["basics/assets.rst", "basics/building_recipes.rst", "basics/design_philosophy.rst", "basics/runtime_extension.rst", "concepts/assets.rst", "concepts/gang.rst", "getting_started/installation/index.rst", "getting_started/installation/installation_from_source.rst", "getting_started/installation/setup_with_uv.rst", "guides/add_model.rst", "guides/pudb.rst", "index.rst", "news/whats_new_v0_5.rst", "other/bibliography.rst", "other/contributing.rst", "reference/assets.rst", "reference/checkpoint.rst", "reference/fairseq2.data.rst", "reference/fairseq2.data.tokenizers.rst", "reference/fairseq2.data.tokenizers.hub.rst", "reference/fairseq2.datasets.rst", "reference/fairseq2.datasets.hub.rst", "reference/fairseq2.device.rst", "reference/fairseq2.gang.rst", "reference/fairseq2.model_checkpoint.rst", "reference/fairseq2.models.rst", "reference/fairseq2.models.hub.rst", "reference/fairseq2.models.llama.rst", "reference/fairseq2.models.qwen.rst", "reference/fairseq2.nn.rst", "reference/fairseq2.nn.batch_layout.rst", "reference/fairseq2.nn.embedding.rst", "reference/fairseq2.nn.incremental_state.rst", "reference/fairseq2.nn.normalization.rst", "reference/fairseq2.nn.position_encoder.rst", "reference/fairseq2.nn.projection.rst", "reference/fairseq2.nn.residual.rst", "reference/fairseq2.nn.utils.rst", "reference/fairseq2.recipe.composition.rst", "reference/fairseq2.recipe.optim.rst", "reference/fairseq2.utils.validation.rst", "reference/logging.rst", "reference/metrics.rst", "reference/optim.rst", "reference/recipe.rst"], "indexentries": {"add_error() (fairseq2.utils.validation.validationresult method)": [[40, "fairseq2.utils.validation.ValidationResult.add_error", false]], "add_sub_result() (fairseq2.utils.validation.validationresult method)": [[40, "fairseq2.utils.validation.ValidationResult.add_sub_result", false]], "additiveresidualconnect (class in fairseq2.nn)": [[36, "fairseq2.nn.AdditiveResidualConnect", false]], "all_gather() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.all_gather", false]], "all_gather() (fairseq2.gang.gang method)": [[23, "fairseq2.gang.Gang.all_gather", false]], "all_gather() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.all_gather", false]], "all_gather_to_list() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.all_gather_to_list", false]], "all_gather_to_list() (fairseq2.gang.gang method)": [[23, "fairseq2.gang.Gang.all_gather_to_list", false]], "all_gather_to_list() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.all_gather_to_list", false]], "all_reduce() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.all_reduce", false]], "all_reduce() (fairseq2.gang.gang method)": [[23, "fairseq2.gang.Gang.all_reduce", false]], "all_reduce() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.all_reduce", false]], "all_sum() (in module fairseq2.gang)": [[23, "fairseq2.gang.all_sum", false]], "apply_mask() (in module fairseq2.nn.utils.mask)": [[37, "fairseq2.nn.utils.mask.apply_mask", false]], "as_process_group() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.as_process_group", false]], "as_process_group() (fairseq2.gang.gang method)": [[23, "fairseq2.gang.Gang.as_process_group", false]], "as_process_group() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.as_process_group", false]], "barrier() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.barrier", false]], "barrier() (fairseq2.gang.gang method)": [[23, "fairseq2.gang.Gang.barrier", false]], "barrier() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.barrier", false]], "basicmodelcheckpointloader (class in fairseq2.model_checkpoint)": [[24, "fairseq2.model_checkpoint.BasicModelCheckpointLoader", false]], "batchlayout (class in fairseq2.nn)": [[30, "fairseq2.nn.BatchLayout", false]], "boh_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.boh_idx", false]], "bos_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.bos_idx", false]], "broadcast() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.broadcast", false]], "broadcast() (fairseq2.gang.gang method)": [[23, "fairseq2.gang.Gang.broadcast", false]], "broadcast() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.broadcast", false]], "broadcast_flag() (in module fairseq2.gang)": [[23, "fairseq2.gang.broadcast_flag", false]], "broadcast_objects() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.broadcast_objects", false]], "broadcast_objects() (fairseq2.gang.gang method)": [[23, "fairseq2.gang.Gang.broadcast_objects", false]], "broadcast_objects() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.broadcast_objects", false]], "capacity_bytes() (fairseq2.nn.incrementalstate method)": [[32, "fairseq2.nn.IncrementalState.capacity_bytes", false]], "capacity_bytes() (fairseq2.nn.incrementalstatebag method)": [[32, "fairseq2.nn.IncrementalStateBag.capacity_bytes", false]], "capacity_increment (fairseq2.nn.incrementalstatebag property)": [[32, "fairseq2.nn.IncrementalStateBag.capacity_increment", false]], "close() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.close", false]], "close() (fairseq2.gang.gangs method)": [[23, "fairseq2.gang.Gangs.close", false]], "close() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.close", false]], "compiled_max_seq_len (fairseq2.nn.batchlayout attribute)": [[30, "fairseq2.nn.BatchLayout.compiled_max_seq_len", false]], "compute_row_mask() (in module fairseq2.nn.utils.mask)": [[37, "fairseq2.nn.utils.mask.compute_row_mask", false]], "convert_qwen_state_dict() (in module fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.convert_qwen_state_dict", false]], "create_decoder() (fairseq2.data.tokenizers.tokenizer method)": [[18, "fairseq2.data.tokenizers.Tokenizer.create_decoder", false]], "create_decoder() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_decoder", false]], "create_decoder() (fairseq2.models.qwen.qwentokenizer method)": [[28, "fairseq2.models.qwen.QwenTokenizer.create_decoder", false]], "create_decoder_frontend() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_decoder_frontend", false]], "create_decoder_layer() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_decoder_layer", false]], "create_default_process_group() (fairseq2.gang.processgroupgang class method)": [[23, "fairseq2.gang.ProcessGroupGang.create_default_process_group", false]], "create_embedding() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_embedding", false]], "create_encoder() (fairseq2.data.tokenizers.tokenizer method)": [[18, "fairseq2.data.tokenizers.Tokenizer.create_encoder", false]], "create_encoder() (fairseq2.models.qwen.qwentokenizer method)": [[28, "fairseq2.models.qwen.QwenTokenizer.create_encoder", false]], "create_fake_gangs() (in module fairseq2.gang)": [[23, "fairseq2.gang.create_fake_gangs", false]], "create_ffn() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_ffn", false]], "create_final_projection() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_final_projection", false]], "create_fsdp_gangs() (in module fairseq2.gang)": [[23, "fairseq2.gang.create_fsdp_gangs", false]], "create_gang() (fairseq2.gang.fakegang method)": [[23, "fairseq2.gang.FakeGang.create_gang", false]], "create_gang() (fairseq2.gang.gang method)": [[23, "fairseq2.gang.Gang.create_gang", false]], "create_gang() (fairseq2.gang.processgroupgang method)": [[23, "fairseq2.gang.ProcessGroupGang.create_gang", false]], "create_layer_norm() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_layer_norm", false]], "create_model() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_model", false]], "create_new_model() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.create_new_model", false]], "create_new_model() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.create_new_model", false]], "create_parallel_gangs() (in module fairseq2.gang)": [[23, "fairseq2.gang.create_parallel_gangs", false]], "create_position_encoder() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_position_encoder", false]], "create_qwen_model() (in module fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.create_qwen_model", false]], "create_raw_encoder() (fairseq2.data.tokenizers.tokenizer method)": [[18, "fairseq2.data.tokenizers.Tokenizer.create_raw_encoder", false]], "create_raw_encoder() (fairseq2.models.qwen.qwentokenizer method)": [[28, "fairseq2.models.qwen.QwenTokenizer.create_raw_encoder", false]], "create_self_attention() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.create_self_attention", false]], "cudacontext (class in fairseq2.device)": [[22, "fairseq2.device.CudaContext", false]], "datasetfamilynotknownerror": [[21, "fairseq2.datasets.hub.DatasetFamilyNotKnownError", false]], "datasethub (class in fairseq2.datasets.hub)": [[21, "fairseq2.datasets.hub.DatasetHub", false]], "datasethubaccessor (class in fairseq2.datasets.hub)": [[21, "fairseq2.datasets.hub.DatasetHubAccessor", false]], "datasetnotknownerror": [[21, "fairseq2.datasets.hub.DatasetNotKnownError", false]], "decode_from_tokens() (fairseq2.data.tokenizers.tokendecoder method)": [[18, "fairseq2.data.tokenizers.TokenDecoder.decode_from_tokens", false]], "delegatingmodelcheckpointloader (class in fairseq2.model_checkpoint)": [[24, "fairseq2.model_checkpoint.DelegatingModelCheckpointLoader", false]], "device (fairseq2.gang.fakegang property)": [[23, "fairseq2.gang.FakeGang.device", false]], "device (fairseq2.gang.gang property)": [[23, "fairseq2.gang.Gang.device", false]], "device (fairseq2.gang.processgroupgang property)": [[23, "fairseq2.gang.ProcessGroupGang.device", false]], "device_count() (fairseq2.device.cudacontext method)": [[22, "fairseq2.device.CudaContext.device_count", false]], "device_count() (fairseq2.device.standardcudacontext method)": [[22, "fairseq2.device.StandardCudaContext.device_count", false]], "dp (fairseq2.gang.gangs attribute)": [[23, "fairseq2.gang.Gangs.dp", false]], "dropout_p (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.dropout_p", false]], "dropout_p (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.dropout_p", false]], "embedding (class in fairseq2.nn)": [[31, "fairseq2.nn.Embedding", false]], "encode_as_tokens() (fairseq2.data.tokenizers.tokenencoder method)": [[18, "fairseq2.data.tokenizers.TokenEncoder.encode_as_tokens", false]], "eoh_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.eoh_idx", false]], "eos_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.eos_idx", false]], "errors (fairseq2.utils.validation.validationresult property)": [[40, "fairseq2.utils.validation.ValidationResult.errors", false]], "export_qwen() (in module fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.export_qwen", false]], "extra_repr() (fairseq2.nn.rmsnorm method)": [[33, "fairseq2.nn.RMSNorm.extra_repr", false]], "extra_repr() (fairseq2.nn.standardlayernorm method)": [[33, "fairseq2.nn.StandardLayerNorm.extra_repr", false]], "fairseq2": [[29, "module-fairseq2", false]], "fairseq2.assets": [[15, "module-fairseq2.assets", false]], "fairseq2.device": [[22, "module-fairseq2.device", false]], "fairseq2.gang": [[23, "module-fairseq2.gang", false]], "fairseq2.model_checkpoint": [[24, "module-fairseq2.model_checkpoint", false]], "fairseq2.models": [[25, "module-fairseq2.models", false]], "fairseq2.recipe.composition": [[38, "module-fairseq2.recipe.composition", false]], "fairseq2.recipe.optim": [[39, "module-fairseq2.recipe.optim", false]], "fairseq2.utils.validation": [[40, "module-fairseq2.utils.validation", false]], "fakegang (class in fairseq2.gang)": [[23, "fairseq2.gang.FakeGang", false]], "ffn_inner_dim (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim", false]], "ffn_inner_dim (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.ffn_inner_dim", false]], "ffn_inner_dim_multiple_of (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_multiple_of", false]], "ffn_inner_dim_multiplier (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_multiplier", false]], "ffn_inner_dim_scale (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_scale", false]], "forward() (fairseq2.nn.additiveresidualconnect method)": [[36, "fairseq2.nn.AdditiveResidualConnect.forward", false]], "forward() (fairseq2.nn.embedding method)": [[31, "fairseq2.nn.Embedding.forward", false]], "forward() (fairseq2.nn.layernorm method)": [[33, "fairseq2.nn.LayerNorm.forward", false]], "forward() (fairseq2.nn.learnedpositionencoder method)": [[34, "fairseq2.nn.LearnedPositionEncoder.forward", false]], "forward() (fairseq2.nn.linear method)": [[35, "fairseq2.nn.Linear.forward", false]], "forward() (fairseq2.nn.positionencoder method)": [[34, "fairseq2.nn.PositionEncoder.forward", false]], "forward() (fairseq2.nn.projection method)": [[35, "fairseq2.nn.Projection.forward", false]], "forward() (fairseq2.nn.residualconnect method)": [[36, "fairseq2.nn.ResidualConnect.forward", false]], "forward() (fairseq2.nn.rmsnorm method)": [[33, "fairseq2.nn.RMSNorm.forward", false]], "forward() (fairseq2.nn.rotaryencoder method)": [[34, "fairseq2.nn.RotaryEncoder.forward", false]], "forward() (fairseq2.nn.scaledresidualconnect method)": [[36, "fairseq2.nn.ScaledResidualConnect.forward", false]], "forward() (fairseq2.nn.shardedembedding method)": [[31, "fairseq2.nn.ShardedEmbedding.forward", false]], "forward() (fairseq2.nn.sinusoidalpositionencoder method)": [[34, "fairseq2.nn.SinusoidalPositionEncoder.forward", false]], "forward() (fairseq2.nn.standardembedding method)": [[31, "fairseq2.nn.StandardEmbedding.forward", false]], "forward() (fairseq2.nn.standardlayernorm method)": [[33, "fairseq2.nn.StandardLayerNorm.forward", false]], "forward() (fairseq2.nn.tiedprojection method)": [[35, "fairseq2.nn.TiedProjection.forward", false]], "from_embedding() (fairseq2.nn.shardedembedding static method)": [[31, "fairseq2.nn.ShardedEmbedding.from_embedding", false]], "gang (class in fairseq2.gang)": [[23, "fairseq2.gang.Gang", false]], "gangerror (class in fairseq2.gang)": [[23, "fairseq2.gang.GangError", false]], "gangs (class in fairseq2.gang)": [[23, "fairseq2.gang.Gangs", false]], "get_arch_config() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.get_arch_config", false]], "get_arch_config() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.get_arch_config", false]], "get_archs() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.get_archs", false]], "get_archs() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.get_archs", false]], "get_current_device() (in module fairseq2.device)": [[22, "fairseq2.device.get_current_device", false]], "get_dataset_config() (fairseq2.datasets.hub.datasethub method)": [[21, "fairseq2.datasets.hub.DatasetHub.get_dataset_config", false]], "get_default_device() (in module fairseq2.device)": [[22, "fairseq2.device.get_default_device", false]], "get_device_properties() (fairseq2.device.cudacontext method)": [[22, "fairseq2.device.CudaContext.get_device_properties", false]], "get_device_properties() (fairseq2.device.standardcudacontext method)": [[22, "fairseq2.device.StandardCudaContext.get_device_properties", false]], "get_model_config() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.get_model_config", false]], "get_model_config() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.get_model_config", false]], "get_qwen_shard_specs() (in module fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.get_qwen_shard_specs", false]], "get_qwen_tokenizer_hub() (in module fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.get_qwen_tokenizer_hub", false]], "get_shard_dims() (fairseq2.nn.shardedembedding method)": [[31, "fairseq2.nn.ShardedEmbedding.get_shard_dims", false]], "get_std_scale_factor() (fairseq2.models.qwen.qwenfactory method)": [[28, "fairseq2.models.qwen.QwenFactory.get_std_scale_factor", false]], "get_tokenizer_config() (fairseq2.data.tokenizers.hub.tokenizerhub method)": [[19, "fairseq2.data.tokenizers.hub.TokenizerHub.get_tokenizer_config", false]], "has_error() (fairseq2.utils.validation.validationresult method)": [[40, "fairseq2.utils.validation.ValidationResult.has_error", false]], "head_dim (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.head_dim", false]], "impl (fairseq2.models.llama.llamatokenizerconfig attribute)": [[27, "fairseq2.models.llama.LLaMATokenizerConfig.impl", false]], "increment_step_nr() (fairseq2.nn.incrementalstatebag method)": [[32, "fairseq2.nn.IncrementalStateBag.increment_step_nr", false]], "incrementalstate (class in fairseq2.nn)": [[32, "fairseq2.nn.IncrementalState", false]], "incrementalstatebag (class in fairseq2.nn)": [[32, "fairseq2.nn.IncrementalStateBag", false]], "init_scaled_embedding() (in module fairseq2.nn)": [[31, "fairseq2.nn.init_scaled_embedding", false]], "init_std (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.init_std", false]], "init_std_scale (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.init_std_scale", false]], "is_available() (fairseq2.device.cudacontext method)": [[22, "fairseq2.device.CudaContext.is_available", false]], "is_available() (fairseq2.device.standardcudacontext method)": [[22, "fairseq2.device.StandardCudaContext.is_available", false]], "iter_cards() (fairseq2.data.tokenizers.hub.tokenizerhub method)": [[19, "fairseq2.data.tokenizers.hub.TokenizerHub.iter_cards", false]], "iter_cards() (fairseq2.datasets.hub.datasethub method)": [[21, "fairseq2.datasets.hub.DatasetHub.iter_cards", false]], "iter_cards() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.iter_cards", false]], "iter_cards() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.iter_cards", false]], "iter_checkpoint() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.iter_checkpoint", false]], "iter_checkpoint() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.iter_checkpoint", false]], "k_norm (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.k_norm", false]], "layernorm (class in fairseq2.nn)": [[33, "fairseq2.nn.LayerNorm", false]], "lazy_load() (fairseq2.model_checkpoint.basicmodelcheckpointloader method)": [[24, "fairseq2.model_checkpoint.BasicModelCheckpointLoader.lazy_load", false]], "lazy_load() (fairseq2.model_checkpoint.delegatingmodelcheckpointloader method)": [[24, "fairseq2.model_checkpoint.DelegatingModelCheckpointLoader.lazy_load", false]], "lazy_load() (fairseq2.model_checkpoint.modelcheckpointloader method)": [[24, "fairseq2.model_checkpoint.ModelCheckpointLoader.lazy_load", false]], "lazy_load() (fairseq2.model_checkpoint.nativemodelcheckpointloader method)": [[24, "fairseq2.model_checkpoint.NativeModelCheckpointLoader.lazy_load", false]], "lazy_load() (fairseq2.model_checkpoint.safetensorscheckpointloader method)": [[24, "fairseq2.model_checkpoint.SafetensorsCheckpointLoader.lazy_load", false]], "learnedpositionencoder (class in fairseq2.nn)": [[34, "fairseq2.nn.LearnedPositionEncoder", false]], "linear (class in fairseq2.nn)": [[35, "fairseq2.nn.Linear", false]], "llamaconfig (class in fairseq2.models.llama)": [[27, "fairseq2.models.llama.LLaMAConfig", false]], "llamatokenizerconfig (class in fairseq2.models.llama)": [[27, "fairseq2.models.llama.LLaMATokenizerConfig", false]], "load_custom_model() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.load_custom_model", false]], "load_custom_model() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.load_custom_model", false]], "load_custom_tokenizer() (fairseq2.data.tokenizers.hub.tokenizerhub method)": [[19, "fairseq2.data.tokenizers.hub.TokenizerHub.load_custom_tokenizer", false]], "load_model() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.load_model", false]], "load_model() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.load_model", false]], "load_model() (in module fairseq2.models)": [[25, "fairseq2.models.load_model", false]], "load_model() (in module fairseq2.models.hub)": [[26, "fairseq2.models.hub.load_model", false]], "load_tokenizer() (fairseq2.data.tokenizers.hub.tokenizerhub method)": [[19, "fairseq2.data.tokenizers.hub.TokenizerHub.load_tokenizer", false]], "load_tokenizer() (in module fairseq2.data.tokenizers.hub)": [[19, "fairseq2.data.tokenizers.hub.load_tokenizer", false]], "localrankoutofrangeerror (class in fairseq2.device)": [[22, "fairseq2.device.LocalRankOutOfRangeError", false]], "max (fairseq2.gang.reduceoperation attribute)": [[23, "fairseq2.gang.ReduceOperation.MAX", false]], "max_num_steps (fairseq2.nn.incrementalstatebag property)": [[32, "fairseq2.nn.IncrementalStateBag.max_num_steps", false]], "max_seq_len (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.max_seq_len", false]], "max_seq_len (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.max_seq_len", false]], "max_seq_len (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.max_seq_len", false]], "maybe_get_arch_config() (fairseq2.models.hub.modelhub method)": [[26, "fairseq2.models.hub.ModelHub.maybe_get_arch_config", false]], "maybe_get_arch_config() (fairseq2.models.modelhub method)": [[25, "fairseq2.models.ModelHub.maybe_get_arch_config", false]], "maybe_get_current_gangs() (in module fairseq2.gang)": [[23, "fairseq2.gang.maybe_get_current_gangs", false]], "maybe_get_state() (fairseq2.nn.incrementalstatebag method)": [[32, "fairseq2.nn.IncrementalStateBag.maybe_get_state", false]], "maybe_raise_param_group_length_error() (in module fairseq2.recipe.optim)": [[39, "fairseq2.recipe.optim.maybe_raise_param_group_length_error", false]], "mean (fairseq2.gang.reduceoperation attribute)": [[23, "fairseq2.gang.ReduceOperation.MEAN", false]], "memory_stats() (fairseq2.device.cudacontext method)": [[22, "fairseq2.device.CudaContext.memory_stats", false]], "memory_stats() (fairseq2.device.standardcudacontext method)": [[22, "fairseq2.device.StandardCudaContext.memory_stats", false]], "min (fairseq2.gang.reduceoperation attribute)": [[23, "fairseq2.gang.ReduceOperation.MIN", false]], "min_seq_len (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.min_seq_len", false]], "model_dim (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.model_dim", false]], "model_dim (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.model_dim", false]], "modelarchitecturenotknownerror": [[26, "fairseq2.models.hub.ModelArchitectureNotKnownError", false]], "modelarchitecturenotknownerror (class in fairseq2.models)": [[25, "fairseq2.models.ModelArchitectureNotKnownError", false]], "modelcheckpointerror (class in fairseq2.model_checkpoint)": [[24, "fairseq2.model_checkpoint.ModelCheckpointError", false]], "modelcheckpointloader (class in fairseq2.model_checkpoint)": [[24, "fairseq2.model_checkpoint.ModelCheckpointLoader", false]], "modelfamilynotknownerror": [[26, "fairseq2.models.hub.ModelFamilyNotKnownError", false]], "modelfamilynotknownerror (class in fairseq2.models)": [[25, "fairseq2.models.ModelFamilyNotKnownError", false]], "modelhub (class in fairseq2.models)": [[25, "fairseq2.models.ModelHub", false]], "modelhub (class in fairseq2.models.hub)": [[26, "fairseq2.models.hub.ModelHub", false]], "modelhubaccessor (class in fairseq2.models)": [[25, "fairseq2.models.ModelHubAccessor", false]], "modelhubaccessor (class in fairseq2.models.hub)": [[26, "fairseq2.models.hub.ModelHubAccessor", false]], "modelnotknownerror": [[26, "fairseq2.models.hub.ModelNotKnownError", false]], "modelnotknownerror (class in fairseq2.models)": [[25, "fairseq2.models.ModelNotKnownError", false]], "module": [[15, "module-fairseq2.assets", false], [22, "module-fairseq2.device", false], [23, "module-fairseq2.gang", false], [24, "module-fairseq2.model_checkpoint", false], [25, "module-fairseq2.models", false], [29, "module-fairseq2", false], [38, "module-fairseq2.recipe.composition", false], [39, "module-fairseq2.recipe.optim", false], [40, "module-fairseq2.utils.validation", false]], "nativemodelcheckpointloader (class in fairseq2.model_checkpoint)": [[24, "fairseq2.model_checkpoint.NativeModelCheckpointLoader", false]], "num_attn_heads (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.num_attn_heads", false]], "num_attn_heads (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.num_attn_heads", false]], "num_key_value_heads (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.num_key_value_heads", false]], "num_key_value_heads (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.num_key_value_heads", false]], "num_layers (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.num_layers", false]], "num_layers (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.num_layers", false]], "objectvalidator (class in fairseq2.utils.validation)": [[40, "fairseq2.utils.validation.ObjectValidator", false]], "of() (fairseq2.nn.batchlayout static method)": [[30, "fairseq2.nn.BatchLayout.of", false]], "open_custom_dataset() (fairseq2.datasets.hub.datasethub method)": [[21, "fairseq2.datasets.hub.DatasetHub.open_custom_dataset", false]], "open_dataset() (fairseq2.datasets.hub.datasethub method)": [[21, "fairseq2.datasets.hub.DatasetHub.open_dataset", false]], "packed (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.packed", false]], "pad_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.pad_idx", false]], "pad_idx (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.pad_idx", false]], "padded (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.padded", false]], "position_indices (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.position_indices", false]], "positionencoder (class in fairseq2.nn)": [[34, "fairseq2.nn.PositionEncoder", false]], "pp (fairseq2.gang.gangs attribute)": [[23, "fairseq2.gang.Gangs.pp", false]], "prefix_indices (fairseq2.data.tokenizers.tokenencoder property)": [[18, "fairseq2.data.tokenizers.TokenEncoder.prefix_indices", false]], "prepare_parameter_groups() (in module fairseq2.recipe.optim)": [[39, "fairseq2.recipe.optim.prepare_parameter_groups", false]], "processgroupgang (class in fairseq2.gang)": [[23, "fairseq2.gang.ProcessGroupGang", false]], "product (fairseq2.gang.reduceoperation attribute)": [[23, "fairseq2.gang.ReduceOperation.PRODUCT", false]], "projection (class in fairseq2.nn)": [[35, "fairseq2.nn.Projection", false]], "q_norm (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.q_norm", false]], "qkv_proj_bias (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.qkv_proj_bias", false]], "qwen_family (in module fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.QWEN_FAMILY", false]], "qwenconfig (class in fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.QwenConfig", false]], "qwenfactory (class in fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.QwenFactory", false]], "qwentokenizer (class in fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.QwenTokenizer", false]], "qwentokenizerconfig (class in fairseq2.models.qwen)": [[28, "fairseq2.models.qwen.QwenTokenizerConfig", false]], "raise_operational_gang_error() (in module fairseq2.gang)": [[23, "fairseq2.gang.raise_operational_gang_error", false]], "rank (fairseq2.gang.fakegang property)": [[23, "fairseq2.gang.FakeGang.rank", false]], "rank (fairseq2.gang.gang property)": [[23, "fairseq2.gang.Gang.rank", false]], "rank (fairseq2.gang.processgroupgang property)": [[23, "fairseq2.gang.ProcessGroupGang.rank", false]], "rdp (fairseq2.gang.gangs attribute)": [[23, "fairseq2.gang.Gangs.rdp", false]], "reduceoperation (class in fairseq2.gang)": [[23, "fairseq2.gang.ReduceOperation", false]], "register_recipe_assets() (in module fairseq2.recipe.composition)": [[38, "fairseq2.recipe.composition.register_recipe_assets", false]], "reorder() (fairseq2.nn.incrementalstate method)": [[32, "fairseq2.nn.IncrementalState.reorder", false]], "reorder() (fairseq2.nn.incrementalstatebag method)": [[32, "fairseq2.nn.IncrementalStateBag.reorder", false]], "reset_non_persistent_buffers() (fairseq2.nn.rotaryencoder method)": [[34, "fairseq2.nn.RotaryEncoder.reset_non_persistent_buffers", false]], "reset_non_persistent_buffers() (fairseq2.nn.sinusoidalpositionencoder method)": [[34, "fairseq2.nn.SinusoidalPositionEncoder.reset_non_persistent_buffers", false]], "reset_parameters() (fairseq2.nn.learnedpositionencoder method)": [[34, "fairseq2.nn.LearnedPositionEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.linear method)": [[35, "fairseq2.nn.Linear.reset_parameters", false]], "reset_parameters() (fairseq2.nn.rmsnorm method)": [[33, "fairseq2.nn.RMSNorm.reset_parameters", false]], "reset_parameters() (fairseq2.nn.rotaryencoder method)": [[34, "fairseq2.nn.RotaryEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.shardedembedding method)": [[31, "fairseq2.nn.ShardedEmbedding.reset_parameters", false]], "reset_parameters() (fairseq2.nn.sinusoidalpositionencoder method)": [[34, "fairseq2.nn.SinusoidalPositionEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.standardembedding method)": [[31, "fairseq2.nn.StandardEmbedding.reset_parameters", false]], "reset_parameters() (fairseq2.nn.standardlayernorm method)": [[33, "fairseq2.nn.StandardLayerNorm.reset_parameters", false]], "reset_peak_memory_stats() (fairseq2.device.cudacontext method)": [[22, "fairseq2.device.CudaContext.reset_peak_memory_stats", false]], "reset_peak_memory_stats() (fairseq2.device.standardcudacontext method)": [[22, "fairseq2.device.StandardCudaContext.reset_peak_memory_stats", false]], "reshard_tensor() (in module fairseq2.model_checkpoint)": [[24, "fairseq2.model_checkpoint.reshard_tensor", false]], "residualconnect (class in fairseq2.nn)": [[36, "fairseq2.nn.ResidualConnect", false]], "result (fairseq2.utils.validation.validationerror attribute)": [[40, "fairseq2.utils.validation.ValidationError.result", false]], "rmsnorm (class in fairseq2.nn)": [[33, "fairseq2.nn.RMSNorm", false]], "root (fairseq2.gang.gangs attribute)": [[23, "fairseq2.gang.Gangs.root", false]], "rope_scale (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.rope_scale", false]], "rope_theta (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.rope_theta", false]], "rope_theta (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.rope_theta", false]], "rotaryencoder (class in fairseq2.nn)": [[34, "fairseq2.nn.RotaryEncoder", false]], "safetensorscheckpointloader (class in fairseq2.model_checkpoint)": [[24, "fairseq2.model_checkpoint.SafetensorsCheckpointLoader", false]], "scaledresidualconnect (class in fairseq2.nn)": [[36, "fairseq2.nn.ScaledResidualConnect", false]], "sdp (fairseq2.gang.gangs attribute)": [[23, "fairseq2.gang.Gangs.sdp", false]], "seq_begin_indices (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.seq_begin_indices", false]], "seq_begin_indices_pt (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.seq_begin_indices_pt", false]], "seq_lens (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.seq_lens", false]], "seq_lens_pt (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.seq_lens_pt", false]], "set_state() (fairseq2.nn.incrementalstatebag method)": [[32, "fairseq2.nn.IncrementalStateBag.set_state", false]], "shard_embed_dim (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.shard_embed_dim", false]], "shardedembedding (class in fairseq2.nn)": [[31, "fairseq2.nn.ShardedEmbedding", false]], "sinusoidalpositionencoder (class in fairseq2.nn)": [[34, "fairseq2.nn.SinusoidalPositionEncoder", false]], "size (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.size", false]], "size (fairseq2.gang.fakegang property)": [[23, "fairseq2.gang.FakeGang.size", false]], "size (fairseq2.gang.gang property)": [[23, "fairseq2.gang.Gang.size", false]], "size (fairseq2.gang.processgroupgang property)": [[23, "fairseq2.gang.ProcessGroupGang.size", false]], "size_bytes() (fairseq2.nn.incrementalstate method)": [[32, "fairseq2.nn.IncrementalState.size_bytes", false]], "size_bytes() (fairseq2.nn.incrementalstatebag method)": [[32, "fairseq2.nn.IncrementalStateBag.size_bytes", false]], "split_regex (fairseq2.models.llama.llamatokenizerconfig attribute)": [[27, "fairseq2.models.llama.LLaMATokenizerConfig.split_regex", false]], "standardcudacontext (class in fairseq2.device)": [[22, "fairseq2.device.StandardCudaContext", false]], "standardembedding (class in fairseq2.nn)": [[31, "fairseq2.nn.StandardEmbedding", false]], "standardlayernorm (class in fairseq2.nn)": [[33, "fairseq2.nn.StandardLayerNorm", false]], "standardobjectvalidator (class in fairseq2.utils.validation)": [[40, "fairseq2.utils.validation.StandardObjectValidator", false]], "step_nr (fairseq2.nn.incrementalstatebag property)": [[32, "fairseq2.nn.IncrementalStateBag.step_nr", false]], "sub_results (fairseq2.utils.validation.validationresult property)": [[40, "fairseq2.utils.validation.ValidationResult.sub_results", false]], "suffix_indices (fairseq2.data.tokenizers.tokenencoder property)": [[18, "fairseq2.data.tokenizers.TokenEncoder.suffix_indices", false]], "sum (fairseq2.gang.reduceoperation attribute)": [[23, "fairseq2.gang.ReduceOperation.SUM", false]], "supports_path() (fairseq2.model_checkpoint.basicmodelcheckpointloader method)": [[24, "fairseq2.model_checkpoint.BasicModelCheckpointLoader.supports_path", false]], "supports_path() (fairseq2.model_checkpoint.delegatingmodelcheckpointloader method)": [[24, "fairseq2.model_checkpoint.DelegatingModelCheckpointLoader.supports_path", false]], "supports_path() (fairseq2.model_checkpoint.modelcheckpointloader method)": [[24, "fairseq2.model_checkpoint.ModelCheckpointLoader.supports_path", false]], "supports_path() (fairseq2.model_checkpoint.nativemodelcheckpointloader method)": [[24, "fairseq2.model_checkpoint.NativeModelCheckpointLoader.supports_path", false]], "supports_path() (fairseq2.model_checkpoint.safetensorscheckpointloader method)": [[24, "fairseq2.model_checkpoint.SafetensorsCheckpointLoader.supports_path", false]], "supports_process_group (fairseq2.gang.fakegang property)": [[23, "fairseq2.gang.FakeGang.supports_process_group", false]], "supports_process_group (fairseq2.gang.gang property)": [[23, "fairseq2.gang.Gang.supports_process_group", false]], "supports_process_group (fairseq2.gang.processgroupgang property)": [[23, "fairseq2.gang.ProcessGroupGang.supports_process_group", false]], "supportsdevicetransfer (class in fairseq2.device)": [[22, "fairseq2.device.SupportsDeviceTransfer", false]], "tied_embeddings (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.tied_embeddings", false]], "tied_embeddings (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.tied_embeddings", false]], "tiedprojection (class in fairseq2.nn)": [[35, "fairseq2.nn.TiedProjection", false]], "to() (fairseq2.device.supportsdevicetransfer method)": [[22, "fairseq2.device.SupportsDeviceTransfer.to", false]], "to_embedding() (fairseq2.nn.shardedembedding method)": [[31, "fairseq2.nn.ShardedEmbedding.to_embedding", false]], "tokendecoder (class in fairseq2.data.tokenizers)": [[18, "fairseq2.data.tokenizers.TokenDecoder", false]], "tokenencoder (class in fairseq2.data.tokenizers)": [[18, "fairseq2.data.tokenizers.TokenEncoder", false]], "tokenizer (class in fairseq2.data.tokenizers)": [[18, "fairseq2.data.tokenizers.Tokenizer", false]], "tokenizerfamilynotknownerror": [[19, "fairseq2.data.tokenizers.hub.TokenizerFamilyNotKnownError", false]], "tokenizerhub (class in fairseq2.data.tokenizers.hub)": [[19, "fairseq2.data.tokenizers.hub.TokenizerHub", false]], "tokenizerhubaccessor (class in fairseq2.data.tokenizers.hub)": [[19, "fairseq2.data.tokenizers.hub.TokenizerHubAccessor", false]], "tokenizernotknownerror": [[19, "fairseq2.data.tokenizers.hub.TokenizerNotKnownError", false]], "tp (fairseq2.gang.gangs attribute)": [[23, "fairseq2.gang.Gangs.tp", false]], "unk_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.unk_idx", false]], "use_eot (fairseq2.models.llama.llamatokenizerconfig attribute)": [[27, "fairseq2.models.llama.LLaMATokenizerConfig.use_eot", false]], "use_im_end (fairseq2.models.qwen.qwentokenizerconfig attribute)": [[28, "fairseq2.models.qwen.QwenTokenizerConfig.use_im_end", false]], "use_scaled_rope (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.use_scaled_rope", false]], "validatable (class in fairseq2.utils.validation)": [[40, "fairseq2.utils.validation.Validatable", false]], "validate() (fairseq2.utils.validation.objectvalidator method)": [[40, "fairseq2.utils.validation.ObjectValidator.validate", false]], "validate() (fairseq2.utils.validation.standardobjectvalidator method)": [[40, "fairseq2.utils.validation.StandardObjectValidator.validate", false]], "validate() (fairseq2.utils.validation.validatable method)": [[40, "fairseq2.utils.validation.Validatable.validate", false]], "validationerror": [[40, "fairseq2.utils.validation.ValidationError", false]], "validationresult (class in fairseq2.utils.validation)": [[40, "fairseq2.utils.validation.ValidationResult", false]], "vocab_info (fairseq2.data.tokenizers.tokenizer property)": [[18, "fairseq2.data.tokenizers.Tokenizer.vocab_info", false]], "vocab_info (fairseq2.models.qwen.qwentokenizer property)": [[28, "fairseq2.models.qwen.QwenTokenizer.vocab_info", false]], "vocab_size (fairseq2.models.llama.llamaconfig attribute)": [[27, "fairseq2.models.llama.LLaMAConfig.vocab_size", false]], "vocab_size (fairseq2.models.qwen.qwenconfig attribute)": [[28, "fairseq2.models.qwen.QwenConfig.vocab_size", false]], "vocabularyinfo (class in fairseq2.data.tokenizers)": [[18, "fairseq2.data.tokenizers.VocabularyInfo", false]], "width (fairseq2.nn.batchlayout property)": [[30, "fairseq2.nn.BatchLayout.width", false]]}, "objects": {"": [[29, 0, 0, "-", "fairseq2"]], "fairseq2": [[15, 0, 0, "-", "assets"], [22, 0, 0, "-", "device"], [23, 0, 0, "-", "gang"], [24, 0, 0, "-", "model_checkpoint"], [25, 0, 0, "-", "models"]], "fairseq2.data.tokenizers": [[18, 1, 1, "", "TokenDecoder"], [18, 1, 1, "", "TokenEncoder"], [18, 1, 1, "", "Tokenizer"], [18, 1, 1, "", "VocabularyInfo"]], "fairseq2.data.tokenizers.TokenDecoder": [[18, 2, 1, "", "decode_from_tokens"]], "fairseq2.data.tokenizers.TokenEncoder": [[18, 2, 1, "", "encode_as_tokens"], [18, 3, 1, "", "prefix_indices"], [18, 3, 1, "", "suffix_indices"]], "fairseq2.data.tokenizers.Tokenizer": [[18, 2, 1, "", "create_decoder"], [18, 2, 1, "", "create_encoder"], [18, 2, 1, "", "create_raw_encoder"], [18, 3, 1, "", "vocab_info"]], "fairseq2.data.tokenizers.VocabularyInfo": [[18, 4, 1, "", "boh_idx"], [18, 4, 1, "", "bos_idx"], [18, 4, 1, "", "eoh_idx"], [18, 4, 1, "", "eos_idx"], [18, 4, 1, "", "pad_idx"], [18, 4, 1, "", "size"], [18, 4, 1, "", "unk_idx"]], "fairseq2.data.tokenizers.hub": [[19, 5, 1, "", "TokenizerFamilyNotKnownError"], [19, 1, 1, "", "TokenizerHub"], [19, 1, 1, "", "TokenizerHubAccessor"], [19, 5, 1, "", "TokenizerNotKnownError"], [19, 6, 1, "", "load_tokenizer"]], "fairseq2.data.tokenizers.hub.TokenizerHub": [[19, 2, 1, "", "get_tokenizer_config"], [19, 2, 1, "", "iter_cards"], [19, 2, 1, "", "load_custom_tokenizer"], [19, 2, 1, "", "load_tokenizer"]], "fairseq2.datasets.hub": [[21, 5, 1, "", "DatasetFamilyNotKnownError"], [21, 1, 1, "", "DatasetHub"], [21, 1, 1, "", "DatasetHubAccessor"], [21, 5, 1, "", "DatasetNotKnownError"]], "fairseq2.datasets.hub.DatasetHub": [[21, 2, 1, "", "get_dataset_config"], [21, 2, 1, "", "iter_cards"], [21, 2, 1, "", "open_custom_dataset"], [21, 2, 1, "", "open_dataset"]], "fairseq2.device": [[22, 1, 1, "", "CudaContext"], [22, 1, 1, "", "LocalRankOutOfRangeError"], [22, 1, 1, "", "StandardCudaContext"], [22, 1, 1, "", "SupportsDeviceTransfer"], [22, 6, 1, "", "get_current_device"], [22, 6, 1, "", "get_default_device"]], "fairseq2.device.CudaContext": [[22, 2, 1, "", "device_count"], [22, 2, 1, "", "get_device_properties"], [22, 2, 1, "", "is_available"], [22, 2, 1, "", "memory_stats"], [22, 2, 1, "", "reset_peak_memory_stats"]], "fairseq2.device.StandardCudaContext": [[22, 2, 1, "", "device_count"], [22, 2, 1, "", "get_device_properties"], [22, 2, 1, "", "is_available"], [22, 2, 1, "", "memory_stats"], [22, 2, 1, "", "reset_peak_memory_stats"]], "fairseq2.device.SupportsDeviceTransfer": [[22, 2, 1, "", "to"]], "fairseq2.gang": [[23, 1, 1, "", "FakeGang"], [23, 1, 1, "", "Gang"], [23, 1, 1, "", "GangError"], [23, 1, 1, "", "Gangs"], [23, 1, 1, "", "ProcessGroupGang"], [23, 1, 1, "", "ReduceOperation"], [23, 6, 1, "", "all_sum"], [23, 6, 1, "", "broadcast_flag"], [23, 6, 1, "", "create_fake_gangs"], [23, 6, 1, "", "create_fsdp_gangs"], [23, 6, 1, "", "create_parallel_gangs"], [23, 6, 1, "", "maybe_get_current_gangs"], [23, 6, 1, "", "raise_operational_gang_error"]], "fairseq2.gang.FakeGang": [[23, 2, 1, "", "all_gather"], [23, 2, 1, "", "all_gather_to_list"], [23, 2, 1, "", "all_reduce"], [23, 2, 1, "", "as_process_group"], [23, 2, 1, "", "barrier"], [23, 2, 1, "", "broadcast"], [23, 2, 1, "", "broadcast_objects"], [23, 2, 1, "", "close"], [23, 2, 1, "", "create_gang"], [23, 3, 1, "", "device"], [23, 3, 1, "", "rank"], [23, 3, 1, "", "size"], [23, 3, 1, "", "supports_process_group"]], "fairseq2.gang.Gang": [[23, 2, 1, "", "all_gather"], [23, 2, 1, "", "all_gather_to_list"], [23, 2, 1, "", "all_reduce"], [23, 2, 1, "", "as_process_group"], [23, 2, 1, "", "barrier"], [23, 2, 1, "", "broadcast"], [23, 2, 1, "", "broadcast_objects"], [23, 2, 1, "", "create_gang"], [23, 3, 1, "", "device"], [23, 3, 1, "", "rank"], [23, 3, 1, "", "size"], [23, 3, 1, "", "supports_process_group"]], "fairseq2.gang.Gangs": [[23, 2, 1, "", "close"], [23, 4, 1, "", "dp"], [23, 4, 1, "", "pp"], [23, 4, 1, "", "rdp"], [23, 4, 1, "", "root"], [23, 4, 1, "", "sdp"], [23, 4, 1, "", "tp"]], "fairseq2.gang.ProcessGroupGang": [[23, 2, 1, "", "all_gather"], [23, 2, 1, "", "all_gather_to_list"], [23, 2, 1, "", "all_reduce"], [23, 2, 1, "", "as_process_group"], [23, 2, 1, "", "barrier"], [23, 2, 1, "", "broadcast"], [23, 2, 1, "", "broadcast_objects"], [23, 2, 1, "", "close"], [23, 2, 1, "", "create_default_process_group"], [23, 2, 1, "", "create_gang"], [23, 3, 1, "", "device"], [23, 3, 1, "", "rank"], [23, 3, 1, "", "size"], [23, 3, 1, "", "supports_process_group"]], "fairseq2.gang.ReduceOperation": [[23, 4, 1, "", "MAX"], [23, 4, 1, "", "MEAN"], [23, 4, 1, "", "MIN"], [23, 4, 1, "", "PRODUCT"], [23, 4, 1, "", "SUM"]], "fairseq2.model_checkpoint": [[24, 1, 1, "", "BasicModelCheckpointLoader"], [24, 1, 1, "", "DelegatingModelCheckpointLoader"], [24, 1, 1, "", "ModelCheckpointError"], [24, 1, 1, "", "ModelCheckpointLoader"], [24, 1, 1, "", "NativeModelCheckpointLoader"], [24, 1, 1, "", "SafetensorsCheckpointLoader"], [24, 6, 1, "", "reshard_tensor"]], "fairseq2.model_checkpoint.BasicModelCheckpointLoader": [[24, 2, 1, "", "lazy_load"], [24, 2, 1, "", "supports_path"]], "fairseq2.model_checkpoint.DelegatingModelCheckpointLoader": [[24, 2, 1, "", "lazy_load"], [24, 2, 1, "", "supports_path"]], "fairseq2.model_checkpoint.ModelCheckpointLoader": [[24, 2, 1, "", "lazy_load"], [24, 2, 1, "", "supports_path"]], "fairseq2.model_checkpoint.NativeModelCheckpointLoader": [[24, 2, 1, "", "lazy_load"], [24, 2, 1, "", "supports_path"]], "fairseq2.model_checkpoint.SafetensorsCheckpointLoader": [[24, 2, 1, "", "lazy_load"], [24, 2, 1, "", "supports_path"]], "fairseq2.models": [[25, 1, 1, "", "ModelArchitectureNotKnownError"], [25, 1, 1, "", "ModelFamilyNotKnownError"], [25, 1, 1, "", "ModelHub"], [25, 1, 1, "", "ModelHubAccessor"], [25, 1, 1, "", "ModelNotKnownError"], [25, 6, 1, "", "load_model"]], "fairseq2.models.ModelHub": [[25, 2, 1, "", "create_new_model"], [25, 2, 1, "", "get_arch_config"], [25, 2, 1, "", "get_archs"], [25, 2, 1, "", "get_model_config"], [25, 2, 1, "", "iter_cards"], [25, 2, 1, "", "iter_checkpoint"], [25, 2, 1, "", "load_custom_model"], [25, 2, 1, "", "load_model"], [25, 2, 1, "", "maybe_get_arch_config"]], "fairseq2.models.hub": [[26, 5, 1, "", "ModelArchitectureNotKnownError"], [26, 5, 1, "", "ModelFamilyNotKnownError"], [26, 1, 1, "", "ModelHub"], [26, 1, 1, "", "ModelHubAccessor"], [26, 5, 1, "", "ModelNotKnownError"], [26, 6, 1, "", "load_model"]], "fairseq2.models.hub.ModelHub": [[26, 2, 1, "", "create_new_model"], [26, 2, 1, "", "get_arch_config"], [26, 2, 1, "", "get_archs"], [26, 2, 1, "", "get_model_config"], [26, 2, 1, "", "iter_cards"], [26, 2, 1, "", "iter_checkpoint"], [26, 2, 1, "", "load_custom_model"], [26, 2, 1, "", "load_model"], [26, 2, 1, "", "maybe_get_arch_config"]], "fairseq2.models.llama": [[27, 1, 1, "", "LLaMAConfig"], [27, 1, 1, "", "LLaMATokenizerConfig"]], "fairseq2.models.llama.LLaMAConfig": [[27, 4, 1, "", "dropout_p"], [27, 4, 1, "", "ffn_inner_dim"], [27, 4, 1, "", "ffn_inner_dim_multiple_of"], [27, 4, 1, "", "ffn_inner_dim_multiplier"], [27, 4, 1, "", "ffn_inner_dim_scale"], [27, 4, 1, "", "init_std"], [27, 4, 1, "", "init_std_scale"], [27, 4, 1, "", "max_seq_len"], [27, 4, 1, "", "model_dim"], [27, 4, 1, "", "num_attn_heads"], [27, 4, 1, "", "num_key_value_heads"], [27, 4, 1, "", "num_layers"], [27, 4, 1, "", "pad_idx"], [27, 4, 1, "", "rope_scale"], [27, 4, 1, "", "rope_theta"], [27, 4, 1, "", "shard_embed_dim"], [27, 4, 1, "", "tied_embeddings"], [27, 4, 1, "", "use_scaled_rope"], [27, 4, 1, "", "vocab_size"]], "fairseq2.models.llama.LLaMATokenizerConfig": [[27, 4, 1, "", "impl"], [27, 4, 1, "", "split_regex"], [27, 4, 1, "", "use_eot"]], "fairseq2.models.qwen": [[28, 7, 1, "", "QWEN_FAMILY"], [28, 1, 1, "", "QwenConfig"], [28, 1, 1, "", "QwenFactory"], [28, 1, 1, "", "QwenTokenizer"], [28, 1, 1, "", "QwenTokenizerConfig"], [28, 6, 1, "", "convert_qwen_state_dict"], [28, 6, 1, "", "create_qwen_model"], [28, 6, 1, "", "export_qwen"], [28, 6, 1, "", "get_qwen_shard_specs"], [28, 6, 1, "", "get_qwen_tokenizer_hub"]], "fairseq2.models.qwen.QwenConfig": [[28, 4, 1, "", "dropout_p"], [28, 4, 1, "", "ffn_inner_dim"], [28, 4, 1, "", "head_dim"], [28, 4, 1, "", "k_norm"], [28, 4, 1, "", "max_seq_len"], [28, 4, 1, "", "model_dim"], [28, 4, 1, "", "num_attn_heads"], [28, 4, 1, "", "num_key_value_heads"], [28, 4, 1, "", "num_layers"], [28, 4, 1, "", "q_norm"], [28, 4, 1, "", "qkv_proj_bias"], [28, 4, 1, "", "rope_theta"], [28, 4, 1, "", "tied_embeddings"], [28, 4, 1, "", "vocab_size"]], "fairseq2.models.qwen.QwenFactory": [[28, 2, 1, "", "create_decoder"], [28, 2, 1, "", "create_decoder_frontend"], [28, 2, 1, "", "create_decoder_layer"], [28, 2, 1, "", "create_embedding"], [28, 2, 1, "", "create_ffn"], [28, 2, 1, "", "create_final_projection"], [28, 2, 1, "", "create_layer_norm"], [28, 2, 1, "", "create_model"], [28, 2, 1, "", "create_position_encoder"], [28, 2, 1, "", "create_self_attention"], [28, 2, 1, "", "get_std_scale_factor"]], "fairseq2.models.qwen.QwenTokenizer": [[28, 2, 1, "", "create_decoder"], [28, 2, 1, "", "create_encoder"], [28, 2, 1, "", "create_raw_encoder"], [28, 3, 1, "", "vocab_info"]], "fairseq2.models.qwen.QwenTokenizerConfig": [[28, 4, 1, "", "use_im_end"]], "fairseq2.nn": [[36, 1, 1, "", "AdditiveResidualConnect"], [30, 1, 1, "", "BatchLayout"], [31, 1, 1, "", "Embedding"], [32, 1, 1, "", "IncrementalState"], [32, 1, 1, "", "IncrementalStateBag"], [33, 1, 1, "", "LayerNorm"], [34, 1, 1, "", "LearnedPositionEncoder"], [35, 1, 1, "", "Linear"], [34, 1, 1, "", "PositionEncoder"], [35, 1, 1, "", "Projection"], [33, 1, 1, "", "RMSNorm"], [36, 1, 1, "", "ResidualConnect"], [34, 1, 1, "", "RotaryEncoder"], [36, 1, 1, "", "ScaledResidualConnect"], [31, 1, 1, "", "ShardedEmbedding"], [34, 1, 1, "", "SinusoidalPositionEncoder"], [31, 1, 1, "", "StandardEmbedding"], [33, 1, 1, "", "StandardLayerNorm"], [35, 1, 1, "", "TiedProjection"], [31, 6, 1, "", "init_scaled_embedding"]], "fairseq2.nn.AdditiveResidualConnect": [[36, 2, 1, "", "forward"]], "fairseq2.nn.BatchLayout": [[30, 4, 1, "", "compiled_max_seq_len"], [30, 3, 1, "", "max_seq_len"], [30, 3, 1, "", "min_seq_len"], [30, 2, 1, "", "of"], [30, 3, 1, "", "packed"], [30, 3, 1, "", "padded"], [30, 3, 1, "", "position_indices"], [30, 3, 1, "", "seq_begin_indices"], [30, 3, 1, "", "seq_begin_indices_pt"], [30, 3, 1, "", "seq_lens"], [30, 3, 1, "", "seq_lens_pt"], [30, 3, 1, "", "width"]], "fairseq2.nn.Embedding": [[31, 2, 1, "", "forward"]], "fairseq2.nn.IncrementalState": [[32, 2, 1, "", "capacity_bytes"], [32, 2, 1, "", "reorder"], [32, 2, 1, "", "size_bytes"]], "fairseq2.nn.IncrementalStateBag": [[32, 2, 1, "", "capacity_bytes"], [32, 3, 1, "", "capacity_increment"], [32, 2, 1, "", "increment_step_nr"], [32, 3, 1, "", "max_num_steps"], [32, 2, 1, "", "maybe_get_state"], [32, 2, 1, "", "reorder"], [32, 2, 1, "", "set_state"], [32, 2, 1, "", "size_bytes"], [32, 3, 1, "", "step_nr"]], "fairseq2.nn.LayerNorm": [[33, 2, 1, "", "forward"]], "fairseq2.nn.LearnedPositionEncoder": [[34, 2, 1, "", "forward"], [34, 2, 1, "", "reset_parameters"]], "fairseq2.nn.Linear": [[35, 2, 1, "", "forward"], [35, 2, 1, "", "reset_parameters"]], "fairseq2.nn.PositionEncoder": [[34, 2, 1, "", "forward"]], "fairseq2.nn.Projection": [[35, 2, 1, "", "forward"]], "fairseq2.nn.RMSNorm": [[33, 2, 1, "", "extra_repr"], [33, 2, 1, "", "forward"], [33, 2, 1, "", "reset_parameters"]], "fairseq2.nn.ResidualConnect": [[36, 2, 1, "", "forward"]], "fairseq2.nn.RotaryEncoder": [[34, 2, 1, "", "forward"], [34, 2, 1, "", "reset_non_persistent_buffers"], [34, 2, 1, "", "reset_parameters"]], "fairseq2.nn.ScaledResidualConnect": [[36, 2, 1, "", "forward"]], "fairseq2.nn.ShardedEmbedding": [[31, 2, 1, "", "forward"], [31, 2, 1, "", "from_embedding"], [31, 2, 1, "", "get_shard_dims"], [31, 2, 1, "", "reset_parameters"], [31, 2, 1, "", "to_embedding"]], "fairseq2.nn.SinusoidalPositionEncoder": [[34, 2, 1, "", "forward"], [34, 2, 1, "", "reset_non_persistent_buffers"], [34, 2, 1, "", "reset_parameters"]], "fairseq2.nn.StandardEmbedding": [[31, 2, 1, "", "forward"], [31, 2, 1, "", "reset_parameters"]], "fairseq2.nn.StandardLayerNorm": [[33, 2, 1, "", "extra_repr"], [33, 2, 1, "", "forward"], [33, 2, 1, "", "reset_parameters"]], "fairseq2.nn.TiedProjection": [[35, 2, 1, "", "forward"]], "fairseq2.nn.utils.mask": [[37, 6, 1, "", "apply_mask"], [37, 6, 1, "", "compute_row_mask"]], "fairseq2.recipe": [[38, 0, 0, "-", "composition"], [39, 0, 0, "-", "optim"]], "fairseq2.recipe.composition": [[38, 6, 1, "", "register_recipe_assets"]], "fairseq2.recipe.optim": [[39, 6, 1, "", "maybe_raise_param_group_length_error"], [39, 6, 1, "", "prepare_parameter_groups"]], "fairseq2.utils": [[40, 0, 0, "-", "validation"]], "fairseq2.utils.validation": [[40, 1, 1, "", "ObjectValidator"], [40, 1, 1, "", "StandardObjectValidator"], [40, 1, 1, "", "Validatable"], [40, 5, 1, "", "ValidationError"], [40, 1, 1, "", "ValidationResult"]], "fairseq2.utils.validation.ObjectValidator": [[40, 2, 1, "", "validate"]], "fairseq2.utils.validation.StandardObjectValidator": [[40, 2, 1, "", "validate"]], "fairseq2.utils.validation.Validatable": [[40, 2, 1, "", "validate"]], "fairseq2.utils.validation.ValidationError": [[40, 4, 1, "", "result"]], "fairseq2.utils.validation.ValidationResult": [[40, 2, 1, "", "add_error"], [40, 2, 1, "", "add_sub_result"], [40, 3, 1, "", "errors"], [40, 2, 1, "", "has_error"], [40, 3, 1, "", "sub_results"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "exception", "Python exception"], "6": ["py", "function", "Python function"], "7": ["py", "data", "Python data"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:exception", "6": "py:function", "7": "py:data"}, "terms": {"": [1, 2, 3, 5, 7, 9, 10, 11, 14, 17, 20, 23, 25, 26, 27, 30, 31, 34, 36, 37, 38], "0": [5, 18, 19, 22, 23, 24, 27, 28, 30, 31, 34, 37, 39, 40], "03762": 13, "05": 33, "064": 28, "06450": 13, "07467": 13, "09864": 13, "1": [5, 20, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40], "10": 23, "100": 30, "10000": [27, 34], "1000000": 28, "10h": 20, "11477": 13, "11_008": 9, "12": [6, 7, 8, 14, 24], "128": 9, "13": [25, 26], "13971": 13, "14": [7, 8, 30, 37], "14b": 28, "15": [23, 37], "151_936": 9, "152": 28, "152064": 28, "16": [23, 25, 26, 32, 37], "1607": 13, "16384": [27, 28], "1706": 13, "18": 8, "18944": 28, "1910": 13, "1_000_000": [9, 28], "1d": 30, "1e": 33, "1t": 12, "2": [5, 6, 20, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 37, 38], "20": [1, 23], "2006": 13, "2016": 13, "2019": 13, "2020": 13, "2023": 13, "2024": [8, 9], "2048": [9, 27, 28, 34], "21": 8, "2104": 13, "22": 8, "2302": 13, "24": [10, 28], "25": 30, "250": 30, "256": 27, "28": 28, "2d": [5, 24], "2x4": 5, "3": [0, 5, 8, 12, 20, 23, 27, 28, 30, 31, 33, 34, 37], "32": [27, 28], "32000": [27, 31], "32768": [26, 28], "32_768": 9, "32b": 28, "3584": 28, "36": 9, "37": 30, "3b": [9, 28], "4": [5, 23, 24, 27, 28, 30, 31, 34, 37], "400": 30, "4096": [0, 27, 28], "4b": 28, "5": [9, 11, 23, 27, 28, 30, 31, 33, 34, 37], "50": 30, "512": [30, 31, 34, 37], "5b": [26, 28], "6": [6, 8, 13, 30, 31, 33, 34], "65": 37, "6666666666666666": 27, "6899": 10, "6b": [9, 18, 19, 28], "7": [6, 23], "70": 7, "75": 30, "768": 28, "7b": [0, 28], "8": [5, 7, 10, 23, 24, 30], "80": [7, 10], "8084": 14, "8192": 0, "8b": [0, 12, 27, 28], "9": [8, 30, 39], "95": 9, "99": 39, "A": [0, 1, 5, 9, 12, 23, 32, 34, 38, 39, 40], "And": 7, "As": [1, 7, 25, 26], "At": [5, 23], "By": [7, 14, 23], "For": [0, 1, 3, 5, 6, 7, 9, 10, 14, 20, 23, 24, 25, 26, 27, 30, 33, 38, 39, 40], "If": [0, 5, 7, 9, 14, 18, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 38, 39, 40], "In": [0, 5, 7, 9, 10, 14, 23, 24], "It": [5, 12, 17, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 32], "Its": [25, 26], "NOT": 40, "No": [0, 8, 12, 23, 27], "Not": 0, "ON": [7, 14], "On": [10, 24], "One": [1, 2], "Or": [3, 18, 28], "That": 1, "The": [1, 2, 3, 5, 7, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44], "Then": [1, 3, 7, 27], "There": 9, "These": [0, 2, 8, 40], "To": [0, 6, 7, 14, 33, 40], "Will": 27, "With": 8, "_": [0, 7, 30], "__init__": [1, 2, 3, 30], "__main__": 3, "__name__": 3, "__path__": 38, "__source__": 0, "__str__": 28, "__version__": 8, "_base": 0, "_chat": 0, "_devic": 23, "_eos_token": 27, "_file": 1, "_instruct": 0, "_legacy_pad_idx": 34, "_model": [1, 27], "_pg": 23, "_tok": 27, "a100": 7, "ab": [9, 13], "abbrevi": 2, "abc": [2, 18, 22, 24, 31, 32, 33, 34, 35, 36, 39, 40], "abdelrahman": 13, "abi": [6, 14], "abil": 12, "abl": 14, "about": [0, 1, 5, 7, 25, 26, 32, 38], "abov": [6, 7, 8, 14], "absolut": [20, 38], "abstract": [0, 2, 5, 17, 18, 22, 23, 24, 31, 32, 33, 34, 35, 36, 40], "accept": [14, 25, 26, 33], "access": [2, 5, 9, 10, 19, 20, 21, 25, 26, 27, 28], "accessor": [19, 21, 26], "accident": [8, 25, 26], "accompani": 14, "accord": [25, 26, 32], "accordingli": [23, 24, 25, 26], "achiev": 7, "across": [0, 1, 12, 23, 24, 25, 26, 31], "act": [2, 22], "activ": [7, 8, 12], "actual": [5, 7, 9, 23, 38], "ad": [12, 14, 20, 26, 27, 28, 36], "adamw": 43, "adamwconfig": 39, "adamwgroupconfig": 39, "adapt": 18, "add": [0, 3, 8, 11, 14, 20, 26, 27, 28, 33, 40], "add_error": 40, "add_generation_prompt": 27, "add_sub_result": 40, "addit": [0, 5, 6, 8, 10, 14, 28, 33, 38, 39], "additiveresidualconnect": 36, "address": [5, 14], "adjac": 23, "adjust": [10, 25, 26], "advanc": [1, 7, 9, 18, 25], "advanced_open": 20, "advantag": [5, 12], "affin": 33, "after": [8, 9, 14, 20, 32], "aggreg": 42, "agnost": 19, "agre": 14, "ahm": 13, "ai": [18, 19, 27, 28], "aidan": 13, "aim": 27, "al": [27, 33, 34], "alexei": 13, "algorithm": [2, 18, 34], "alia": 22, "all": [0, 2, 3, 5, 9, 10, 12, 13, 14, 18, 19, 20, 21, 23, 25, 26, 30, 35, 40], "all_gath": 23, "all_gather_to_list": 23, "all_reduc": [5, 23], "all_sum": 23, "alloc": [10, 23, 30], "allow": [0, 1, 2, 3, 5, 8, 11, 24, 25, 26, 34], "allow_uneven": 1, "allreduc": 5, "along": [2, 7, 23, 24, 31, 40], "alongsid": 38, "alreadi": [7, 14, 23], "also": [6, 7, 14, 20, 24, 25, 37], "altern": [5, 12, 14], "alwai": [8, 37, 38], "amper": 7, "an": [0, 2, 5, 6, 7, 9, 10, 14, 18, 20, 22, 23, 25, 26, 28, 31, 32, 33, 34, 38, 39, 40], "analysi": 12, "and_return": 1, "ani": [0, 1, 2, 3, 5, 7, 14, 20, 22, 25, 26, 31, 32, 34, 37, 40], "ann": 13, "annot": 2, "anoth": 35, "api": [0, 1, 2, 5, 6, 12, 14, 22, 23, 24, 26, 27, 28, 30, 34], "appear": [9, 10], "appli": [9, 25, 26, 27, 28, 30, 33, 35, 36, 37], "applic": 41, "apply_chat_templ": 27, "apply_mask": [30, 37], "approach": [1, 2, 5], "appropri": [9, 10, 24, 25, 26], "approx": 28, "apt": [6, 7], "ar": [0, 1, 2, 3, 5, 7, 8, 9, 12, 14, 18, 20, 23, 25, 26, 27, 28, 30, 33, 35, 38, 40], "arbitrari": 23, "arch": [3, 7, 9, 25, 26, 28], "architectur": [0, 1, 2, 3, 5, 25, 26, 27, 29], "arg": [2, 23, 33, 36, 40], "argument": [1, 5, 10, 18, 28, 34, 39], "armand": 13, "around": [2, 3], "arrow": [6, 14], "art": 12, "arxiv": [9, 13], "as_": [1, 26], "as_auto_regress": 1, "as_i": 27, "as_input": 1, "as_process_group": 23, "ashish": 13, "ask": 7, "aspect": 1, "assert": [5, 22, 23, 27], "asset": [1, 2, 3, 8, 11, 12, 18, 19, 21, 25, 26, 27, 28, 38, 40], "asset_nam": 0, "asset_stor": [0, 2, 19, 21, 25, 26], "assetcard": [19, 21, 25, 26], "assetcarderror": [25, 26], "assetnotfounderror": 0, "assetsconfig": 38, "assetstor": [2, 19, 21, 25, 26, 38], "assign": 39, "assist": 27, "associ": [5, 18, 28], "astral": 8, "async": 12, "asynchron": [12, 22], "atmeta": [6, 8, 14], "attempt": [19, 21], "attent": [2, 9, 12, 13, 25, 26, 27, 28, 30], "attentionlay": 30, "attn_mask": 30, "attribut": 23, "audiocol": 17, "audiodataset": 17, "auli": 13, "aurelien": 13, "authent": 9, "author": [24, 25, 26, 38], "auto": 2, "auto_activate_bas": 8, "autocomplet": 1, "automat": [1, 2, 24, 26, 30], "avail": [0, 5, 7, 9, 12, 14, 19, 21, 22, 23, 25, 26, 27, 38], "average_loss": 23, "avoid": [7, 22, 24], "awar": 12, "azhar": 13, "b": [7, 14], "ba": [13, 33], "back": [5, 8], "backend": [5, 23], "background": 1, "backward": [25, 26], "baevski": 13, "bag": 32, "baptist": 13, "bar": [25, 26], "barrier": 23, "base": [1, 2, 5, 7, 8, 10, 12, 14, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40], "base_model": 0, "base_model_instruct": 0, "baselin": 12, "basic": [0, 1, 5, 8, 9, 10, 20, 39], "basicmodelcheckpointload": 24, "batch": [1, 17, 23, 29, 30, 31, 32, 34, 36, 37], "batch_first": 30, "batch_layout": [11, 12, 29, 31, 34, 37], "batch_siz": 30, "batch_tensor": [30, 37], "batchlayout": [1, 12, 17, 28, 31, 34, 37], "beam": 32, "becaus": [5, 14], "becom": [7, 8, 14, 22], "been": 12, "befor": [0, 7, 10, 23, 36, 40], "begin": [5, 18, 27, 30], "begin_of_text": 27, "beginn": [1, 12], "behavior": 5, "behind": 18, "being": [11, 14, 15, 16, 41, 42, 43, 44], "belong": [23, 25, 26, 39], "below": [0, 2, 8, 14, 23, 25, 26, 34], "benefici": 5, "benefit": [0, 5], "beta": 39, "better": [12, 30], "between": [0, 2, 6, 8, 14, 18, 22, 25, 26, 28, 32], "beyond": 9, "bia": [9, 28, 33, 35], "biao": 13, "bibliographi": 11, "bibtex": 8, "bin": [7, 8, 24], "binari": 14, "black": 14, "block": [23, 25, 26, 29], "bo": [13, 18, 27], "boh": 18, "boh_idx": 18, "boilerpl": 1, "bool": [2, 18, 19, 22, 23, 24, 25, 26, 27, 28, 30, 33, 35, 40], "boolean": [23, 37], "bos_idx": 18, "both": [0, 1, 5, 8, 10, 12, 17, 20, 23, 24, 25, 26, 30, 33, 34, 36], "boundari": [23, 30], "branch": 14, "brew": [6, 7], "broadcast": [5, 23, 37], "broadcast_flag": 23, "broadcast_object": 23, "broader": 12, "browser": 14, "budget": 12, "buffer": [25, 26, 28], "bug": 14, "build": [6, 8, 11, 14, 20, 29], "build_typ": 7, "builder": 1, "built": [0, 1, 2, 3, 5, 7, 14, 20], "byte": 32, "bytes_or_buff": 28, "c": [6, 7, 8, 9, 12, 14, 17], "cach": [0, 8, 12, 15, 18, 19, 32], "calcul": 5, "call": [5, 20, 22, 23, 25, 26, 32, 38, 40], "callabl": [31, 33, 34, 35], "caller": [2, 23, 24, 38], "can": [0, 1, 2, 3, 5, 7, 8, 10, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 34, 38, 39, 40], "cannot": [25, 26], "capabl": [3, 9, 12, 24], "capac": 32, "capacity_byt": 32, "capacity_incr": 32, "capit": 28, "card": [2, 12, 18, 19, 21, 25, 27, 38], "care": 30, "carefulli": 14, "case": [7, 9, 10, 20, 32], "cast_fp32": 33, "catalog": 15, "caus": [23, 24, 25, 26, 34], "cc": 14, "cd": [6, 7, 8, 14], "cento": 6, "central": [0, 2, 19, 21], "certain": [25, 26], "chain": 17, "chang": [5, 8, 9, 12, 14, 22, 25, 26, 32], "channel": 23, "chatbot": 1, "check": [0, 1, 8, 9, 12, 23, 24, 38], "checkabl": 40, "checkpoint": [0, 1, 2, 5, 9, 11, 24, 25], "checkpoint_path": [24, 25, 26, 28], "chicken": 27, "choic": 28, "choos": [10, 14], "chosen": 10, "chunk": [1, 2], "ci": 8, "cl": 0, "cla": 14, "clang": 14, "class": [5, 17, 20, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40], "classmethod": [0, 23], "classvar": 30, "clean": [2, 5, 8], "clear": [0, 1, 2, 8, 14, 40], "clearer": 12, "cli": 1, "clip": 43, "clone": [6, 14], "closabl": 23, "close": [5, 23], "cluster": [0, 7, 10, 20], "clusterscop": 8, "cmake": [7, 14], "cmake_cuda_architectur": 7, "cmakelist": 7, "code": [0, 1, 2, 3, 5, 7, 8, 9, 12, 14, 15, 16, 22, 25, 26, 27, 28, 41, 42, 43, 44], "codebas": 3, "coeffici": [27, 28, 34], "cohes": 5, "collat": 17, "collect": [0, 2, 5, 23, 24, 39], "com": [0, 6, 7, 8, 9, 10, 14], "combin": [5, 6, 23], "come": [0, 15, 16, 17, 41, 42, 43, 44], "command": [0, 1, 6, 7, 8, 9, 10, 14, 18], "comment": 0, "commit": [0, 6, 14], "common": [1, 20, 38, 44], "commonsect": 1, "commun": [5, 12, 23], "companion": 20, "compar": 28, "comparison": [5, 30], "compat": [6, 8, 9, 14, 24, 25, 26, 30], "compil": [1, 7, 12], "compiled_max_seq_len": 30, "complet": [1, 3, 7, 8, 14], "complex": [1, 2, 5, 14, 19, 20, 23, 24], "compon": [0, 1, 3, 9, 39], "compos": 2, "composit": [0, 1, 2, 3, 11, 20, 40], "comprehens": [17, 30], "comput": [1, 5, 7, 10, 23, 30, 42], "compute_loss": 23, "compute_row_mask": 37, "concaten": [23, 24], "concept": [2, 38], "concern": 8, "concret": [2, 18, 19, 21, 28], "conda": [7, 8], "condit": 12, "config": [0, 1, 3, 7, 8, 9, 10, 18, 19, 20, 21, 25, 26, 27, 28, 38, 39, 40], "config_kl": [1, 3, 19, 21, 25, 26, 39], "config_registri": 3, "config_yaml": 10, "configregistrar": 3, "configur": [2, 7, 10, 12, 18, 19, 20, 21, 23, 24, 25, 26, 38, 39, 40, 41, 43, 44], "conflict": [7, 8], "connect": [9, 10, 36], "consequ": 5, "consid": 34, "consist": [0, 1, 9, 12, 14, 23, 30], "consolid": [5, 12, 30], "constant": 36, "constrain": [25, 26], "construct": [2, 18, 23, 28], "constructor": 2, "consult": 7, "consum": 17, "contain": [1, 2, 3, 5, 14, 20, 22, 23, 24, 25, 26, 27, 31, 38, 39], "content": [11, 25, 26, 27], "context": [0, 1, 5, 22, 23], "contigu": 23, "continu": 12, "continue_process": 23, "contract": [2, 18], "contrast": 5, "contribut": [7, 11, 23, 31], "control": [0, 1, 12, 18, 28], "conveni": [0, 7, 9, 25, 26], "convent": [9, 14], "convers": [23, 24], "convert": [1, 12, 24, 28, 39], "coordin": 5, "copi": [2, 23, 34], "core": [1, 3, 17, 29], "cornerston": 30, "correct": [24, 39], "correctli": [5, 9, 40], "correspond": [5, 20, 24, 27, 28, 31, 32, 39], "cost": 22, "could": 20, "coupl": 2, "cover": [9, 14], "coverag": 12, "cpu": [5, 6, 8, 10, 14, 22, 23, 30, 37], "crash": [6, 14], "creat": [3, 7, 8, 14, 18, 19, 21, 23, 25, 26, 27, 28, 29, 31, 37], "create_decod": [18, 19, 28], "create_decoder_frontend": 28, "create_decoder_lay": 28, "create_default_process_group": [5, 23], "create_embed": 28, "create_encod": [18, 19, 27, 28], "create_fake_gang": 23, "create_ffn": 28, "create_final_project": 28, "create_fsdp_gang": [5, 23], "create_gang": 23, "create_layer_norm": 28, "create_model": 28, "create_my_custom_model": [1, 3], "create_my_optim": 39, "create_new_model": [9, 25, 26, 28], "create_parallel_gang": [5, 23], "create_position_encod": 28, "create_raw_encod": [18, 28], "create_read": [1, 20], "create_self_attent": 28, "create_train": 1, "creation": [0, 20], "critic": [2, 17], "cross": 27, "csv": 17, "csvdataset": 17, "cu124": [6, 8], "cu126": 6, "cu128": [6, 7, 8, 14], "cuda": [5, 8, 14, 22, 23, 30], "cuda_arch": 7, "cuda_vers": 7, "cuda_visible_devic": 22, "cudacontext": 22, "curl": 8, "current": [0, 5, 22, 23, 24, 32], "current_gang": [5, 23], "custom": [1, 3, 8, 9, 11, 12, 18, 19, 21, 25, 27, 33, 44], "custom_dataset": [1, 3, 20, 21], "custom_load": [1, 3], "custom_model": 9, "custom_open": [1, 3, 20], "custom_path": [18, 19], "custom_qwen": 0, "custom_token": [1, 3, 18, 19], "customdataset": [1, 3, 20], "customdatasetconfig": [1, 3, 20], "customiz": 1, "customtoken": [1, 3], "customtokenizerconfig": [1, 3], "cut": 12, "cxx": 14, "d0": [5, 23], "d1": [5, 23], "d2": [5, 23], "d3": [5, 23], "d4": [5, 23], "d5": [5, 23], "d6": [5, 23], "d7": [5, 23], "data": [0, 1, 8, 11, 20, 21, 23, 24, 25, 26, 27, 28, 29, 33, 35], "data_read": 1, "dataclass": [0, 1, 20, 39, 40], "dataload": 17, "datapipelin": [1, 17], "datapipelineread": 1, "dataread": [1, 20], "dataset": [3, 5, 11, 12, 17, 19, 26, 38], "dataset_config": [0, 20], "dataset_famili": [0, 20], "datasetconfigt": 21, "datasetfamili": 21, "datasetsect": 1, "datasett": 21, "date": 14, "dclm": 12, "dcmake_build_typ": 7, "dcmake_cuda_architectur": 7, "dcp": 12, "ddp": 23, "de": [18, 28], "deadlock": 10, "debian": 6, "debug": [1, 5, 11, 23, 41], "decai": [27, 28, 34], "decid": 10, "decis": [23, 25, 26], "declar": 5, "decod": [18, 19, 25, 26, 27, 28, 32, 34], "decode_from_token": 18, "decor": [2, 9], "def": [0, 1, 2, 3, 5, 9, 20, 30, 38, 39, 40], "default": [0, 1, 2, 3, 5, 7, 8, 14, 22, 23, 25, 26, 27, 28, 39], "default_dataset": 1, "default_devic": 22, "default_encod": 27, "default_factori": [0, 1, 39], "defin": [0, 2, 8, 9, 18, 20, 23, 24, 25, 26, 28, 34, 38], "definit": [0, 20], "deleg": [24, 25, 26], "delegatingmodelcheckpointload": 24, "delet": 24, "demand": 2, "demonstr": [0, 2], "denomin": 33, "denot": [5, 23], "dens": 12, "dep": 7, "depend": [0, 1, 3, 5, 6, 8, 9, 12, 14, 20, 38, 39], "dependencycollectioncontain": 2, "dependencycollectionresolv": 2, "dependencycontain": [0, 1, 2, 3, 20, 38, 39], "dependencyprovid": 2, "dependencyresolv": [2, 20, 39], "deploi": 0, "deploy": 0, "deprec": [24, 25, 26], "depth": 27, "deriv": 40, "describ": [0, 7, 9, 14, 18, 20, 27, 33, 34], "descript": [0, 14], "deseri": [24, 25, 26], "design": [0, 1, 3, 5, 8, 9, 10, 11, 12, 17, 30], "desir": [6, 7], "destroi": 23, "destroy_process_group": 5, "detail": [0, 1, 3, 19], "detect": [0, 24], "determin": [5, 22, 24, 25, 26, 39], "determinist": [2, 12], "dev": [7, 8], "devel": [6, 7, 14], "develop": [0, 6, 7, 8, 9, 11, 12, 15, 16, 41, 42, 43, 44], "deviat": 27, "devic": [2, 5, 7, 11, 14, 18, 23, 25, 26, 28, 30, 31, 33, 34, 35, 37], "device_count": 22, "device_mesh": 5, "device_typ": 22, "dfairseq2n_perform_lto": 7, "dfairseq2n_python_devel": 7, "dfairseq2n_run_clang_tidi": 14, "dfairseq2n_sanit": 7, "dfairseq2n_treat_warnings_as_error": 7, "dfairseq2n_use_cuda": 7, "di": 2, "diagram": [2, 34], "dict": [1, 22, 24, 28, 39], "dictionari": [24, 28, 31], "did": 27, "differ": [0, 2, 7, 9, 18, 20, 23, 24, 25, 26, 27, 28, 30], "dim": [24, 28, 30], "dimens": [5, 9, 23, 24, 27, 28, 31, 33, 34, 35, 37], "dimension": [5, 9, 27, 28, 31, 34, 35, 36], "dir": [0, 1, 7, 18, 19, 20], "direct": [0, 5, 9, 25, 26], "directli": [12, 18, 19, 25, 26], "directori": [0, 1, 7, 14, 27, 38], "disabl": [8, 25, 26], "discov": [19, 21, 26], "discover": 12, "discoveri": [0, 25, 26], "disk": 12, "dist": 5, "distinct": 5, "distinguish": [18, 28], "distribut": [1, 5, 7, 12, 23, 24, 25, 26, 28], "divers": 2, "dnf": [6, 7], "do": [1, 14], "doc": [8, 10, 14, 18], "docstr": 14, "document": [0, 4, 7, 8, 12, 15, 16, 17, 19, 21, 26, 38, 41, 42, 43, 44], "doe": [5, 6, 22, 23, 25, 26, 32, 38, 39], "doesn": [25, 26], "don": 20, "done": 18, "download": [0, 7, 8, 12, 15, 18, 19, 25, 26], "dp": [5, 23, 24], "dp_gang": 5, "dp_idx": 24, "dp_mesh": 5, "dp_rank": 24, "dp_size": [5, 24], "driven": 12, "dropout": [0, 9, 25, 26, 27, 28], "dropout_p": [0, 9, 27, 28], "dtensor": 5, "dtype": [23, 25, 26, 31, 33, 34, 35], "due": [7, 23, 25, 26, 37], "dummi": 0, "dump": 1, "duplic": [2, 23], "dure": [5, 12, 16, 23, 24, 30, 31, 32], "dynam": [0, 12, 30], "e": [0, 2, 5, 6, 7, 8, 9, 10, 12, 13, 14, 20, 21, 23, 24, 25, 26, 27, 28, 31, 33, 34, 38, 39, 40], "each": [1, 2, 5, 8, 9, 23, 24, 25, 26, 30, 31, 37, 38, 39, 40], "earlier": 1, "eas": 12, "easi": [0, 1, 5, 9, 14], "easier": [12, 30], "easili": 8, "echo": [0, 10], "ecosystem": 12, "edit": [6, 8, 14], "edouard": 13, "effect": [7, 37], "effici": [1, 12, 13, 17, 23, 24, 25, 26, 29, 30], "either": [5, 20, 38], "element": [18, 30, 34, 37], "elementwise_affin": 33, "elimin": [1, 5], "els": [1, 5, 30], "emb": [28, 31], "embed": [9, 11, 13, 27, 28, 29, 34], "embed_dim": 31, "empti": [7, 23, 40], "en": [18, 28], "enabl": [2, 12, 22, 23, 24], "encapsul": 5, "encod": [2, 18, 19, 27, 28, 34], "encode_as_token": 18, "encoder_decoder_attn": 2, "encoder_decoder_attn_layer_norm": 2, "encoding_dim": 34, "end": [0, 5, 7, 18, 23, 27], "end_header_id": 27, "end_of_text": 27, "enforc": 14, "enhanc": [10, 12, 13], "ensur": [2, 8, 9, 10, 14, 23, 40], "entir": [5, 9, 12, 14, 24], "entri": [0, 3, 9, 25, 26], "entry_point": 0, "env": [5, 10], "environ": [3, 5, 8, 10, 22, 23, 25, 26], "eo": [18, 27], "eoh": 18, "eoh_idx": 18, "eos_idx": 18, "eos_token": 28, "eot_id": 27, "ep": 33, "equal": 23, "eric": 13, "error": [1, 8, 23, 25, 28, 40], "especi": 12, "essenti": [0, 2, 39], "et": [27, 33, 34], "etc": [0, 2, 5, 8, 9, 10, 20, 25, 26], "eval": 28, "evalrecip": 20, "evalu": [0, 12, 17, 42], "even": 34, "everi": [5, 23, 32], "everyth": [1, 5, 24], "ex": 40, "exactli": [6, 14], "exampl": [0, 1, 2, 7, 8, 10, 12, 15, 16, 19, 20, 21, 23, 24, 25, 30, 31, 33, 34, 37, 38, 39, 41, 42, 43, 44], "exce": [22, 34], "except": [0, 9, 40], "exclud": 40, "exclus": 8, "execut": [1, 23], "exist": [0, 7, 8, 12, 24, 25, 26, 30], "expand": [12, 30], "expandus": 1, "expect": [2, 10, 14, 25, 26, 32, 34], "expens": 2, "experi": [6, 10, 14], "experiment": [5, 8, 23], "explain": [8, 10], "explan": 10, "explicit": [5, 8], "explicitli": 5, "explor": [2, 10], "export": [3, 28], "expos": [9, 12, 22, 26, 28, 40], "extend": 3, "extens": [0, 2, 11, 12, 20], "extensionerror": 3, "extra": [0, 3, 6, 7, 8, 14, 33, 38], "extra_path": [0, 1, 20, 38], "extra_repr": 33, "extract": [5, 17], "f": [0, 1, 2, 5, 8, 9, 18, 19, 21, 23, 25, 26, 28, 30, 40], "face": [0, 14, 24, 28], "facebook": [0, 14], "facebookresearch": [6, 7, 8, 14], "factor": [27, 36], "factori": [1, 3, 19, 21, 22, 27, 39], "fail": [3, 7, 9, 23], "failur": [14, 23], "fair": [6, 7, 8, 14], "fairseq2": [0, 1, 2, 3, 6, 8, 9, 12], "fairseq2_asset_dir": [0, 20], "fairseq2_cache_dir": 0, "fairseq2_devic": 22, "fairseq2_ext": 0, "fairseq2_extension_trac": 3, "fairseq2_no_progress": [25, 26], "fairseq2_user_asset_dir": [0, 20], "fairseq2n": [8, 14], "fairseq2n_use_cuda": 7, "faisal": 13, "fake": [5, 23], "fakegang": [5, 23], "fallback": 0, "fals": [2, 8, 9, 18, 22, 23, 24, 25, 26, 27, 28, 30, 33], "famili": [0, 1, 3, 18, 19, 20, 21, 25, 28], "familiar": [7, 9, 10], "family_nam": [19, 21, 25, 26], "fast": 8, "fault": 5, "favicon": 8, "featur": [2, 5, 8, 10, 12, 14, 17, 30, 34], "fedora": [6, 7], "feed": [2, 9, 25, 26, 27, 28], "feedforwardnetwork": [2, 28], "few": 1, "ffn": 2, "ffn_inner_dim": [9, 27, 28], "ffn_inner_dim_multiple_of": 27, "ffn_inner_dim_multipli": 27, "ffn_inner_dim_scal": 27, "ffn_layer_norm": 2, "field": [1, 26, 39, 40], "field1": 40, "field2": 40, "file": [1, 3, 10, 12, 14, 17, 20, 24, 25, 26, 27, 38], "file_rank": 1, "file_system": 24, "file_world_s": 1, "filenotfounderror": [25, 26], "filesystem": [0, 24], "fill_valu": [30, 37], "final": [0, 1, 2, 7, 19, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 40], "find": [0, 9, 40], "fine": [0, 12], "first": [1, 2, 3, 5, 7, 9, 12, 20, 23, 24, 34, 39], "fit": 24, "fix": [31, 34], "flag": 23, "flake8": 14, "flash3": 12, "flexibl": [0, 1, 3, 12, 17, 20], "float": [23, 27, 28, 33, 34, 36, 37, 39], "float32": 23, "fly": 24, "focu": 1, "focus": [1, 9, 12], "follow": [0, 2, 6, 7, 10, 12, 14, 20, 22, 24, 25, 26, 40], "foo": [0, 40], "foo1": 0, "foo2": 0, "fooconfig": 40, "footprint": 24, "forg": 7, "fork": [2, 14], "form": [0, 7, 14, 24], "format": [0, 1, 8, 9, 12, 17, 20, 24, 25, 26, 27, 28, 40, 41], "formatt": 7, "formatted_text": 27, "formula": 28, "forward": [2, 9, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36], "found": [0, 1, 7, 18, 19, 21, 25, 26], "foundat": [8, 12, 13], "four": 1, "frac": [31, 35], "framework": [1, 2, 5, 12, 13], "franc": 28, "free": [0, 8], "freqs_init_fn": 34, "frequenc": [27, 34], "frequent": 32, "fresh": [8, 25, 26], "from": [0, 1, 2, 3, 6, 8, 9, 10, 12, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 34, 35, 37, 38, 39, 40], "from_embed": 31, "from_path": 0, "fs2_build_wheel": 7, "fs2_state_dict": 28, "fsdp": 23, "full": [1, 12, 14, 24, 25, 26, 30], "fulli": [5, 12, 23, 30], "function": [1, 3, 9, 10, 18, 20, 21, 30, 31], "furo": 8, "further": [5, 12], "futur": [12, 18, 19, 22, 27, 28], "g": [0, 2, 5, 6, 7, 9, 10, 12, 14, 20, 23, 24, 25, 26, 27, 28], "gang": [1, 11, 24, 25, 26, 28, 31], "gangerror": 23, "gangsect": 1, "gather": 23, "gautier": 13, "gener": [0, 5, 7, 11, 12, 18, 19, 21, 25, 26, 27, 28, 37], "generationrecip": 20, "generic_instruct": 0, "geoffrei": 13, "germani": 28, "get": [1, 5, 9, 10, 12, 14, 18, 20, 21, 26, 27, 28, 30, 32], "get_arch": [9, 25, 26, 28], "get_arch_config": [9, 25, 26, 28], "get_asset_stor": [0, 25, 26], "get_current_devic": 22, "get_dataset_config": 21, "get_default_devic": [5, 22, 25, 26, 28, 30], "get_default_dtyp": [25, 26], "get_dependency_resolv": 2, "get_device_properti": 22, "get_group": 5, "get_llama_model_hub": [26, 27], "get_llama_tokenizer_hub": 27, "get_mistral_model_hub": 26, "get_model_config": [25, 26], "get_my_dataset_hub": 21, "get_my_model_hub": [25, 26], "get_qwen_model_hub": [9, 25, 26, 28], "get_qwen_tokenizer_hub": [18, 19], "get_rank": [5, 10], "get_shard_dim": 31, "get_sharding_dim": 24, "get_start_lr": 39, "get_std_scale_factor": 28, "get_tokenizer_config": [18, 19], "get_world_s": 5, "getdefaultencod": 28, "git": [6, 7, 8, 14], "github": [6, 7, 8, 10, 14], "give": 12, "given": [9, 23, 24, 28], "glob": 1, "global": [2, 5, 19], "gloo": [5, 23], "gninja": [7, 14], "go": 1, "goal": 2, "gomez": 13, "goyal": 13, "gpu": [1, 5, 7, 8, 10, 14, 23, 30], "gqa": [9, 28], "grace": 1, "gradient": [31, 43], "gradual": 5, "grain": 12, "graph": [2, 40], "grave": 13, "greater": [12, 37], "greatli": 5, "grep": 9, "group": [0, 1, 5, 8, 9, 12, 23, 27, 28, 39], "group_config": 39, "guarante": [5, 37], "guid": [5, 8], "guidanc": 12, "guidelin": 14, "guillaum": 13, "h": 33, "h_": 35, "ha": [2, 6, 7, 12, 14, 18, 23, 26, 32, 40], "hambro": 13, "handl": [1, 2, 9, 12, 18, 19, 22, 23, 24, 25, 27, 28, 30, 34], "handler": 28, "hang": 10, "hardwar": 8, "has_error": 40, "hash": [6, 14], "hashabl": 2, "have": [0, 2, 6, 7, 9, 10, 12, 14, 20, 23, 31, 34, 40], "haven": 14, "head": [9, 27, 28, 30], "head_dim": [9, 28], "header": [18, 27], "hello": 27, "help": [12, 18, 27], "helper": [1, 5, 18, 23, 38, 39, 40], "henri": 13, "here": [1, 3, 9, 10, 14, 18, 20, 22, 23], "hf": [12, 18, 19], "hf_state_dict": 28, "hg": [0, 9, 12, 27], "hide": 30, "high": [5, 12, 17, 19, 23, 25, 26], "high_prior": 23, "hinton": 13, "hold": [23, 27, 32, 34, 40], "home": 0, "homebrew": 7, "host": [7, 10, 23], "hostnam": 10, "hot": 22, "hour": 14, "how": [0, 1, 2, 3, 7, 8, 9, 10, 14, 18, 23, 24], "howev": 7, "hsdp": 23, "html": 14, "http": [0, 6, 7, 8, 10, 13, 14], "hub": [0, 8, 11, 12, 15, 18, 20, 24, 25, 27, 28], "hug": [0, 24, 28], "huggingfac": [18, 19], "huggingfaceexport": 28, "huggingfacetokenmodel": 28, "hugo": 13, "hybrid": [5, 23], "hyperparamet": 44, "i": [1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "icanon": 10, "id": 1, "idea": 2, "ideal": 14, "ident": 35, "identifi": [0, 1, 28], "ignor": [25, 26, 33], "illia": 13, "illustr": 2, "immedi": [6, 14], "impl": 27, "implement": [5, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 33, 34, 35, 37, 40], "implementor": [19, 21, 26], "implicit": 5, "import": [0, 1, 2, 3, 5, 8, 9, 10, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 34, 37, 38, 39, 40], "impos": 22, "improv": [1, 2, 12], "includ": [0, 2, 3, 5, 10, 12, 14, 15, 16, 17, 23, 27, 28, 29, 34, 37, 41, 42, 43, 44], "incom": 33, "incompat": [8, 25, 26], "increas": 27, "increment": [32, 34], "increment_step_nr": 32, "incremental_st": [11, 29], "incrementalst": 32, "incrementalstatebag": [32, 34], "independ": 20, "index": [6, 7, 8, 11, 14, 18, 22, 27, 30, 31, 40], "index_select": 32, "indic": [0, 5, 18, 23, 28, 31, 38, 40], "individu": [1, 5, 12, 23, 30, 39], "induc": 10, "infer": [5, 17, 27, 28, 32], "inference_mod": 28, "inform": [0, 1, 3, 5, 7, 9, 18, 22, 23, 24, 28, 31, 32, 33, 34], "init": [7, 8], "init_device_mesh": 5, "init_fairseq": [25, 26], "init_fairseq2": [0, 2, 3], "init_fn": [31, 33, 35], "init_scaled_embed": 31, "init_std": 27, "init_std_scal": 27, "initi": [1, 2, 5, 8, 9, 23, 25, 26, 27, 31, 33, 34, 35, 36, 39], "inject": [1, 3, 12, 20], "inner": [9, 24, 27, 28], "inp": 35, "input": [1, 5, 9, 23, 27, 28, 31, 32, 33, 34, 35, 36, 37], "input_batch": 1, "input_dim": 35, "input_tensor": 23, "insert": 10, "inspect": [2, 9, 12, 24, 25], "instal": [8, 9, 10, 11, 14], "instanc": [1, 2, 3, 5, 7, 19, 20, 21, 23, 25, 26, 28, 31, 35, 39], "instanti": [5, 25, 26, 28], "instead": [2, 7, 12, 22, 23, 24, 25, 26, 27, 34], "instruct": [0, 6, 7, 9, 10, 14, 22, 27], "int": [18, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40], "integ": [9, 23, 40], "integr": [2, 14, 17, 20], "intend": 38, "intent": 40, "inter": [5, 23], "interact": [0, 20, 22], "interchang": 2, "interest": 14, "interfac": [1, 5, 9, 10, 18, 25, 26, 30], "intermedi": 24, "intern": [12, 19, 23, 33, 34, 36], "internet": 9, "intra": [5, 23], "intra_node_s": [5, 23], "introduc": [1, 2], "intuit": 12, "invalid": 3, "invalid_arch": 26, "invalidoperationerror": 23, "invok": [10, 38], "involv": 24, "is_avail": [8, 22], "is_dir": 1, "isinst": 39, "isol": 7, "isort": 14, "issu": [0, 6, 7, 8], "item": 23, "iter": [2, 19, 21, 24, 25, 39], "iter_card": [18, 19, 21, 25, 26], "iter_checkpoint": [25, 26], "iter_kei": 2, "its": [2, 3, 7, 18, 23, 24, 25, 26, 31, 39, 40], "izacard": 13, "jakob": 13, "jami": 13, "jepa_vith16": 0, "jepa_vith16_384": 0, "jepa_vitl16": 0, "jianlin": 13, "jimmi": 13, "job": [5, 10, 12], "joke": 27, "jone": 13, "joulin": 13, "json": [17, 27], "jsondataset": 17, "jsonl": [1, 17], "jupyt": 8, "just": [1, 5, 14], "k": 35, "k_norm": 28, "kaiser": 13, "keep": [0, 32], "kei": [0, 2, 9, 12, 17, 24, 26, 27, 28, 30, 40], "kernel": 7, "key_padding_mask": 30, "kind": [0, 8, 9, 18], "kiro": 13, "kl": [1, 2, 3, 19, 21, 25, 26, 32], "know": 0, "known": [25, 26], "kw_onli": 1, "kwarg": [2, 23, 33, 36, 40], "l": [0, 7, 10], "la": 0, "lab": 8, "lachaux": 13, "lacroix": 13, "lambda": 1, "lampl": 13, "lang": [18, 28], "languag": [1, 9, 11, 12, 13, 18, 27, 28], "larg": [2, 12, 17, 24], "larger": [14, 38], "last": [33, 34, 35], "later": [5, 23], "latest": [8, 14], "launch": 10, "lavril": 13, "layer": [0, 2, 5, 9, 13, 25, 26, 27, 28, 29, 33], "layer_idx": 28, "layernorm": [2, 28, 33], "layout": [1, 29, 30, 37], "lazi": 24, "lazili": [24, 25, 26], "lazy_load": 24, "learn": [0, 1, 3, 5, 7, 9, 10, 13, 17, 28, 33, 34, 38, 39, 43, 44], "learnedpositionencod": [2, 34], "least": 37, "legaci": 8, "lei": 13, "len": 39, "length": [0, 9, 17, 23, 27, 28, 30, 32, 34, 36, 37, 39], "less": [22, 38], "let": [1, 9], "level": [17, 19, 20, 25, 26, 39], "leverag": 12, "librari": [2, 7, 14, 25, 26], "librilight": 20, "libsndfil": [6, 7], "libsndfile1": 6, "lightweight": 12, "like": [5, 6, 7, 14, 18, 19, 23, 25, 26, 37, 40], "line": [1, 9, 18, 33], "linear": 35, "link": 9, "lint": 8, "linter": 7, "linux": 7, "list": [0, 1, 8, 9, 19, 21, 23, 24, 25, 26, 28, 30, 31, 39, 40], "listen": 10, "liter": 27, "liu": 13, "ll": 9, "llama": [0, 9, 11, 12, 13, 25], "llama2": 0, "llama2_13b": 0, "llama2_13b_chat": 0, "llama3": 27, "llama3_1_8b_instruct": 2, "llama3_2_1b": [9, 27], "llama3_2_1b_instruct": [1, 27], "llama3_70b": 9, "llama3_8b": [0, 9, 26], "llama3_8b_instruct": 0, "llamaropescaleconfig": 27, "llion": 13, "llm": [0, 10], "lm": [1, 10], "lm_train_dataset": 1, "lmtrainconfig": 1, "lmtraindataset": 1, "lmtraindatasetconfig": 1, "lmtraindatasetsect": 1, "lmtrainrecip": 1, "lmtrainunit": 1, "load": [0, 1, 5, 7, 12, 15, 16, 17, 19, 21, 24, 25, 27], "load_custom_model": [9, 25, 26, 28], "load_custom_token": [18, 19, 27], "load_model": [2, 8, 9, 25, 27, 28], "load_token": [18, 27, 28], "loader": [0, 1, 2, 3, 17, 24], "local": [0, 5, 8, 10, 18, 19, 20, 23], "local_loss": 23, "local_rank": 22, "localhost": 14, "localrankoutofrangeerror": 22, "locat": [0, 9, 20, 38], "log": [1, 3, 11], "logic": [1, 5, 9, 24, 25, 26], "long": [27, 28, 32, 34], "longer": [12, 34], "look": [0, 9, 40], "lookup": 12, "loos": 2, "loss": [1, 23], "low": [25, 26], "lower": 37, "lr": 39, "lr_schedul": 1, "lrschedulersect": 1, "lssf": 8, "lto": 7, "lu": 13, "lukasz": 13, "m": [0, 1, 7, 8, 9, 10, 14, 18, 28, 32, 36], "machin": [0, 7, 10, 17, 44], "maco": 7, "made": [14, 25, 26], "mai": [9, 12, 23, 24, 25, 26, 30], "main": [0, 1, 5, 9, 10, 14, 18, 19, 21, 26], "maintain": [3, 5, 24], "major": [2, 5, 12], "make": [0, 2, 7, 9, 12, 14, 20, 23, 30, 40], "manag": [0, 1, 2, 3, 5, 7, 8, 15, 16, 19, 20, 21, 22, 23, 44], "mani": 12, "manual": [5, 7, 40], "manylinux_2_28_": 7, "map": [0, 1, 5, 24, 25, 26, 40], "mari": 13, "mark": 30, "marker": 27, "martinet": 13, "masked_batch": [30, 37], "masked_fil": 30, "match": [0, 6, 7, 8, 9, 14, 20, 25, 26, 32, 39], "mathcal": [31, 35], "matter": 1, "max": [23, 30], "max_len": 30, "max_length": 0, "max_mask_prob": 37, "max_num_step": 32, "max_seq_len": [0, 9, 26, 27, 28, 30, 34], "maxim": 1, "maximum": [9, 27, 28, 32, 34], "maybe_get_arch_config": [25, 26], "maybe_get_current_gang": [5, 23], "maybe_get_st": 32, "maybe_raise_param_group_length_error": 39, "me": 27, "mean": [2, 5, 6, 13, 14, 23, 27, 33], "meaning": 0, "meant": [24, 25, 26], "meantim": [15, 16, 41, 42, 43, 44], "mechan": 20, "mel": 17, "memori": [1, 17, 18, 23, 24, 25, 26, 28, 30], "memory_stat": 22, "mermaid": 8, "mesh": 5, "mesh_dim_nam": 5, "messag": [0, 24, 27, 40], "meta": [0, 10, 25, 26, 27], "metadata": [0, 9, 15, 16, 25, 26, 30], "meth": 1, "method": [1, 2, 5, 9, 18, 19, 21, 23, 25, 26, 27, 32, 33, 38, 40], "metric": [1, 11], "metric_bag": 1, "metricbag": [1, 12], "mfcc": 17, "michael": 13, "might": [6, 14, 22], "mileston": 12, "min": [12, 23, 30], "min_num_span": 37, "min_seq_len": 30, "minim": [1, 2, 5, 24, 25, 26], "minut": 23, "mismatch": 8, "mistral": [0, 9], "mistral_7b": [9, 26], "mistral_8x7b": 9, "mix": 8, "mkdir": 8, "mlm": 37, "mmap": [24, 25, 26], "mock": 5, "mode": [7, 8, 12, 18, 28, 30, 32, 34], "model": [1, 2, 3, 8, 11, 13, 15, 16, 17, 19, 21, 23, 24, 29, 36, 38, 39], "model_arch": [0, 9, 26], "model_checkpoint": 11, "model_config": [0, 25, 26], "model_dim": [9, 27, 28], "model_famili": [0, 9], "modelarchitecturenotknownerror": [25, 26], "modelcheckpointerror": [24, 25, 26], "modelcheckpointload": 24, "modelconfigt": [25, 26], "modelfamili": [25, 26], "modelfamilynotknownerror": [25, 26], "modelhub": 25, "modelhubaccessor": 25, "modelnotknownerror": [9, 25, 26], "modelsect": 1, "modelt": [25, 26], "modern": 8, "modifi": [2, 3, 7, 9, 14, 23, 26, 28], "modul": [0, 1, 2, 3, 5, 7, 11, 12, 15, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44], "moham": 13, "monolith": 2, "more": [0, 1, 2, 3, 5, 7, 9, 10, 12, 14, 18, 20, 22, 23, 24, 26, 28, 30, 32, 38, 40], "most": [1, 5, 7, 9, 14, 20], "mqa": 9, "much": 1, "multi": [0, 5, 10, 24, 33], "multihead": 2, "multiheadattent": [2, 28, 30], "multilingu": [18, 28], "multipl": [0, 2, 5, 9, 18, 27, 32], "multipli": 27, "murtadha": 13, "must": [6, 7, 9, 14, 20, 23, 25, 26, 28, 32, 35, 37, 38, 40], "mutual": 8, "my": [0, 8, 9, 26, 28], "my_advanced_open": 20, "my_asset": 0, "my_clust": 0, "my_custom_arch_vari": 3, "my_custom_dataset": 0, "my_custom_llama": 0, "my_custom_model": [0, 1, 3], "my_data_family_nam": 21, "my_dataset": [0, 20, 21], "my_dataset_famili": 21, "my_extens": 3, "my_help": 38, "my_in_mem_sourc": 0, "my_model": [0, 9], "my_model_famili": [25, 26], "my_model_nam": 0, "my_optim": 39, "my_packag": [0, 3], "my_recipe_helper_funct": 38, "myclust": 20, "myconfig": 21, "mycustommodel": [1, 3], "mycustommodelconfig": [1, 3], "mydataset": [0, 20, 21], "mydatasetconfig": [0, 20, 21], "mylelrconfig": 39, "mymodel": [25, 26], "mymodelconfig": [25, 26], "myoptim": 39, "myoptimizerconfig": 39, "myoptimizergroupconfig": 39, "mypi": [8, 14], "myrecip": [0, 38], "myst": 8, "mytrainrecip": 39, "myvenv": 7, "n": [0, 13, 24, 31, 32, 34, 36, 37], "naman": 13, "name": [0, 1, 3, 7, 8, 9, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 38, 39, 40], "nativ": [5, 6, 7, 12, 14, 24], "nativemodelcheckpointload": 24, "navig": 9, "nbsphinx": 8, "nc": 10, "nccl": [5, 23], "nearest": 27, "necessari": [7, 9, 12, 25, 26], "need": [0, 1, 5, 9, 10, 12, 13, 14, 20, 25, 26, 30, 32], "network": [2, 9, 17, 23, 25, 26, 27, 28, 29, 43], "neural": [17, 29, 43], "new": [1, 2, 3, 5, 7, 8, 9, 14, 23, 24, 25, 26, 27, 28, 32, 39], "new_group": 5, "new_model": 9, "new_ord": 32, "newli": [9, 26], "next": 32, "nf": 12, "nightli": [6, 7, 14], "niki": 13, "ninja": 7, "nll_loss": 1, "nlp": 12, "nltk": 8, "nn": [11, 12, 17, 28], "no_progress": [25, 26], "noam": 13, "node": [5, 10, 23], "non": [5, 23, 40], "non_block": 22, "non_existent_dataset": 21, "none": [0, 1, 2, 3, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40], "nonexistent_model": 26, "noreturn": 23, "normal": [10, 11, 13, 28, 29], "normalized_shap": 33, "nosan": 7, "note": [7, 9, 20, 23, 25, 26, 37, 38, 39, 40], "notebook": 8, "notsupportederror": [23, 25, 26], "novel": 2, "now": [0, 12, 23], "ntask": 10, "num_attn_head": [9, 27, 28], "num_devic": 22, "num_embed": 31, "num_head": 30, "num_key_value_head": [9, 27, 28], "num_lay": [9, 25, 26, 27, 28], "num_param_group": 39, "num_step": 1, "num_warmup_step": 1, "number": [5, 9, 18, 22, 25, 26, 27, 28, 32, 34, 37, 39], "numel": 9, "numer": [12, 33], "nvidia": [7, 8], "o": 10, "obj": [2, 40], "object": [1, 2, 3, 5, 18, 19, 20, 22, 23, 25, 26, 27, 28, 30, 32, 37, 39, 40], "object_nam": 20, "objectvalid": 40, "observ": 14, "obtain": 10, "occur": [23, 40], "off": [7, 30], "offer": [5, 10, 12, 19, 21], "offlin": 12, "omit": [24, 25, 26], "onboard": 12, "onc": [1, 7, 10, 14, 24], "one": [2, 5, 7, 10, 14, 23, 24, 25, 26, 37, 38, 40], "ones": 5, "onli": [0, 1, 2, 5, 8, 9, 10, 12, 14, 20, 23, 24, 25, 26, 27, 30, 32], "onlin": [11, 12], "op": 23, "open": [0, 1, 3, 10, 13, 14, 21], "open_custom_dataset": [20, 21], "open_dataset": 21, "open_lm_train_dataset": 1, "open_my_dataset": 0, "oper": [5, 12, 17, 18, 22, 23, 26, 29, 30, 34], "operationalerror": 23, "optim": [1, 11, 17, 24, 30], "optimizersect": 1, "option": [0, 1, 8, 14, 20, 24, 38, 40], "orchestr": 2, "order": [0, 2, 14, 23, 24, 32, 39], "org": [7, 8, 9, 13], "organ": [0, 12], "other": [0, 1, 3, 5, 7, 9, 10, 15, 17, 20, 23, 25, 26, 28, 29, 43], "otherwis": [6, 14, 25, 26, 27, 28], "our": [1, 10, 11, 14], "out": [7, 14, 23, 24, 35, 38], "outer": 24, "output": [0, 1, 9, 23, 27, 28, 30, 32, 33, 35, 36], "output_dim": 35, "output_dir": 10, "output_tensor": 23, "outsid": 40, "over": [5, 12, 14, 23, 25, 31, 33], "overal": 12, "overhaul": 12, "overhead": 12, "overlap": 37, "overrid": [1, 5, 7, 20, 25, 26, 39], "overridden": [0, 20, 35], "overview": 26, "own": [1, 11, 18, 23, 26, 27, 28, 33], "p": [9, 10, 14], "pack": [1, 12, 30], "packag": [0, 3, 7, 8, 14], "packed_layout": 30, "packed_memori": 30, "pad": [12, 18, 27, 30, 37], "pad_idx": [18, 27, 31], "padded_layout": 30, "padded_memori": 30, "padding_mask": [30, 37], "page": 11, "pair": [24, 25, 26], "pan": 13, "pane": 10, "paper": [9, 34], "parallel": [1, 23, 24, 25, 26, 27], "param": [28, 39], "param_group": 39, "paramet": [1, 3, 5, 10, 18, 20, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39], "parametergroupconfig": 39, "parent": 0, "pariti": 12, "parmar": 13, "parquet": 17, "parquetdataset": 17, "pars": 1, "parser": 8, "part": [20, 23, 25, 26], "parti": [7, 12, 25, 26], "particular": [24, 25, 26], "particularli": 5, "partition": 12, "pass": [3, 5, 7, 14, 23, 25, 26, 30, 34, 39], "past": 2, "path": [18, 19, 20, 22, 24, 25, 26, 27, 28, 38], "pathlib": [0, 9, 18, 26, 27, 28], "pattern": [0, 1, 5, 24, 27], "pdb": 10, "peak": 24, "pedant": 14, "pep517": 7, "per": [0, 10, 23, 27], "perform": [1, 5, 17, 22, 23, 24, 25, 26, 41], "persist": 14, "person": 0, "pg": 5, "phase": 2, "philosophi": [1, 3, 5, 9, 10, 11], "pickl": [23, 24, 25, 26], "picklabl": 23, "pin": [1, 8, 18, 28], "pin_memori": [18, 28], "pip": [6, 8, 10, 14], "pipelin": [1, 5, 12, 23, 29, 44], "pkg": [6, 8, 14], "place": [14, 23], "plan": [7, 14], "plat": 7, "pleas": [0, 7, 10, 14, 15, 16, 24, 41, 42, 43, 44], "pluggabl": [1, 2], "point": [3, 5, 9, 23, 25, 26], "polosukhin": 13, "port": 10, "portion": [7, 14, 24], "pos_encod": [28, 34], "pos_indic": 30, "posit": [2, 9, 13, 27, 28, 32, 34, 40], "position_encod": [11, 29], "position_indic": [30, 37], "positionencod": [2, 28, 34], "possibl": [2, 14, 22, 25, 26], "post": 12, "post1": 8, "potenti": 20, "power": [1, 2], "pp": [5, 23], "practic": 24, "pre": [6, 7, 14, 15, 23, 28, 29, 44], "prealloc": 32, "preced": 22, "prefetch": 1, "prefix": 18, "prefix_indic": 18, "prepar": [23, 27, 28, 39], "prepare_parameter_group": 39, "preprocess": [1, 17], "prereleas": 8, "prerequisit": [9, 10], "present": 32, "preset": 9, "press": 10, "pretrain": [0, 1, 12, 25, 26], "pretrained_llm": [18, 19], "pretti": 14, "prevent": [8, 10, 12], "preview": 1, "previou": 32, "primari": [25, 26], "primarili": 38, "primarli": 40, "primit": [5, 23], "principl": [1, 2], "print": [0, 2, 5, 8, 9, 18, 19, 21, 23, 25, 26, 28, 30, 33, 40], "priorit": 14, "prioriti": 23, "probabl": [9, 25, 26, 27, 28, 37], "problem": 14, "procedur": 5, "proceed": 23, "process": [1, 5, 6, 8, 9, 10, 14, 22, 23, 24, 25, 26, 28, 29], "process_batch": [1, 30], "processgroup": 23, "processgroupgang": [5, 23], "produc": [24, 32], "product": [0, 8, 23], "program": 5, "programmat": 18, "progress": [4, 19, 25, 26, 38], "project": [3, 7, 9, 11, 14, 27, 28, 29], "prompt": 27, "prompt_encod": 27, "prompt_respons": 27, "proper": [1, 9, 34, 37], "properli": 9, "properti": [1, 2, 18, 23, 28, 30, 32, 40], "protocol": [2, 37, 40], "provid": [0, 1, 2, 3, 5, 7, 8, 9, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 39, 40, 41, 42, 43, 44], "pt": [0, 9, 12, 24, 26, 28], "pt2": [6, 8, 14], "pth": 24, "ptx": 7, "public": [14, 22], "publish": 14, "pudb": 11, "pure": 14, "purpos": [0, 5], "put": [3, 23], "py": [1, 3, 8, 9, 25, 26, 38], "pyarrow": 8, "pyproject": [3, 8], "pytest": [7, 8, 14], "python": [0, 1, 3, 8, 9, 10, 14, 17, 18, 23, 25, 26, 38], "python3": 7, "python_vers": 7, "pytorch": [2, 8, 9, 12, 14, 22, 23, 24, 30, 34, 39], "q": 10, "q_norm": 28, "qkv_proj_bia": [9, 28], "qualiti": [8, 12], "qualnam": 23, "queri": [0, 9, 27, 28], "quick": [1, 5, 9], "quickli": 12, "quit": 10, "qwen": [0, 9, 11, 12, 18, 19, 25], "qwen2": [0, 9, 28], "qwen25_0": 26, "qwen25_1": 26, "qwen25_14b": [9, 28], "qwen25_1_5b": 28, "qwen25_32b": 28, "qwen25_3b": [9, 26, 28], "qwen25_3b_instruct": 9, "qwen25_7b": [0, 25, 26, 28], "qwen25_7b_instruct": [0, 25, 26], "qwen3": [0, 18, 19, 28], "qwen3_0": [9, 18, 19, 28], "qwen3_1": 28, "qwen3_14b": 28, "qwen3_32b": 28, "qwen3_4b": 28, "qwen3_8b": [0, 9, 28], "qwen_checkpoint": 28, "qwen_config": [25, 26], "qwen_hf_checkpoint": 28, "qwen_model": [25, 26], "qwenconfig": [9, 25, 26], "qwentoken": [18, 19], "qwentokenizerconfig": [18, 19], "r": [6, 7, 14], "race": 12, "rais": [3, 19, 21, 22, 23, 24, 25, 26, 34, 38, 39, 40], "raise_operational_gang_error": 23, "randint": 31, "randn": [5, 30, 34, 37], "random": [9, 25, 26, 37], "random_mask": 37, "rang": [9, 12, 23], "rank": [1, 5, 10, 23, 24], "rate": [1, 39, 43], "rather": [5, 24, 25, 26], "raw": [18, 28], "rdp": [5, 23], "re": [9, 14, 24, 33], "reach": [10, 23], "read": [1, 5, 7, 12, 14, 20], "read_fil": 1, "read_sequ": 1, "readabl": [9, 14], "reader": 1, "readi": 1, "readm": 14, "real": [5, 7, 23], "rearrang": 32, "reason": [6, 7, 14], "receiv": 32, "recip": [0, 10, 11, 20, 40], "recipecontext": [1, 40], "recipemodel": [1, 39], "recipes1": 38, "recipes2": 38, "recogn": 9, "recommend": [7, 8, 20, 25, 26, 27], "recurs": [7, 20, 38], "reduc": [5, 12, 23, 24, 25, 26, 28], "reduceoper": [5, 23], "reduct": 23, "redund": 2, "refer": [1, 5, 9, 10, 15, 16, 18, 21, 26, 27, 28, 34, 41, 42, 43, 44], "refrain": 14, "regex": 27, "regim": 1, "regimesect": 1, "regist": [0, 1, 2, 3, 9, 19, 20, 21, 24, 25, 26, 38, 39], "register_compon": 39, "register_dataset_famili": [0, 1, 3, 20], "register_file_asset": [0, 3], "register_in_memory_asset": 0, "register_inst": 2, "register_model_famili": [1, 3], "register_package_asset": [0, 3], "register_recipe_asset": 38, "register_tokenizer_famili": [1, 3], "register_typ": 2, "registr": 9, "registri": [2, 15], "regular": [12, 25, 26], "reinstal": 8, "rel": [0, 20, 34, 38], "rel_path": 38, "relat": [0, 9], "relationship": 0, "releas": [6, 7, 12, 14], "relev": [0, 5, 12, 24], "reli": [5, 6, 14], "reliabl": 8, "remark": 1, "remov": [24, 25, 26], "reorder": 32, "replac": [6, 10], "replic": [5, 23, 24], "repo": [8, 10], "report": [14, 24, 42], "repositori": [0, 2, 14], "repr": [28, 40], "repres": [5, 12, 18, 22, 23, 24, 31, 35, 36, 38, 40], "represent": [13, 33], "reproduc": [8, 14], "request": [9, 12, 25, 26], "requir": [0, 5, 6, 7, 8, 9, 12, 14, 24, 30], "research": [2, 5, 11], "reserv": 32, "reset_non_persistent_buff": 34, "reset_paramet": [31, 33, 34, 35], "reset_peak_memory_stat": 22, "reshard": [12, 24], "reshard_tensor": 24, "residu": [11, 29], "residualconnect": 36, "resolut": [2, 8], "resolv": [1, 2, 8, 20, 27, 38, 39], "resolve_opt": 2, "resourc": [0, 2, 10], "respect": [2, 24, 34], "rest": [2, 23], "restart": [8, 9], "restrict": [24, 25, 26], "result": [23, 28, 30, 40], "resum": 16, "retrain": 12, "retriev": [2, 5, 20, 22, 23, 24], "retrieve_card": [0, 2, 25, 26], "return": [0, 1, 2, 3, 5, 9, 20, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 37, 39, 40], "reus": 7, "revers": 10, "review": 9, "revis": [12, 14], "rf": 8, "rico": 13, "rm": 8, "rmsnorm": 33, "road": 27, "robust": 12, "rodriguez": 13, "roform": 13, "role": 27, "root": [5, 7, 13, 14, 23, 25, 26, 33], "root_gang": [5, 23], "rope": 9, "rope_scal": 27, "rope_theta": [9, 27, 28], "rotari": [13, 27, 28], "rotaryencod": [2, 34], "round": 27, "row": 37, "row_len": 37, "rowmaskfactori": 37, "rozi\u00e8r": 13, "rst": 14, "ruff": 8, "run": [5, 6, 7, 8, 12, 14, 25, 26, 28], "runner": 2, "runtim": [0, 2, 11, 14, 20, 22, 25, 26, 38, 39, 40], "ryan": 13, "safe": [1, 24, 25, 26], "safetensor": [0, 9, 24], "safetensors_load": 24, "safetensorscheckpointload": 24, "safetensorsload": 24, "safeti": 1, "salloc": 10, "same": [0, 5, 6, 7, 9, 14, 23, 33, 34, 35, 36, 37], "sampl": 17, "sampler": 17, "sanit": 7, "save": [1, 12, 16, 25, 26, 30], "scalar": 23, "scale": [5, 27, 36], "scaledresidualconnect": 36, "scan": 38, "scatter": 5, "scenario": [5, 9, 23], "scene": 18, "schedul": [1, 39, 43], "scheme": [12, 25, 26], "scope": 14, "scratch": [7, 12], "screenshot": 10, "script": [3, 7], "scriptmodul": [33, 34, 36], "sdp": [5, 23], "seamless": [5, 12, 17, 20], "seamlessli": 30, "search": [0, 11, 32, 38], "second": [9, 23], "section": [1, 8, 20, 34], "see": [5, 7, 8, 9, 22, 23, 24, 25, 32], "segfault": [6, 14], "select": [1, 24, 32], "self": [0, 1, 2, 13, 20, 30, 38, 39, 40], "self_attn": 2, "self_attn_layer_norm": 2, "semant": 5, "sennrich": [13, 33], "sensibl": 1, "sentencepiec": [0, 18, 27], "separ": [0, 5, 8], "seq": [1, 30, 31, 34, 36, 37], "seq_begin_indic": 30, "seq_begin_indices_pt": 30, "seq_boundari": 30, "seq_len": [1, 30, 31, 34, 37], "seq_lens_pt": [30, 37], "seq_lens_tensor": 30, "seqs_layout": [1, 28, 34], "sequenc": [0, 1, 2, 11, 17, 18, 23, 24, 27, 28, 32, 33, 34, 36, 37, 39, 40], "sequencebatch": 1, "seri": 28, "serial": [24, 25, 26], "serv": [5, 12, 25, 26], "server": 14, "servic": 20, "session": [9, 10], "set": [0, 1, 2, 3, 5, 8, 9, 10, 12, 20, 22, 23, 25, 26, 27, 32, 38, 39, 40], "set_stat": 32, "set_trac": 10, "setup": [5, 6, 24], "setup_fs2_extens": 0, "setup_my_fairseq2": 0, "setup_my_fairseq2_extens": 3, "setuptool": [0, 3], "sever": [2, 5, 10, 27, 28], "sh": [7, 8], "shape": [18, 23, 26, 30, 31, 32, 33, 34, 35, 36, 37], "shard": [1, 5, 23, 24, 25, 26, 27, 31], "shard_dim": 24, "shard_embed_dim": 27, "shard_spec": [24, 28], "shardedembed": 31, "shardspec": [24, 28], "share": [9, 33, 34, 36], "shazeer": 13, "shell": 8, "shengfeng": 13, "short": [7, 12, 14], "shorter": 0, "should": [9, 12, 14, 23, 24, 27, 32, 33, 38, 40], "should_continu": 23, "show": [0, 1, 2, 3, 9, 10, 34], "showcas": 1, "shown": 7, "shuffl": 17, "shutdown": 1, "signific": 12, "significantli": [2, 12], "similar": [7, 12, 18, 23], "similarli": 7, "simpl": [1, 3, 5, 9, 20], "simpler": 30, "simplest": 7, "simpli": [6, 14], "simplif": 12, "simplifi": [1, 2, 12, 28], "simul": [5, 23], "sinc": [10, 14, 25, 26], "singl": [0, 1, 2, 5, 12, 22, 23, 24, 30, 33], "singleton": 2, "sinusoid": 34, "sinusoidalpositionencod": [2, 34], "size": [0, 5, 9, 10, 18, 23, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38], "size_byt": 32, "skeleton": 1, "skip_special_token": [18, 28], "slice": [5, 24], "slight": [22, 25, 26], "slower": [24, 25, 26], "slurm": 10, "smi": 8, "so": [1, 7, 38], "solid": 8, "solut": 5, "some": [9, 18, 19, 24, 25, 26, 27, 28], "some_condit": 23, "some_distributed_funct": 5, "some_object": 20, "soon": [11, 15, 16, 17, 41, 42, 43, 44], "sort": [1, 28], "sourc": [0, 1, 2, 6, 8, 10, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "source_rank": [5, 23], "source_shard_s": 24, "source_split": 24, "sp": 27, "sp_llama": 27, "span": 37, "span_len": 37, "special": [0, 12, 17, 24, 32], "special_tokens_map": 27, "specif": [1, 2, 5, 6, 7, 9, 12, 14, 19, 20, 21, 23, 24, 25, 26, 28, 37, 44], "specifi": [0, 1, 5, 8, 9, 10, 18, 22, 23, 24, 25, 26, 27, 28, 31, 37, 38, 39, 40], "spectrogram": 17, "speech": 13, "sphinx": [8, 14], "sphinxcontrib": 8, "split": [1, 5, 23, 24], "split_group": 23, "split_regex": 27, "spuriou": [6, 14], "sqrt": 35, "squar": [13, 33], "src": [5, 8, 9, 25, 26], "srun": 10, "stabil": [3, 33], "stack": [27, 38], "stack_level": 38, "stai": 12, "standalon": [3, 5, 25, 26], "standard": [0, 7, 10, 22, 23, 27, 28, 30, 31, 35, 40], "standardcudacontext": 22, "standardembed": 31, "standardlayernorm": 33, "standardobjectvalid": 40, "standardtransformerdecoderlay": 2, "start": [1, 2, 10, 12, 23], "start_header_id": 27, "start_lr": 39, "state": [5, 12, 23, 24, 28, 32, 33, 34, 36, 40], "state_bag": 34, "state_dict": 28, "state_dict_convert": 24, "statedictconvert": 24, "statement": 5, "static": [30, 31], "step": [7, 32], "step_nr": [32, 34], "stop": 10, "storag": 24, "store": [1, 15, 19, 21, 23, 25, 26, 31, 32], "str": [1, 18, 19, 21, 22, 24, 25, 26, 27, 28, 33, 38, 39, 40], "straightforward": [1, 7, 9], "strategi": [5, 17, 23, 25, 26, 30], "stream": [17, 23], "streamlin": 12, "strict": 28, "string": [9, 25, 26, 28, 33, 38, 40], "strong": 1, "strongli": [7, 25, 26], "structur": [0, 1, 5, 9, 24, 25, 26, 27, 41], "stty": 10, "studi": 14, "su": [13, 34], "sub": [5, 23, 40], "sub_gang": 23, "sub_kl": 2, "sub_result": 40, "subclass": [2, 12, 18, 28], "submit": 14, "submodul": 7, "subsystem": 6, "success": 9, "sudo": [6, 7], "suffici": [7, 14, 20], "suffix": [0, 18], "suffix_indic": 18, "suit": [7, 14], "sum": [5, 9, 23, 30, 36], "summar": 11, "super": 30, "supervis": 13, "support": [0, 1, 2, 5, 7, 8, 9, 10, 17, 20, 23, 24, 25, 26, 28, 30, 39, 40], "supports_path": 24, "supports_process_group": 23, "supportsdevicetransf": 22, "sure": [7, 14, 23], "surfac": 5, "swap": [1, 5], "switch": 8, "sy": 28, "symbol": [18, 27, 28], "sync": 8, "synchron": 23, "syntax": [0, 9, 14], "system": [1, 2, 3, 6, 9, 14, 15, 17, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 44], "t": [2, 10, 14, 20, 25, 26, 31, 32], "t_co": 2, "tabl": [27, 28, 31, 34], "take": [5, 20, 32], "target": [1, 18, 24, 25, 26, 28], "target_batch": 1, "target_shard_rank": 24, "target_shard_s": 24, "task": [0, 2, 5, 10, 11, 18, 20, 24, 28, 44], "team": 12, "technic": [2, 34], "tell": [9, 27], "tensor": [1, 5, 12, 18, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39], "tensor_dp": 5, "tensor_load": 24, "tensor_tp": 5, "tensor_tp0_dp0": 24, "tensor_tp1_dp0": 24, "tensorboard": 8, "tensorload": 24, "term": [27, 28, 32, 34], "term_siz": 10, "termin": 10, "test": [0, 2, 5, 7, 8, 9, 23], "testabl": 12, "text": [18, 19, 27, 28, 31, 35], "than": [5, 14, 22, 24, 25, 26, 34, 37, 38], "thank": 12, "thei": 24, "them": [7, 9, 14, 23, 36, 40], "therefor": [31, 39], "theta": [9, 34], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 33, 35, 38, 39, 40, 41, 42, 43, 44], "thibaut": 13, "third": [7, 25, 26], "thousand": 5, "thread": [5, 22, 23], "three": 0, "through": [1, 2, 3, 5, 9, 20, 24, 25, 26, 27, 28], "throughout": 1, "throughput": [12, 17], "thu": 32, "ti": [1, 27, 28], "tidi": 14, "tie": 9, "tied_embed": [9, 27, 28], "tiedproject": 35, "tightli": 12, "tiktoken": 18, "tiktoken_llama_instruct": 27, "time": [14, 24, 25, 26, 32], "timedelta": 23, "timeout": 23, "timoth\u00e9": 13, "to_batch": 1, "to_embed": 31, "todo": 1, "togeth": [1, 9, 23, 25, 26], "token": [0, 1, 3, 9, 11, 12, 15, 17, 21, 26, 31, 38], "tokendecod": [18, 28], "tokenencod": [18, 28], "tokenizer_config": [0, 9, 27], "tokenizer_config_overrid": 27, "tokenizer_famili": [0, 9, 27], "tokenizer_hub": 28, "tokenizerconfigt": [19, 28], "tokenizerfamili": 19, "tokenizerhub": 28, "tokenizerhubaccessor": 18, "tokenizersect": 1, "tokenizert": [19, 28], "toler": 5, "toml": [3, 8], "too": 14, "tool": [7, 8, 14, 17], "toolkit": [7, 11, 12, 14], "top": [5, 20, 39], "topologi": [5, 23], "torch": [1, 5, 7, 8, 12, 22, 23, 25, 26, 28, 31, 32, 34, 35, 37, 39], "torch_vers": 7, "torchaudio": 8, "torchvis": 8, "total": [5, 23, 27, 30], "total_loss": 23, "touch": [3, 14], "touvron": [13, 27], "tp": [5, 23, 24, 25, 26], "tp_gang": 5, "tp_idx": 24, "tp_mesh": 5, "tp_rank": 24, "tp_size": [5, 23, 24], "trace": 3, "track": [0, 5, 14, 32, 42], "trade": 30, "tradeoff": [25, 26], "train": [0, 1, 5, 8, 10, 11, 12, 15, 16, 17, 25, 26, 28, 29, 30, 31, 37, 42, 43, 44], "train_main": 1, "train_model": 8, "trainer": 1, "trainersect": 1, "trainrecip": [0, 1, 20, 38, 39], "trainunit": 1, "transcript": [18, 28], "transfer": 22, "transform": [0, 9, 13, 17, 24, 27, 28, 29, 33, 35, 36], "transformer_lm": 0, "transformerdecoderlay": 2, "transformerfrontend": 28, "transformerlm": 28, "transformerlmdecod": 28, "transformerlmdecoderlay": 28, "translat": [11, 18, 28], "travers": 40, "treat": [25, 26, 40], "tree": 14, "tricki": 7, "trivial": 5, "troubleshoot": 12, "true": [18, 22, 23, 24, 25, 26, 27, 28, 30, 33, 40], "try": [0, 9, 21, 26, 40], "tune": [0, 12, 25, 26], "tupl": [1, 24, 25, 26, 30, 31, 37, 39, 40], "turn": [7, 27], "tutori": [1, 9, 10, 12, 26, 27, 28], "two": [3, 5, 9, 14, 23], "txt": [6, 7, 14], "type": [0, 1, 2, 9, 12, 17, 19, 21, 23, 24, 25, 26, 27, 32, 40], "typic": [5, 7, 18, 22, 24, 25, 26, 28, 32, 40], "u": [18, 28, 35], "ubuntu": [6, 7], "under": [12, 14, 30, 38], "underli": [5, 9, 23, 24, 25, 26], "understand": [26, 27, 28], "unexpect": 23, "unifi": [0, 5, 9, 12, 24, 25, 26, 29, 30], "uniform": 30, "uniformli": 5, "uniniti": 26, "unintend": [25, 26], "uniqu": [0, 23], "unit": [1, 12, 14], "unk": 18, "unk_idx": 18, "unknown": 18, "unknown_famili": 21, "unless": [7, 35], "unmask": 37, "unshard": 31, "unsqueez": 30, "until": 23, "up": [0, 2, 3, 5, 8, 12, 27], "updat": [1, 5, 7, 11, 12, 14, 31], "update_nll_loss_metr": 1, "update_seq_batch_metr": 1, "upgrad": [6, 12, 14], "uri": 0, "url": [0, 6, 7, 8, 13, 14], "us": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 14, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 38, 39, 40], "usag": [1, 5, 8, 12, 19, 20, 21, 24, 25, 31, 34, 37], "use_eot": 27, "use_im_end": [0, 9, 28], "use_scaled_rop": 27, "user": [0, 5, 7, 8, 9, 14, 20, 25, 26, 27, 38], "usual": 10, "uszkoreit": 13, "util": [1, 5, 10, 11, 16, 17, 27, 28, 29, 30, 41, 42, 43], "uv": 6, "v": [5, 8, 30], "v0": [1, 2, 8, 11, 24, 25, 26, 30], "v04": 8, "valid": [1, 11, 18, 23, 24, 25, 26, 28, 30, 38], "validat": 40, "validationerror": [39, 40], "validationresult": 40, "valu": [1, 9, 23, 27, 28, 31, 32, 33, 39, 40], "valueerror": [23, 25, 26, 34, 38], "vari": 9, "variabl": [0, 3, 5, 17, 22, 25, 26, 30], "variant": [0, 7, 8, 9, 14, 20], "variou": [0, 12, 17, 20, 24, 29], "varlen": 12, "vaswani": 13, "ve": [1, 14], "venv": [7, 8], "verif": 9, "verifi": 8, "version": 28, "via": [0, 1, 2, 7, 14, 19, 20, 24, 27], "view": 10, "virtual": 2, "visit": 14, "vllm": [8, 12], "vocab_info": [18, 28], "vocab_s": [9, 27, 28], "vocabulari": [18, 27, 28, 31], "vocabularyinfo": [18, 28], "volta": 7, "vstack": 28, "w": 20, "wa": 7, "wai": [3, 19, 21, 24, 25, 26], "wait": 10, "walk": 9, "want": [7, 9, 10, 14, 18, 24, 40], "warn": 3, "wast": 30, "wav2vec": 13, "wav2vec2_asr_base_10h": [25, 26], "wav2vec2_larg": 0, "wav2vec2_large_lv60k": 0, "wav2vec2_model": [25, 26], "we": [1, 7, 10, 14], "websit": 7, "weight": [9, 24, 25, 26, 27, 35], "well": [2, 23, 40], "wen": 13, "what": [1, 2, 9, 10, 11, 23], "wheel": 7, "wheelhous": 7, "when": [0, 5, 7, 8, 9, 12, 18, 19, 21, 22, 23, 24, 25, 26, 27, 32, 34, 39, 40], "whenev": 40, "where": [0, 3, 5, 8, 9, 10, 18, 20, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37], "wherea": 5, "wherev": [2, 34], "whether": 27, "which": [1, 2, 3, 5, 6, 7, 9, 10, 14, 18, 24, 27, 28, 31, 32, 33, 38, 39], "while": [5, 12, 18, 20, 23, 24, 28], "whl": [6, 7, 8, 14], "who": 7, "whole": [25, 26], "whose": 39, "why": 27, "wide": [0, 20], "width": 30, "wire": [1, 2], "within": [0, 2, 5, 12, 23, 31, 38], "without": [2, 3, 5, 7, 23, 24, 25, 26], "won": 31, "work": [0, 4, 5, 7, 8, 12, 17, 18, 19, 21, 23, 25, 27, 28, 38], "workflow": [12, 17], "workload": 17, "world": [5, 23, 27], "world_siz": 5, "worldinfo": 2, "would": [7, 10], "wrap": 23, "wrapper": [5, 38], "write": [12, 23], "wsl": 6, "x": [24, 30, 31, 33, 35], "x86_64": 7, "xavier": 13, "xxxxx": 9, "yaml": [1, 3, 9, 20, 38], "ye": 0, "yet": [12, 14], "yet_other_asset": [0, 1], "yield": [24, 25, 26], "yield_from": 1, "you": [0, 1, 3, 5, 6, 7, 8, 9, 10, 13, 14, 18, 20, 27, 33], "your": [3, 6, 7, 8, 10, 11, 18, 20, 21, 26, 27, 28, 33], "your_packag": 1, "yourrecip": 20, "yourself": 10, "yu": 13, "yunfeng": 13, "zero": 22, "zhang": [13, 33], "zhou": 13}, "titles": ["<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-container\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.41.24l4.711 2.774A1.767 1.767 0 0116 4.54v5.01a1.77 1.77 0 01-.88 1.53l-7.753 4.521-.002.001a1.767 1.767 0 01-1.774 0H5.59L.873 12.85A1.762 1.762 0 010 11.327V6.292c0-.304.078-.598.22-.855l.004-.005.01-.019c.15-.262.369-.486.64-.643L8.641.239a1.75 1.75 0 011.765 0l.002.001zM9.397 1.534a.25.25 0 01.252 0l4.115 2.422-7.152 4.148a.267.267 0 01-.269 0L2.227 5.716l7.17-4.182zM7.365 9.402L8.73 8.61v4.46l-1.5.875V9.473a1.77 1.77 0 00.136-.071zm2.864 2.794V7.741l1.521-.882v4.45l-1.521.887zm3.021-1.762l1.115-.65h.002a.268.268 0 00.133-.232V5.264l-1.25.725v4.445zm-11.621 1.12l4.1 2.393V9.474a1.77 1.77 0 01-.138-.072L1.5 7.029v4.298c0 .095.05.181.129.227z\"></path></svg> Assets", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-rocket\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z\"></path></svg> Building Recipes", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-infinity\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.5 6c-1.086 0-2 .914-2 2 0 1.086.914 2 2 2 .525 0 1.122-.244 1.825-.727.51-.35 1.025-.79 1.561-1.273-.536-.483-1.052-.922-1.56-1.273C4.621 6.244 4.025 6 3.5 6zm4.5.984c-.59-.533-1.204-1.066-1.825-1.493-.797-.548-1.7-.991-2.675-.991C1.586 4.5 0 6.086 0 8s1.586 3.5 3.5 3.5c.975 0 1.878-.444 2.675-.991.621-.427 1.235-.96 1.825-1.493.59.533 1.204 1.066 1.825 1.493.797.547 1.7.991 2.675.991 1.914 0 3.5-1.586 3.5-3.5s-1.586-3.5-3.5-3.5c-.975 0-1.878.443-2.675.991-.621.427-1.235.96-1.825 1.493zM9.114 8c.536.483 1.052.922 1.56 1.273.704.483 1.3.727 1.826.727 1.086 0 2-.914 2-2 0-1.086-.914-2-2-2-.525 0-1.122.244-1.825.727-.51.35-1.025.79-1.561 1.273z\"></path></svg> Design Philosophy", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-plug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.276 3.09a.25.25 0 01.192-.09h.782a.25.25 0 01.25.25v8.5a.25.25 0 01-.25.25h-.782a.25.25 0 01-.192-.09l-.95-1.14a.75.75 0 00-.483-.264l-3.124-.39a.25.25 0 01-.219-.249V5.133a.25.25 0 01.219-.248l3.124-.39a.75.75 0 00.483-.265l.95-1.14zM4 8v1.867a1.75 1.75 0 001.533 1.737l2.83.354.761.912c.332.4.825.63 1.344.63h.782A1.75 1.75 0 0013 11.75V11h2.25a.75.75 0 000-1.5H13v-4h2.25a.75.75 0 000-1.5H13v-.75a1.75 1.75 0 00-1.75-1.75h-.782c-.519 0-1.012.23-1.344.63l-.76.913-2.831.353A1.75 1.75 0 004 5.133V6.5H2.5A2.5 2.5 0 000 9v5.25a.75.75 0 001.5 0V9a1 1 0 011-1H4z\"></path></svg> Runtime Extension", "Assets", "What is a Gang?", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-download\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.47 10.78a.75.75 0 001.06 0l3.75-3.75a.75.75 0 00-1.06-1.06L8.75 8.44V1.75a.75.75 0 00-1.5 0v6.69L4.78 5.97a.75.75 0 00-1.06 1.06l3.75 3.75zM3.75 13a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5z\"></path></svg> Installation", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-file-binary\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0114.25 15h-9a.75.75 0 010-1.5h9a.25.25 0 00.25-.25V6h-2.75A1.75 1.75 0 0110 4.25V1.5H5.75a.25.25 0 00-.25.25v2a.75.75 0 01-1.5 0v-2zm7.5-.188V4.25c0 .138.112.25.25.25h2.688a.252.252 0 00-.011-.013l-2.914-2.914a.272.272 0 00-.013-.011zM0 7.75C0 6.784.784 6 1.75 6h1.5C4.216 6 5 6.784 5 7.75v2.5A1.75 1.75 0 013.25 12h-1.5A1.75 1.75 0 010 10.25v-2.5zm1.75-.25a.25.25 0 00-.25.25v2.5c0 .138.112.25.25.25h1.5a.25.25 0 00.25-.25v-2.5a.25.25 0 00-.25-.25h-1.5zm5-1.5a.75.75 0 000 1.5h.75v3h-.75a.75.75 0 000 1.5h3a.75.75 0 000-1.5H9V6.75A.75.75 0 008.25 6h-1.5z\"></path></svg> Installing from Source", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-lock\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 4v2h-.25A1.75 1.75 0 002 7.75v5.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 13.25v-5.5A1.75 1.75 0 0012.25 6H12V4a4 4 0 10-8 0zm6.5 2V4a2.5 2.5 0 00-5 0v2h5zM12 7.5h.25a.25.25 0 01.25.25v5.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-5.5a.25.25 0 01.25-.25H12z\"></path></svg> UV Setup", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-ruby\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.637 2.291A.75.75 0 014.23 2h7.54a.75.75 0 01.593.291l3.48 4.5a.75.75 0 01-.072.999l-7.25 7a.75.75 0 01-1.042 0l-7.25-7a.75.75 0 01-.072-.999l3.48-4.5zM4.598 3.5L1.754 7.177 8 13.207l6.246-6.03L11.402 3.5H4.598z\"></path></svg> Add Your Own Model", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-bug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.72.22a.75.75 0 011.06 0l1 .999a3.492 3.492 0 012.441 0l.999-1a.75.75 0 111.06 1.061l-.775.776c.616.63.995 1.493.995 2.444v.327c0 .1-.009.197-.025.292.408.14.764.392 1.029.722l1.968-.787a.75.75 0 01.556 1.392L13 7.258V9h2.25a.75.75 0 010 1.5H13v.5c0 .409-.049.806-.141 1.186l2.17.868a.75.75 0 01-.557 1.392l-2.184-.873A4.997 4.997 0 018 16a4.997 4.997 0 01-4.288-2.427l-2.183.873a.75.75 0 01-.558-1.392l2.17-.868A5.013 5.013 0 013 11v-.5H.75a.75.75 0 010-1.5H3V7.258L.971 6.446a.75.75 0 01.558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.684 1.684 0 01-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 010-1.06zM6.173 5h3.654A.173.173 0 0010 4.827V4.5a2 2 0 10-4 0v.327c0 .096.077.173.173.173zM5.25 6.5a.75.75 0 00-.75.75V11a3.5 3.5 0 107 0V7.25a.75.75 0 00-.75-.75h-5.5z\"></path></svg> Debugging with PuDB", "Welcome to fairseq2 Documentation", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-report\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M1.75 1.5a.25.25 0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 01.75.75v2.19l2.72-2.72a.75.75 0 01.53-.22h6.5a.25.25 0 00.25-.25v-9.5a.25.25 0 00-.25-.25H1.75zM0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0114.25 13H8.06l-2.573 2.573A1.457 1.457 0 013 14.543V13H1.75A1.75 1.75 0 010 11.25v-9.5zM9 9a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z\"></path></svg> What\u2019s New in v0.5", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-book\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M0 1.75A.75.75 0 01.75 1h4.253c1.227 0 2.317.59 3 1.501A3.744 3.744 0 0111.006 1h4.245a.75.75 0 01.75.75v10.5a.75.75 0 01-.75.75h-4.507a2.25 2.25 0 00-1.591.659l-.622.621a.75.75 0 01-1.06 0l-.622-.621A2.25 2.25 0 005.258 13H.75a.75.75 0 01-.75-.75V1.75zm8.755 3a2.25 2.25 0 012.25-2.25H14.5v9h-3.757c-.71 0-1.4.201-1.992.572l.004-7.322zm-1.504 7.324l.004-5.073-.002-2.253A2.25 2.25 0 005.003 2.5H1.5v9h3.757a3.75 3.75 0 011.994.574z\"></path></svg> Bibliography", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-heart\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z\"></path></svg> Contributing to fairseq2", "fairseq2.assets", "fairseq2.checkpoint", "fairseq2.data", "fairseq2.data.tokenizers", "fairseq2.data.tokenizers.hub", "fairseq2.datasets", "fairseq2.datasets.hub", "fairseq2.device", "fairseq2.gang", "fairseq2.model_checkpoint", "fairseq2.models", "fairseq2.models.hub", "fairseq2.models.llama", "fairseq2.models.qwen", "fairseq2.nn", "fairseq2.nn.batch_layout", "fairseq2.nn.embedding", "fairseq2.nn.incremental_state", "fairseq2.nn.normalization", "fairseq2.nn.position_encoder", "fairseq2.nn.projection", "fairseq2.nn.residual", "fairseq2.nn.utils", "fairseq2.recipe.composition", "fairseq2.recipe.optim", "fairseq2.utils.validation", "fairseq2.logging", "fairseq2.metrics", "fairseq2.optim", "fairseq2.recipe"], "titleterms": {"": [12, 18], "0": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "00": [0, 1, 3, 6, 7, 8, 10, 12, 13], "000": [3, 6, 7], "001": [1, 3, 6, 12, 14], "0010": 10, "0012": 8, "0013": 3, "0014": [1, 8], "0016": 1, "001a1": 0, "001zm9": 0, "002": [0, 8, 13, 14], "002a": 0, "002l8": 14, "002zm12": 1, "003": [13, 14], "003a": 1, "003h": 14, "004": [0, 3, 13], "005": [0, 1, 13], "006": [13, 14], "008": [7, 14], "009": 10, "01": [0, 1, 3, 7, 8, 9, 10, 12, 13, 14], "010": [0, 7, 10, 12], "011": [0, 3, 7, 10, 13], "0110": 7, "0111": 13, "0114": [1, 7, 12], "0116": 0, "011zm0": 7, "012": [1, 3, 10, 12, 13], "013": [7, 10, 12], "013l": 7, "014": 9, "018": [10, 14], "019c": 0, "01a1": 0, "01a7": 14, "02": [1, 14], "021": 0, "025": [2, 10], "026": 10, "029": [10, 14], "029v4": 0, "02l": 1, "03": 10, "037": 1, "03l11": 9, "042": 9, "045": 14, "046": 1, "047": 1, "049": 10, "05": 0, "051": 1, "052": 2, "058": 1, "06": [1, 6, 10, 13], "061l": 10, "063": 1, "064": 1, "066": 2, "066zm3": 1, "06l": 12, "06l3": 6, "06l8": 6, "06zm6": 10, "071zm2": 0, "072": 9, "072l1": 0, "073": 13, "075": 14, "077": 10, "078": 0, "079": 1, "08": 14, "086": [2, 14], "088": 1, "09": 1, "094": 1, "095": 0, "096": 10, "09a": 3, "09h": 3, "09l": 3, "0a8": 1, "0c6": 14, "0em": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "0h": 1, "0h12": 12, "0h5": [0, 7], "0l": [0, 9, 10, 13, 14], "0l1": 10, "0l2": 0, "0l3": 6, "0l4": 0, "0l8": 14, "0v": [7, 10, 12], "0v2": 12, "0v2h5zm12": 8, "0v6": 6, "0v7": 10, "0v9a1": 3, "0zm": [1, 12], "0zm6": 8, "1": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "10": [1, 6, 7, 8, 10, 14], "102": 1, "102a": 1, "103": 1, "107": 10, "11": [0, 1, 3, 12, 14], "111": 10, "112": [7, 12], "114": 2, "115": 0, "116l5": 1, "117": 1, "118": 1, "119": 1, "119l": 1, "11l3": 1, "11v": 10, "12": [0, 1], "122": 2, "123": 1, "124": [1, 3], "125l": 1, "127l": 1, "129": 0, "12c": 1, "12h": 7, "12l4": 0, "13": [8, 9, 14], "133": 0, "133a": 3, "133v6": 3, "135": 14, "136": 0, "138": [0, 7, 12], "13a": 6, "13h": 13, "13h8": 12, "14": [10, 12, 14], "141": 10, "143": 1, "144": 14, "145": 1, "145l2": 1, "148a": 0, "148z": 1, "14a": 3, "14zm4": 3, "15": [0, 1, 14], "152": 0, "153": 14, "15h": 7, "16": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "164": 14, "16a4": 10, "17": [0, 10, 14], "173": 10, "173zm5": 10, "175l": 1, "176": 1, "177": [1, 9], "178": 1, "181": 0, "182zm7": 0, "183": 10, "184": [7, 10], "186a": 1, "186a7": 1, "186l2": 10, "186zm10": 1, "187": 1, "188v4": 7, "192": 3, "197": 10, "19l2": 12, "1a": 10, "1h4": 13, "1h4z": 3, "2": [0, 1, 2, 3, 7, 8, 9, 10, 12, 13, 14], "20": 14, "201": 13, "203": 14, "204": 2, "207l6": 9, "21": 1, "211c12": 14, "213": 1, "213v": 1, "216": [7, 12], "219": 3, "22": [0, 14], "227": [0, 13], "227z": 0, "22a": 10, "22h6": 12, "23": [1, 3, 9], "231": 14, "232v5": 0, "235": 2, "237": 7, "237v8": 7, "239a1": 0, "244": 2, "245a": 13, "246": 9, "248l3": 3, "249v5": 3, "24l4": 0, "25": [0, 1, 3, 7, 8, 9, 10, 12, 13, 14], "252": [0, 7], "253a2": 13, "253c1": 13, "258": 13, "258l": 10, "258v9h2": 10, "25a": [3, 7, 8, 10, 12], "25a1": 8, "25c0": 7, "25h": [3, 7, 8], "25h1": [7, 12], "25h12z": 8, "25h14": 13, "25h2": 7, "25h2a": 12, "25l": 14, "25v": [1, 7, 8, 12], "25v1": 7, "25v2": 7, "25v2a": 7, "25v5": 8, "25v6h": 7, "25v8": 3, "25v9": 12, "25z": 14, "25zm0": 14, "26": 1, "262": 0, "264l": [0, 3], "265": [1, 10], "265c": 1, "265l": 3, "266": 1, "266h3": 1, "267": 0, "268": 0, "269": 0, "272": 7, "273": [1, 2], "273c4": 2, "273z": 2, "276": 3, "288": [1, 10], "28a": 10, "291a": 9, "291l3": 9, "292": 10, "292c0": 0, "292v4": 10, "298c0": 0, "2a": 1, "2h7": 9, "2v4a2": 8, "2zm7": 7, "3": [1, 2, 3, 6, 7, 9, 10, 13, 14], "304": 0, "309a": 1, "31": 14, "314": 1, "317": [1, 13], "317a15": 1, "31a1": 1, "322zm": 13, "324l": 13, "327c0": 10, "327v6": 0, "328": 7, "329": 7, "33": 10, "332": [1, 3], "336": 14, "338": 1, "344": 3, "345": 14, "35": [1, 2, 14], "353a1": 3, "354": 3, "365": [0, 14], "369": 0, "373": 14, "38": 10, "392": 10, "392l": 10, "392l1": 10, "392l13": 10, "392l2": 10, "393a20": 14, "393v9": 0, "397": 0, "39a": 3, "3a2": 13, "4": [0, 1, 2, 3, 7, 8, 9, 10, 13, 14], "402": 9, "402l8": 0, "408": 10, "409": 10, "41": 0, "414": 14, "414c2": 14, "416": 1, "418": 1, "418l2": 1, "422": 0, "427": 2, "427l": 10, "428c": 1, "429": 1, "434": 14, "44": 1, "441": 10, "442": 14, "443": 2, "444": 2, "444l4": 10, "444v": 10, "445zm": 0, "446a": 10, "44v1": 6, "456a": 14, "457": 12, "458": 1, "458a15": 1, "458c": 1, "458h": 1, "459": 1, "459a8": 1, "45l": 0, "464": 7, "46l": 0, "47": 6, "473a1": 0, "474a1": 0, "48": 9, "483": [2, 3], "485c": 1, "486": [0, 14], "49": 1, "492": 10, "493": [2, 10], "493a7": 1, "493zm9": 2, "499": 1, "49v9": 1, "4h2": 3, "4v2h": 8, "5": [0, 1, 2, 3, 6, 7, 8, 10, 12, 13, 14], "501a3": 13, "504": 13, "507a2": 13, "51": 2, "513": 7, "513l2": 7, "519": 3, "521": [0, 1], "525": 2, "53": 12, "533": [2, 3], "534a": 0, "536": 2, "53l": 0, "543v13h1": 12, "547": 2, "547zm5": 1, "548": [1, 2], "54a": 9, "54v5": 0, "556": 10, "557": 10, "558": 10, "56": 2, "561": [2, 14], "563l": 1, "565": 14, "56a1": 1, "572l": 13, "573": 12, "573a1": 12, "574z": 13, "58": 14, "583": 10, "584l": 14, "586": 2, "586a1": 7, "586c": 7, "59": [1, 2, 13], "591": 13, "593": 9, "598": [0, 9], "598z": 9, "59l": 0, "5a": [3, 6, 7, 8, 9, 10, 12, 13], "5a1": [1, 7, 8, 12], "5a2": [3, 10], "5c": [2, 14], "5c0": [7, 8, 10, 12, 14], "5c15": 12, "5c4": 7, "5h": [1, 6, 7, 8, 10], "5h1": 13, "5h13v": [3, 10], "5h2": 3, "5h3": 10, "5h3a": 7, "5h3v7": 10, "5h4": 9, "5h5": 7, "5h8": 6, "5h9a": 7, "5h9v6": 7, "5l": 1, "5l1": 9, "5v9h": 13, "5v9h3": 13, "5z": [6, 7, 10, 12], "5zm1": 7, "5zm4": 9, "5zm5": 7, "5zm8": 14, "5zm9": 12, "6": [1, 2, 7, 9, 10, 14], "607a": 1, "609": 14, "616": [1, 10], "61v4": 0, "62": 10, "621": [0, 2], "621a": 13, "621a2": 13, "622": 13, "623": 14, "625c": 1, "63": [3, 10], "637": 9, "63h": 3, "63l": 3, "64": 0, "641": [0, 1], "643": 14, "643l8": 0, "644": 14, "65": 14, "654a": 10, "659l": 13, "65h": 0, "665": 1, "666": 14, "666a": 14, "671": 1, "675": 2, "678": 1, "682a20": 14, "684": 10, "688a": 7, "69": 14, "69l4": 6, "6c": 2, "6h": 7, "6h1": 7, "6h12v4a4": 8, "6zm4": 2, "7": [0, 1, 2, 7, 8, 9, 10, 13, 14], "704": 2, "707a1": 1, "71": 13, "711": 0, "716l7": 0, "72": [10, 12], "722a1": 10, "722l1": 10, "725v4": 0, "727": 2, "72a": 12, "73": [0, 1], "731": 14, "734": 1, "737l2": 3, "741l1": 0, "744": [13, 14], "75": [0, 1, 3, 6, 7, 8, 9, 10, 12, 13, 14], "752": 14, "753": 0, "754": 9, "755": 13, "757a3": 13, "757c": 13, "75a": [6, 7, 10, 13], "75a1": [1, 3, 7, 12], "75c0": [7, 12], "75c4": 7, "75h": [3, 10, 13], "75h8": 8, "75v1": 13, "75v10": 13, "75v11a3": 10, "75v11h2": 3, "75v2": [7, 12], "75v3h": 7, "75v5": 8, "75v9": 12, "75zm0": 12, "75zm3": 6, "75zm8": 13, "76": 3, "761": 3, "762": 0, "762l1": 0, "764": 10, "765": 0, "766c": 1, "767": 0, "77": 0, "773": 7, "774": [0, 1], "774a1": 0, "775": 10, "776c": 10, "78": 6, "782": 1, "782a": 3, "782a1": 3, "782c": 3, "783": 1, "784": [7, 8, 12], "787a": 10, "787c": 10, "78a": 6, "79": 2, "794v7": 0, "797": [2, 14], "7a": 9, "8": [0, 1, 6, 8, 9, 14], "802": 14, "806": 10, "814": 10, "818a22": 14, "825": [2, 3], "826": 2, "827v4": 10, "83": 3, "831": 3, "833": 1, "833l": 1, "836": 14, "847": 14, "85": 14, "855l": 0, "859": 14, "85a1": 0, "864": 0, "867a1": 3, "868a": 10, "868a5": 10, "873": 0, "873a": 10, "873a4": 10, "875v9": 0, "878": 2, "88": 0, "882v4": 0, "885": 14, "887zm3": 0, "8c": 2, "8s1": 2, "8v1": 3, "9": [0, 1, 12, 14], "904": 1, "904l": 1, "909": 7, "912c": 3, "913": 3, "914": [2, 7, 14], "914a": 7, "914c": 7, "92": 14, "922": 2, "936v1": 1, "949": 1, "95": [1, 3], "951": 10, "954": 1, "954c": 1, "96": 2, "966": 8, "967": 10, "968": 10, "971": 10, "975": 2, "979": 1, "979h3": 1, "97a": 6, "984c": 2, "986": 14, "991": 2, "991c1": 2, "992": 13, "994": 13, "995": 10, "997": 10, "999": 10, "999a3": 10, "999l": 9, "999l3": 9, "9a": 7, "9a1": 12, "9v5": 3, "A": 8, "Not": 9, "The": 0, "ad": [0, 9], "add": 9, "advanc": [0, 6, 12, 20, 26], "agreement": 14, "also": [0, 1, 2, 3, 17, 19, 21, 26, 27, 28, 29], "api": 11, "appl": 6, "architectur": [7, 9, 12, 28], "aria": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "asset": [0, 4, 9, 15, 20], "audio": 17, "author": 12, "avail": [18, 28], "base": [0, 18], "basic": [2, 3, 11, 28], "batch": 12, "batch_layout": 30, "batchlayout": 30, "best": [0, 8], "bibliographi": 13, "binari": 7, "book": 13, "breakpoint": 10, "bug": 10, "build": [1, 7], "card": [0, 9, 20, 26], "chat": 27, "check": [7, 14], "checkpoint": [12, 16, 26, 28], "class": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 26], "cli": 0, "clone": 7, "code": 10, "common": [0, 8, 9, 26], "comparison": 28, "compil": 30, "complet": [9, 27, 28], "compon": [2, 17], "composit": 38, "concept": [8, 11], "configur": [0, 1, 8, 9, 27, 28], "consider": 30, "constant": 28, "contain": 0, "contribut": 14, "contributor": 14, "convent": 2, "convert_qwen_state_dict": 28, "core": [2, 9, 19, 21, 26], "cpu": 7, "creat": [0, 1, 5, 9, 20, 30], "create_qwen_model": 28, "cuda": [6, 7], "custom": [0, 20, 26, 28], "d": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "data": [5, 12, 17, 18, 19], "dataset": [0, 1, 20, 21], "datasetfamilynotknownerror": 21, "datasethub": 21, "datasethubaccessor": 21, "datasetnotknownerror": 21, "debug": 10, "debugg": 10, "deepli": 5, "defin": 1, "depend": [2, 7], "design": 2, "detail": [8, 9], "develop": 14, "devic": 22, "devicemesh": 5, "differ": 5, "document": [11, 14], "download": [6, 9], "edit": 7, "embed": 31, "entri": 1, "enum": 23, "environ": [0, 7, 14], "error": [3, 9, 26], "evenodd": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "exampl": [3, 9, 26, 27, 28], "except": [19, 21, 22, 23, 24, 25, 26], "execut": 2, "exist": 9, "exit": 10, "experi": 12, "export_qwen": 28, "extens": 3, "face": [9, 12], "factori": [23, 28], "fairseq2": [5, 7, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "fairseq2n": 7, "famili": [9, 26], "featur": 20, "field": 0, "file": [0, 7, 9], "fill": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "flow": 2, "format": 14, "found": 9, "from": [5, 7, 28], "function": [5, 19, 22, 23, 24, 25, 26, 38, 39], "gang": [5, 23], "get": 11, "get_qwen_shard_spec": 28, "get_qwen_tokenizer_hub": 28, "global": 26, "guid": [9, 11, 12], "handl": [3, 26], "heart": 14, "height": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "hidden": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "how": 5, "http": 9, "hub": [9, 19, 21, 26], "hug": [9, 12], "huggingfac": 27, "i": 5, "implement": [1, 2, 9, 27], "incremental_st": 32, "indic": [11, 30], "infin": 2, "inform": 30, "inherit": 0, "initi": 10, "inject": 2, "inspect": 26, "instal": [6, 7], "integr": [9, 12, 30], "interfac": [2, 22, 24], "interoper": 28, "invers": 2, "issu": 14, "iter": 26, "kei": [8, 20], "latest": 11, "layer": 30, "licens": 14, "lint": 14, "linux": 6, "list": [14, 18], "llama": [26, 27], "llamaconfig": 27, "llamatokenizerconfig": 27, "load": [9, 18, 26, 28], "load_model": 26, "load_token": 19, "local": 9, "lock": 8, "log": 41, "m0": 13, "m1": 12, "m10": [0, 3], "m14": 1, "m3": [2, 9], "m4": [7, 8, 10, 14], "m7": 6, "maco": 6, "maintain": 12, "manag": 12, "mask": [30, 37], "memori": 12, "metric": [12, 42], "migrat": 12, "mistral": 26, "mode": 27, "model": [0, 5, 9, 12, 18, 25, 26, 27, 28], "model_checkpoint": 24, "modelhub": 26, "modelhubaccessor": 26, "monitor": 12, "nest": 5, "network": 30, "neural": 30, "new": [11, 12], "next": 12, "nn": [29, 30, 31, 32, 33, 34, 35, 36, 37], "normal": 33, "octicon": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "onli": 7, "open": 20, "optim": [12, 39, 43], "option": [7, 9], "other": 11, "over": 26, "overrid": 0, "overview": [1, 3, 8, 9], "own": 9, "parallel": 5, "paramet": 9, "path": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "perform": [12, 30], "philosophi": 2, "pip": 7, "pipelin": 17, "place": 10, "plug": 3, "point": 1, "posit": 30, "position_encod": 34, "practic": [0, 8], "prerequisit": 8, "process": [12, 17], "processgroup": 5, "programmat": 0, "project": [8, 35], "pudb": 10, "pull": 14, "python": 7, "pytorch": [5, 6, 7], "quick": [6, 8, 18, 19, 26, 27, 28], "qwen": [26, 28], "qwen_famili": 28, "qwenconfig": 28, "qwenfactori": 28, "qwentoken": 28, "qwentokenizerconfig": 28, "recip": [1, 2, 12, 38, 39, 44], "recommend": 9, "refer": [0, 11, 19], "registr": [0, 20], "remot": 10, "report": 12, "repositori": 7, "request": 14, "residu": 36, "rocket": 1, "rubi": 9, "rule": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "run": [1, 10], "runtim": 3, "saniti": 7, "sd": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "see": [0, 1, 2, 3, 17, 19, 21, 26, 27, 28, 29], "sequenc": [9, 30], "set": [7, 14], "setup": [1, 3, 8], "shard": [12, 28], "silicon": 6, "socket": 10, "sourc": [7, 9], "special": 27, "specif": [0, 18], "start": [8, 11, 18, 26, 27, 28], "step": [1, 9], "store": 0, "structur": 17, "support": [6, 12, 27], "svg": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "system": [0, 7], "tabl": 11, "templat": 27, "test": 14, "text": 17, "tiktoken": 27, "tip": 8, "token": [18, 19, 27, 28], "tokenizerfamilynotknownerror": 19, "tokenizerhub": [18, 19], "tokenizerhubaccessor": 19, "tokenizernotknownerror": 19, "torch": 30, "train": 9, "troubleshoot": [0, 8, 9], "true": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "understand": [0, 9], "up": [7, 14], "url": 9, "us": [5, 18, 27], "usag": [0, 2, 3, 26, 28], "user": 12, "util": [23, 37, 40], "uv": 8, "v0": 12, "valid": [9, 40], "variant": 6, "verifi": 9, "version": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "viewbox": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "virtual": 7, "vocabulari": 9, "welcom": 11, "what": [5, 12], "width": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 14], "window": 6, "work": [9, 14, 26, 30], "workflow": 8, "yaml": 0, "your": [1, 9, 14]}})