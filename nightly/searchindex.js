Search.setIndex({"alltitles": {"1. Clone the Repository": [[6, "clone-the-repository"]], "2. Set up a Python Virtual Environment": [[6, "set-up-a-python-virtual-environment"]], "3. Install Dependencies": [[6, "install-dependencies"]], "3.1 System Dependencies": [[6, "system-dependencies"]], "3.2 PyTorch": [[6, "pytorch"]], "3.3 CUDA": [[6, "cuda"]], "3.4 pip": [[6, "pip"]], "4. Build fairseq2n": [[6, "build-fairseq2n"]], "4.1 CPU-Only Builds": [[6, "cpu-only-builds"]], "4.2 CUDA Builds": [[6, "cuda-builds"]], "4.3 CUDA Architectures": [[6, "cuda-architectures"]], "5. Install fairseq2": [[6, "install-fairseq2"]], "5.1 Editable Install": [[6, "editable-install"]], "6. Optional Sanity Check": [[6, "optional-sanity-check"]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-book\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M0 1.75A.75.75 0 01.75 1h4.253c1.227 0 2.317.59 3 1.501A3.744 3.744 0 0111.006 1h4.245a.75.75 0 01.75.75v10.5a.75.75 0 01-.75.75h-4.507a2.25 2.25 0 00-1.591.659l-.622.621a.75.75 0 01-1.06 0l-.622-.621A2.25 2.25 0 005.258 13H.75a.75.75 0 01-.75-.75V1.75zm8.755 3a2.25 2.25 0 012.25-2.25H14.5v9h-3.757c-.71 0-1.4.201-1.992.572l.004-7.322zm-1.504 7.324l.004-5.073-.002-2.253A2.25 2.25 0 005.003 2.5H1.5v9h3.757a3.75 3.75 0 011.994.574z\"></path></svg> Bibliography": [[38, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-bug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.72.22a.75.75 0 011.06 0l1 .999a3.492 3.492 0 012.441 0l.999-1a.75.75 0 111.06 1.061l-.775.776c.616.63.995 1.493.995 2.444v.327c0 .1-.009.197-.025.292.408.14.764.392 1.029.722l1.968-.787a.75.75 0 01.556 1.392L13 7.258V9h2.25a.75.75 0 010 1.5H13v.5c0 .409-.049.806-.141 1.186l2.17.868a.75.75 0 01-.557 1.392l-2.184-.873A4.997 4.997 0 018 16a4.997 4.997 0 01-4.288-2.427l-2.183.873a.75.75 0 01-.558-1.392l2.17-.868A5.013 5.013 0 013 11v-.5H.75a.75.75 0 010-1.5H3V7.258L.971 6.446a.75.75 0 01.558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.684 1.684 0 01-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 010-1.06zM6.173 5h3.654A.173.173 0 0010 4.827V4.5a2 2 0 10-4 0v.327c0 .096.077.173.173.173zM5.25 6.5a.75.75 0 00-.75.75V11a3.5 3.5 0 107 0V7.25a.75.75 0 00-.75-.75h-5.5z\"></path></svg> Debugging with PuDB": [[40, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-container\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.41.24l4.711 2.774A1.767 1.767 0 0116 4.54v5.01a1.77 1.77 0 01-.88 1.53l-7.753 4.521-.002.001a1.767 1.767 0 01-1.774 0H5.59L.873 12.85A1.762 1.762 0 010 11.327V6.292c0-.304.078-.598.22-.855l.004-.005.01-.019c.15-.262.369-.486.64-.643L8.641.239a1.75 1.75 0 011.765 0l.002.001zM9.397 1.534a.25.25 0 01.252 0l4.115 2.422-7.152 4.148a.267.267 0 01-.269 0L2.227 5.716l7.17-4.182zM7.365 9.402L8.73 8.61v4.46l-1.5.875V9.473a1.77 1.77 0 00.136-.071zm2.864 2.794V7.741l1.521-.882v4.45l-1.521.887zm3.021-1.762l1.115-.65h.002a.268.268 0 00.133-.232V5.264l-1.25.725v4.445zm-11.621 1.12l4.1 2.393V9.474a1.77 1.77 0 01-.138-.072L1.5 7.029v4.298c0 .095.05.181.129.227z\"></path></svg> Assets": [[0, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-download\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.47 10.78a.75.75 0 001.06 0l3.75-3.75a.75.75 0 00-1.06-1.06L8.75 8.44V1.75a.75.75 0 00-1.5 0v6.69L4.78 5.97a.75.75 0 00-1.06 1.06l3.75 3.75zM3.75 13a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5z\"></path></svg> Installation": [[5, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-file-binary\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0114.25 15h-9a.75.75 0 010-1.5h9a.25.25 0 00.25-.25V6h-2.75A1.75 1.75 0 0110 4.25V1.5H5.75a.25.25 0 00-.25.25v2a.75.75 0 01-1.5 0v-2zm7.5-.188V4.25c0 .138.112.25.25.25h2.688a.252.252 0 00-.011-.013l-2.914-2.914a.272.272 0 00-.013-.011zM0 7.75C0 6.784.784 6 1.75 6h1.5C4.216 6 5 6.784 5 7.75v2.5A1.75 1.75 0 013.25 12h-1.5A1.75 1.75 0 010 10.25v-2.5zm1.75-.25a.25.25 0 00-.25.25v2.5c0 .138.112.25.25.25h1.5a.25.25 0 00.25-.25v-2.5a.25.25 0 00-.25-.25h-1.5zm5-1.5a.75.75 0 000 1.5h.75v3h-.75a.75.75 0 000 1.5h3a.75.75 0 000-1.5H9V6.75A.75.75 0 008.25 6h-1.5z\"></path></svg> Installing from Source": [[6, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-heart\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z\"></path></svg> Contributing to fairseq2": [[4, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-infinity\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.5 6c-1.086 0-2 .914-2 2 0 1.086.914 2 2 2 .525 0 1.122-.244 1.825-.727.51-.35 1.025-.79 1.561-1.273-.536-.483-1.052-.922-1.56-1.273C4.621 6.244 4.025 6 3.5 6zm4.5.984c-.59-.533-1.204-1.066-1.825-1.493-.797-.548-1.7-.991-2.675-.991C1.586 4.5 0 6.086 0 8s1.586 3.5 3.5 3.5c.975 0 1.878-.444 2.675-.991.621-.427 1.235-.96 1.825-1.493.59.533 1.204 1.066 1.825 1.493.797.547 1.7.991 2.675.991 1.914 0 3.5-1.586 3.5-3.5s-1.586-3.5-3.5-3.5c-.975 0-1.878.443-2.675.991-.621.427-1.235.96-1.825 1.493zM9.114 8c.536.483 1.052.922 1.56 1.273.704.483 1.3.727 1.826.727 1.086 0 2-.914 2-2 0-1.086-.914-2-2-2-.525 0-1.122.244-1.825.727-.51.35-1.025.79-1.561 1.273z\"></path></svg> Design Philosophy": [[2, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-lock\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 4v2h-.25A1.75 1.75 0 002 7.75v5.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 13.25v-5.5A1.75 1.75 0 0012.25 6H12V4a4 4 0 10-8 0zm6.5 2V4a2.5 2.5 0 00-5 0v2h5zM12 7.5h.25a.25.25 0 01.25.25v5.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-5.5a.25.25 0 01.25-.25H12z\"></path></svg> UV Setup": [[7, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-plug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.276 3.09a.25.25 0 01.192-.09h.782a.25.25 0 01.25.25v8.5a.25.25 0 01-.25.25h-.782a.25.25 0 01-.192-.09l-.95-1.14a.75.75 0 00-.483-.264l-3.124-.39a.25.25 0 01-.219-.249V5.133a.25.25 0 01.219-.248l3.124-.39a.75.75 0 00.483-.265l.95-1.14zM4 8v1.867a1.75 1.75 0 001.533 1.737l2.83.354.761.912c.332.4.825.63 1.344.63h.782A1.75 1.75 0 0013 11.75V11h2.25a.75.75 0 000-1.5H13v-4h2.25a.75.75 0 000-1.5H13v-.75a1.75 1.75 0 00-1.75-1.75h-.782c-.519 0-1.012.23-1.344.63l-.76.913-2.831.353A1.75 1.75 0 004 5.133V6.5H2.5A2.5 2.5 0 000 9v5.25a.75.75 0 001.5 0V9a1 1 0 011-1H4z\"></path></svg> Runtime Extension": [[3, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-report\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M1.75 1.5a.25.25 0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 01.75.75v2.19l2.72-2.72a.75.75 0 01.53-.22h6.5a.25.25 0 00.25-.25v-9.5a.25.25 0 00-.25-.25H1.75zM0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0114.25 13H8.06l-2.573 2.573A1.457 1.457 0 013 14.543V13H1.75A1.75 1.75 0 010 11.25v-9.5zM9 9a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z\"></path></svg> What\u2019s New in v0.5": [[9, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-rocket\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z\"></path></svg> Building Recipes": [[1, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-ruby\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.637 2.291A.75.75 0 014.23 2h7.54a.75.75 0 01.593.291l3.48 4.5a.75.75 0 01-.072.999l-7.25 7a.75.75 0 01-1.042 0l-7.25-7a.75.75 0 01-.072-.999l3.48-4.5zM4.598 3.5L1.754 7.177 8 13.207l6.246-6.03L11.402 3.5H4.598z\"></path></svg> Add Your Own Model": [[39, null]], "A Detailed Project Setup": [[7, "a-detailed-project-setup"]], "API Reference": [[20, null]], "Adding a Custom Dataset": [[0, "adding-a-custom-dataset"]], "Adding a Custom Model": [[0, "adding-a-custom-model"]], "Advanced Configuration": [[0, "advanced-configuration"]], "Advanced Dataset Opening": [[16, "advanced-dataset-opening"]], "Advanced Installation": [[5, null]], "Advanced Usage": [[23, "advanced-usage"]], "Architecture Comparison": [[26, "architecture-comparison"]], "Architecture Configuration Error": [[39, "architecture-configuration-error"]], "Asset Card Reference": [[0, "asset-card-reference"]], "Asset Cards: YAML Configuration Files": [[0, "asset-cards-yaml-configuration-files"]], "Asset Source Options": [[39, "asset-source-options"]], "Asset Store Configuration": [[0, "asset-store-configuration"]], "Assets and Checkpoints": [[20, "assets-and-checkpoints"]], "Audio Processing": [[12, "audio-processing"]], "Available Models": [[26, "available-models"]], "Base Assets and Inheritance": [[0, "base-assets-and-inheritance"]], "Base Classes": [[14, "base-classes"]], "Basic Model Usage": [[26, "basic-model-usage"]], "Basic Usage": [[2, "basic-usage"], [3, "basic-usage"]], "Basics": [[8, null]], "Batch Layout": [[27, null]], "Best Practices": [[0, "best-practices"]], "CLI Usage": [[0, "cli-usage"]], "Chat Template Support": [[25, "chat-template-support"]], "Check List for Pull Requests": [[4, "check-list-for-pull-requests"]], "Checkpoint Inspection": [[23, "checkpoint-inspection"]], "Common Asset Fields": [[0, "common-asset-fields"]], "Common Exceptions": [[23, "common-exceptions"]], "Common Model Parameters": [[39, "common-model-parameters"]], "Common Workflows": [[7, "common-workflows"]], "Complete Examples": [[25, "complete-examples"], [26, "complete-examples"]], "Configuration": [[7, "configuration"]], "Configuration Overrides": [[0, "configuration-overrides"]], "Configuration Validation Errors": [[39, "configuration-validation-errors"]], "Constants": [[26, "constants"]], "Contributor License Agreement": [[4, "contributor-license-agreement"]], "Core Architecture": [[39, "core-architecture"]], "Core Classes": [[13, "core-classes"], [15, "core-classes"], [19, "core-classes"], [23, "core-classes"]], "Core Components": [[2, "core-components"]], "Creating BatchLayout": [[27, "creating-batchlayout"]], "Creating Custom Assets": [[0, "creating-custom-assets"]], "Creating Custom Datasets": [[16, "creating-custom-datasets"]], "Custom Architecture": [[26, "custom-architecture"]], "Custom Model Loading": [[23, "custom-model-loading"]], "Data Pipeline Components": [[12, "data-pipeline-components"]], "Data Processing": [[20, "data-processing"]], "Dataset Registration and Asset Cards": [[16, "dataset-registration-and-asset-cards"]], "DatasetFamilyNotKnownError": [[15, "datasetfamilynotknownerror"]], "DatasetHub": [[15, "datasethub"]], "DatasetHubAccessor": [[15, "datasethubaccessor"]], "DatasetNotKnownError": [[15, "datasetnotknownerror"]], "Dependency Injection": [[2, "dependency-injection"]], "Dependency Inversion": [[2, "dependency-inversion"]], "Distributed Computing": [[20, "distributed-computing"]], "Documenting Your Work": [[4, "documenting-your-work"]], "Download/Loading Errors": [[39, "download-loading-errors"]], "Embeddings": [[28, null]], "Enums and Types": [[19, "enums-and-types"]], "Environment-Specific Assets": [[0, "environment-specific-assets"]], "Error Handling": [[3, "error-handling"], [23, "error-handling"]], "Example Error Handling": [[23, "example-error-handling"]], "Example Extension Setup": [[3, "example-extension-setup"]], "Example: Complete Implementation": [[39, "example-complete-implementation"]], "Examples": [[19, "examples"]], "Exceptions": [[13, "exceptions"], [15, "exceptions"]], "Exiting the debugger": [[40, "exiting-the-debugger"]], "FAQ": [[8, null]], "Factory Functions": [[19, "factory-functions"]], "Formatting Your Work": [[4, "formatting-your-work"]], "Functions": [[13, "functions"]], "Gang Configuration": [[19, "gang-configuration"]], "Gang Implementations": [[19, "gang-implementations"]], "Gang Topology": [[19, "gang-topology"]], "Getting Model Information": [[24, "getting-model-information"]], "Getting Started": [[8, null], [9, "getting-started"]], "Global Functions": [[23, "global-functions"]], "HTTP URLs": [[39, "http-urls"]], "Hugging Face Hub (Recommended)": [[39, "hugging-face-hub-recommended"]], "Incremental State": [[29, null]], "Indices and tables": [[8, "indices-and-tables"]], "Initializing the socket for remote debugger": [[40, "initializing-the-socket-for-remote-debugger"]], "Integration with Neural Network Layers": [[27, "integration-with-neural-network-layers"]], "Interface/Implementation Convention": [[2, "interface-implementation-convention"]], "Interoperability": [[26, "interoperability"]], "Issues": [[4, "issues"]], "Iterating Over Model Cards": [[23, "iterating-over-model-cards"]], "Key Concepts": [[7, "key-concepts"]], "Key Features": [[16, "key-features"]], "LLaMA Models": [[23, "llama-models"]], "LLaMAConfig": [[25, "llamaconfig"]], "LLaMATokenizerConfig": [[25, "llamatokenizerconfig"]], "Latest News": [[8, null]], "License": [[4, "license"]], "Linting Your Work": [[4, "linting-your-work"]], "Listing Available Models": [[24, "listing-available-models"]], "Listing Available Tokenizers": [[14, "listing-available-tokenizers"]], "Loading a Model": [[24, "loading-a-model"]], "Loading a Specific Model\u2019s Tokenizer": [[14, "loading-a-specific-model-s-tokenizer"]], "Loading a Tokenizer": [[14, "loading-a-tokenizer"]], "Loading from Custom Checkpoint": [[26, "loading-from-custom-checkpoint"]], "Local Files": [[39, "local-files"]], "Masking Utilities": [[35, "masking-utilities"]], "Mistral Models": [[23, "mistral-models"]], "Model Configuration": [[25, "model-configuration"], [26, "model-configuration"]], "Model Factory": [[26, "model-factory"]], "Model Hub": [[25, "model-hub"], [26, "model-hub"]], "Model Not Found Error": [[39, "model-not-found-error"]], "ModelHub": [[23, "modelhub"]], "ModelHubAccessor": [[23, "modelhubaccessor"]], "Neural Networks & Modeling": [[20, "neural-networks-modeling"]], "Normalization Layers": [[31, null]], "Overview": [[1, "overview"], [3, "overview"], [7, "overview"], [39, "overview"]], "Performance Considerations": [[27, "performance-considerations"]], "Placing the debugger breakpoint in the code": [[40, "placing-the-debugger-breakpoint-in-the-code"]], "Position Encoders": [[32, null]], "Prerequisites": [[7, "prerequisites"]], "Programmatic Asset Registration": [[0, "programmatic-asset-registration"]], "Projection Layers": [[33, null]], "QWEN_FAMILY": [[26, "qwen-family"]], "Quick Install": [[5, "quick-install"]], "Quick Reference": [[13, "quick-reference"]], "Quick Start": [[7, "quick-start"], [14, "quick-start"], [23, "quick-start"], [24, "quick-start"], [25, "quick-start"], [26, "quick-start"]], "Qwen Models": [[23, "qwen-models"]], "QwenConfig": [[26, "qwenconfig"]], "QwenFactory": [[26, "qwenfactory"]], "QwenTokenizer": [[26, "qwentokenizer"]], "QwenTokenizerConfig": [[26, "qwentokenizerconfig"]], "Recipe Execution Flow": [[2, "recipe-execution-flow"]], "Reference": [[8, null]], "Residual Connections": [[34, null]], "Running Your Recipe": [[1, "running-your-recipe"]], "Running fairseq2 with debugger": [[40, "running-fairseq2-with-debugger"]], "See Also": [[0, "see-also"], [1, "see-also"], [2, "see-also"], [3, "see-also"], [12, "see-also"], [13, "see-also"], [15, "see-also"], [19, "see-also"], [23, "see-also"], [25, "see-also"], [26, "see-also"], [30, "see-also"]], "Sequence Information": [[27, "sequence-information"]], "Setting up Development Environment": [[4, "setting-up-development-environment"]], "Sharding": [[26, "sharding"]], "Special Tokens": [[25, "special-tokens"]], "Step 0: Setup the Entry Point": [[1, "step-0-setup-the-entry-point"]], "Step 1: Add Model Architecture Configuration": [[39, "step-1-add-model-architecture-configuration"]], "Step 1: Define Your Configuration": [[1, "step-1-define-your-configuration"]], "Step 2: Create Asset Card": [[39, "step-2-create-asset-card"]], "Step 2: Implement Your Dataset": [[1, "step-2-implement-your-dataset"]], "Step 3: Create Your Recipe Class": [[1, "step-3-create-your-recipe-class"]], "Step 3: Verify the Integration": [[39, "step-3-verify-the-integration"]], "Step-by-Step Guide: Adding a Model to Existing Family": [[39, "step-by-step-guide-adding-a-model-to-existing-family"]], "Structured Data": [[12, "structured-data"]], "Supported Model Families": [[24, "supported-model-families"]], "Supported PyTorch Versions (macOS Apple Silicon)": [[5, "id2"]], "Supported PyTorch Versions and CUDA Variants (Linux)": [[5, "id1"]], "Supported Variants": [[5, "supported-variants"]], "Testing Your Work": [[4, "testing-your-work"]], "Text Processing": [[12, "text-processing"]], "The Asset Store System": [[0, "the-asset-store-system"]], "Tips & Best Practices": [[7, "tips-best-practices"]], "Tokenizer": [[25, "tokenizer"], [26, "tokenizer"]], "Tokenizer Configuration": [[25, "tokenizer-configuration"]], "Tokenizer Modes": [[25, "tokenizer-modes"]], "TokenizerFamilyNotKnownError": [[13, "tokenizerfamilynotknownerror"]], "TokenizerHub": [[13, "tokenizerhub"]], "TokenizerHubAccessor": [[13, "tokenizerhubaccessor"]], "TokenizerNotKnownError": [[13, "tokenizernotknownerror"]], "Torch.compile Integration": [[27, "torch-compile-integration"]], "Training & Architecture Details": [[39, "training-architecture-details"]], "Training and Optimization": [[20, "training-and-optimization"]], "Troubleshooting": [[0, "troubleshooting"], [7, "troubleshooting"], [39, "troubleshooting"]], "Tutorials": [[8, null]], "Understanding Model Families": [[39, "understanding-model-families"]], "Understanding the Asset System": [[0, "understanding-the-asset-system"]], "Using HuggingFace Tokenizer": [[25, "using-huggingface-tokenizer"]], "Using Tiktoken Implementation": [[25, "using-tiktoken-implementation"]], "Using TokenizerHub": [[14, "using-tokenizerhub"]], "Utilities": [[20, "utilities"]], "Utility Functions": [[19, "utility-functions"]], "Vocabulary & Sequence": [[39, "vocabulary-sequence"]], "Welcome to fairseq2 Documentation": [[8, null]], "What\u2019s Gang?": [[19, "what-s-gang"]], "What\u2019s Next": [[9, "what-s-next"]], "Windows": [[5, "windows"]], "Working with Model Families": [[23, "working-with-model-families"]], "Working with Model Hubs": [[39, "working-with-model-hubs"]], "Working with Position Indices and Masks": [[27, "working-with-position-indices-and-masks"]], "convert_qwen_state_dict": [[26, "convert-qwen-state-dict"]], "create_qwen_model": [[26, "create-qwen-model"]], "export_qwen": [[26, "export-qwen"]], "fairseq2.assets": [[10, null]], "fairseq2.checkpoint": [[11, null]], "fairseq2.data": [[12, null]], "fairseq2.data.tokenizers": [[14, null]], "fairseq2.data.tokenizers.hub": [[13, null]], "fairseq2.datasets": [[16, null]], "fairseq2.datasets.hub": [[15, null]], "fairseq2.device": [[17, null]], "fairseq2.gang": [[19, null]], "fairseq2.logging": [[21, null]], "fairseq2.metrics": [[22, null]], "fairseq2.models": [[24, null]], "fairseq2.models.hub": [[23, null]], "fairseq2.models.llama": [[25, null]], "fairseq2.models.qwen": [[26, null]], "fairseq2.nn": [[30, null]], "fairseq2.nn.utils": [[35, null]], "fairseq2.optim": [[36, null]], "fairseq2.recipe": [[37, null]], "fairseq2.recipe.optim": [[18, null]], "get_llama_model_hub": [[25, "get-llama-model-hub"]], "get_llama_tokenizer_hub": [[25, "get-llama-tokenizer-hub"]], "get_qwen_model_hub": [[26, "get-qwen-model-hub"]], "get_qwen_shard_specs": [[26, "get-qwen-shard-specs"]], "get_qwen_tokenizer_hub": [[26, "get-qwen-tokenizer-hub"]], "load_model": [[23, "load-model"]], "load_tokenizer": [[13, "load-tokenizer"]], "\u2699\ufe0f Advanced Model Sharding": [[9, "advanced-model-sharding"]], "\u26a1 Performance & Memory Optimizations": [[9, "performance-memory-optimizations"]], "\ud83c\udfaf Migration Guide": [[9, "migration-guide"]], "\ud83d\udcbe Advanced Checkpoint Management": [[9, "advanced-checkpoint-management"]], "\ud83d\udcc8 Metrics & Monitoring": [[9, "metrics-monitoring"]], "\ud83d\udcca Data Processing & Batching": [[9, "data-processing-batching"]], "\ud83d\udd17 Hugging Face Integration": [[9, "hugging-face-integration"]], "\ud83d\udd27 Architecture & Maintainability": [[9, "architecture-maintainability"]], "\ud83d\ude80 Recipe Authoring & User Experience": [[9, "recipe-authoring-user-experience"]], "\ud83e\udd16 New Model Support": [[9, "new-model-support"]]}, "docnames": ["basics/assets", "basics/building_recipes", "basics/design_philosophy", "basics/runtime_extension", "faq/contributing", "getting_started/installation/index", "getting_started/installation/installation_from_source", "getting_started/installation/setup_with_uv", "index", "news/whats_new_v0_5", "reference/api/assets", "reference/api/checkpoint", "reference/api/data/index", "reference/api/data/tokenizers/hub", "reference/api/data/tokenizers/index", "reference/api/datasets/hub", "reference/api/datasets/index", "reference/api/device", "reference/api/fairseq2.recipe.optim", "reference/api/gang", "reference/api/index", "reference/api/logging", "reference/api/metrics", "reference/api/models/hub", "reference/api/models/index", "reference/api/models/llama", "reference/api/models/qwen", "reference/api/nn/batch_layout", "reference/api/nn/embedding", "reference/api/nn/incremental_state", "reference/api/nn/index", "reference/api/nn/normalization", "reference/api/nn/position_encoder", "reference/api/nn/projection", "reference/api/nn/residual", "reference/api/nn/utils", "reference/api/optim", "reference/api/recipe", "reference/bibliography", "tutorials/add_model", "tutorials/pudb"], "envversion": {"nbsphinx": 4, "sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["basics/assets.rst", "basics/building_recipes.rst", "basics/design_philosophy.rst", "basics/runtime_extension.rst", "faq/contributing.rst", "getting_started/installation/index.rst", "getting_started/installation/installation_from_source.rst", "getting_started/installation/setup_with_uv.rst", "index.rst", "news/whats_new_v0_5.rst", "reference/api/assets.rst", "reference/api/checkpoint.rst", "reference/api/data/index.rst", "reference/api/data/tokenizers/hub.rst", "reference/api/data/tokenizers/index.rst", "reference/api/datasets/hub.rst", "reference/api/datasets/index.rst", "reference/api/device.rst", "reference/api/fairseq2.recipe.optim.rst", "reference/api/gang.rst", "reference/api/index.rst", "reference/api/logging.rst", "reference/api/metrics.rst", "reference/api/models/hub.rst", "reference/api/models/index.rst", "reference/api/models/llama.rst", "reference/api/models/qwen.rst", "reference/api/nn/batch_layout.rst", "reference/api/nn/embedding.rst", "reference/api/nn/incremental_state.rst", "reference/api/nn/index.rst", "reference/api/nn/normalization.rst", "reference/api/nn/position_encoder.rst", "reference/api/nn/projection.rst", "reference/api/nn/residual.rst", "reference/api/nn/utils.rst", "reference/api/optim.rst", "reference/api/recipe.rst", "reference/bibliography.rst", "tutorials/add_model.rst", "tutorials/pudb.rst"], "indexentries": {"additiveresidualconnect (class in fairseq2.nn)": [[34, "fairseq2.nn.AdditiveResidualConnect", false]], "all_gather() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.all_gather", false]], "all_gather() (fairseq2.gang.gang method)": [[19, "fairseq2.gang.Gang.all_gather", false]], "all_gather() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.all_gather", false]], "all_gather_to_list() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.all_gather_to_list", false]], "all_gather_to_list() (fairseq2.gang.gang method)": [[19, "fairseq2.gang.Gang.all_gather_to_list", false]], "all_gather_to_list() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.all_gather_to_list", false]], "all_reduce() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.all_reduce", false]], "all_reduce() (fairseq2.gang.gang method)": [[19, "fairseq2.gang.Gang.all_reduce", false]], "all_reduce() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.all_reduce", false]], "all_sum() (in module fairseq2.gang)": [[19, "fairseq2.gang.all_sum", false]], "apply_mask() (in module fairseq2.nn.utils.mask)": [[35, "fairseq2.nn.utils.mask.apply_mask", false]], "as_process_group() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.as_process_group", false]], "as_process_group() (fairseq2.gang.gang method)": [[19, "fairseq2.gang.Gang.as_process_group", false]], "as_process_group() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.as_process_group", false]], "barrier() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.barrier", false]], "barrier() (fairseq2.gang.gang method)": [[19, "fairseq2.gang.Gang.barrier", false]], "barrier() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.barrier", false]], "batchlayout (class in fairseq2.nn)": [[27, "fairseq2.nn.BatchLayout", false]], "boh_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[14, "fairseq2.data.tokenizers.VocabularyInfo.boh_idx", false]], "bos_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[14, "fairseq2.data.tokenizers.VocabularyInfo.bos_idx", false]], "broadcast() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.broadcast", false]], "broadcast() (fairseq2.gang.gang method)": [[19, "fairseq2.gang.Gang.broadcast", false]], "broadcast() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.broadcast", false]], "broadcast_flag() (in module fairseq2.gang)": [[19, "fairseq2.gang.broadcast_flag", false]], "broadcast_objects() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.broadcast_objects", false]], "broadcast_objects() (fairseq2.gang.gang method)": [[19, "fairseq2.gang.Gang.broadcast_objects", false]], "broadcast_objects() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.broadcast_objects", false]], "capacity_bytes() (fairseq2.nn.incrementalstate method)": [[29, "fairseq2.nn.IncrementalState.capacity_bytes", false]], "capacity_bytes() (fairseq2.nn.incrementalstatebag method)": [[29, "fairseq2.nn.IncrementalStateBag.capacity_bytes", false]], "capacity_increment (fairseq2.nn.incrementalstatebag property)": [[29, "fairseq2.nn.IncrementalStateBag.capacity_increment", false]], "close() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.close", false]], "close() (fairseq2.gang.gangs method)": [[19, "fairseq2.gang.Gangs.close", false]], "close() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.close", false]], "compiled_max_seq_len (fairseq2.nn.batchlayout attribute)": [[27, "fairseq2.nn.BatchLayout.compiled_max_seq_len", false]], "compute_row_mask() (in module fairseq2.nn.utils.mask)": [[35, "fairseq2.nn.utils.mask.compute_row_mask", false]], "convert_qwen_state_dict() (in module fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.convert_qwen_state_dict", false]], "create_decoder() (fairseq2.data.tokenizers.tokenizer method)": [[14, "fairseq2.data.tokenizers.Tokenizer.create_decoder", false]], "create_decoder() (fairseq2.models.qwen.qwentokenizer method)": [[26, "fairseq2.models.qwen.QwenTokenizer.create_decoder", false]], "create_default_process_group() (fairseq2.gang.processgroupgang class method)": [[19, "fairseq2.gang.ProcessGroupGang.create_default_process_group", false]], "create_encoder() (fairseq2.data.tokenizers.tokenizer method)": [[14, "fairseq2.data.tokenizers.Tokenizer.create_encoder", false]], "create_encoder() (fairseq2.models.qwen.qwentokenizer method)": [[26, "fairseq2.models.qwen.QwenTokenizer.create_encoder", false]], "create_fake_gangs() (in module fairseq2.gang)": [[19, "fairseq2.gang.create_fake_gangs", false]], "create_fsdp_gangs() (in module fairseq2.gang)": [[19, "fairseq2.gang.create_fsdp_gangs", false]], "create_gang() (fairseq2.gang.fakegang method)": [[19, "fairseq2.gang.FakeGang.create_gang", false]], "create_gang() (fairseq2.gang.gang method)": [[19, "fairseq2.gang.Gang.create_gang", false]], "create_gang() (fairseq2.gang.processgroupgang method)": [[19, "fairseq2.gang.ProcessGroupGang.create_gang", false]], "create_parallel_gangs() (in module fairseq2.gang)": [[19, "fairseq2.gang.create_parallel_gangs", false]], "create_qwen_model() (in module fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.create_qwen_model", false]], "create_raw_encoder() (fairseq2.data.tokenizers.tokenizer method)": [[14, "fairseq2.data.tokenizers.Tokenizer.create_raw_encoder", false]], "create_raw_encoder() (fairseq2.models.qwen.qwentokenizer method)": [[26, "fairseq2.models.qwen.QwenTokenizer.create_raw_encoder", false]], "datasetfamilynotknownerror": [[15, "fairseq2.datasets.hub.DatasetFamilyNotKnownError", false]], "datasethub (class in fairseq2.datasets.hub)": [[15, "fairseq2.datasets.hub.DatasetHub", false]], "datasethubaccessor (class in fairseq2.datasets.hub)": [[15, "fairseq2.datasets.hub.DatasetHubAccessor", false]], "datasetnotknownerror": [[15, "fairseq2.datasets.hub.DatasetNotKnownError", false]], "decode_from_tokens() (fairseq2.data.tokenizers.tokendecoder method)": [[14, "fairseq2.data.tokenizers.TokenDecoder.decode_from_tokens", false]], "device (fairseq2.gang.fakegang property)": [[19, "fairseq2.gang.FakeGang.device", false]], "device (fairseq2.gang.gang property)": [[19, "fairseq2.gang.Gang.device", false]], "device (fairseq2.gang.processgroupgang property)": [[19, "fairseq2.gang.ProcessGroupGang.device", false]], "dp (fairseq2.gang.gangs attribute)": [[19, "fairseq2.gang.Gangs.dp", false]], "dropout_p (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.dropout_p", false]], "dropout_p (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.dropout_p", false]], "embedding (class in fairseq2.nn)": [[28, "fairseq2.nn.Embedding", false]], "encode_as_tokens() (fairseq2.data.tokenizers.tokenencoder method)": [[14, "fairseq2.data.tokenizers.TokenEncoder.encode_as_tokens", false]], "eoh_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[14, "fairseq2.data.tokenizers.VocabularyInfo.eoh_idx", false]], "eos_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[14, "fairseq2.data.tokenizers.VocabularyInfo.eos_idx", false]], "export_qwen() (in module fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.export_qwen", false]], "extra_repr() (fairseq2.nn.rmsnorm method)": [[31, "fairseq2.nn.RMSNorm.extra_repr", false]], "extra_repr() (fairseq2.nn.standardlayernorm method)": [[31, "fairseq2.nn.StandardLayerNorm.extra_repr", false]], "fairseq2.assets": [[10, "module-fairseq2.assets", false]], "fairseq2.recipe.optim": [[18, "module-fairseq2.recipe.optim", false]], "fakegang (class in fairseq2.gang)": [[19, "fairseq2.gang.FakeGang", false]], "ffn_inner_dim (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim", false]], "ffn_inner_dim (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.ffn_inner_dim", false]], "ffn_inner_dim_multiple_of (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_multiple_of", false]], "ffn_inner_dim_multiplier (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_multiplier", false]], "ffn_inner_dim_scale (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_scale", false]], "forward() (fairseq2.nn.additiveresidualconnect method)": [[34, "fairseq2.nn.AdditiveResidualConnect.forward", false]], "forward() (fairseq2.nn.embedding method)": [[28, "fairseq2.nn.Embedding.forward", false]], "forward() (fairseq2.nn.layernorm method)": [[31, "fairseq2.nn.LayerNorm.forward", false]], "forward() (fairseq2.nn.learnedpositionencoder method)": [[32, "fairseq2.nn.LearnedPositionEncoder.forward", false]], "forward() (fairseq2.nn.linear method)": [[33, "fairseq2.nn.Linear.forward", false]], "forward() (fairseq2.nn.positionencoder method)": [[32, "fairseq2.nn.PositionEncoder.forward", false]], "forward() (fairseq2.nn.projection method)": [[33, "fairseq2.nn.Projection.forward", false]], "forward() (fairseq2.nn.residualconnect method)": [[34, "fairseq2.nn.ResidualConnect.forward", false]], "forward() (fairseq2.nn.rmsnorm method)": [[31, "fairseq2.nn.RMSNorm.forward", false]], "forward() (fairseq2.nn.rotaryencoder method)": [[32, "fairseq2.nn.RotaryEncoder.forward", false]], "forward() (fairseq2.nn.scaledresidualconnect method)": [[34, "fairseq2.nn.ScaledResidualConnect.forward", false]], "forward() (fairseq2.nn.shardedembedding method)": [[28, "fairseq2.nn.ShardedEmbedding.forward", false]], "forward() (fairseq2.nn.sinusoidalpositionencoder method)": [[32, "fairseq2.nn.SinusoidalPositionEncoder.forward", false]], "forward() (fairseq2.nn.standardembedding method)": [[28, "fairseq2.nn.StandardEmbedding.forward", false]], "forward() (fairseq2.nn.standardlayernorm method)": [[31, "fairseq2.nn.StandardLayerNorm.forward", false]], "forward() (fairseq2.nn.tiedprojection method)": [[33, "fairseq2.nn.TiedProjection.forward", false]], "from_embedding() (fairseq2.nn.shardedembedding static method)": [[28, "fairseq2.nn.ShardedEmbedding.from_embedding", false]], "gang (class in fairseq2.gang)": [[19, "fairseq2.gang.Gang", false]], "gangs (class in fairseq2.gang)": [[19, "fairseq2.gang.Gangs", false]], "get_llama_model_hub() (in module fairseq2.models.llama)": [[25, "fairseq2.models.llama.get_llama_model_hub", false]], "get_llama_tokenizer_hub() (in module fairseq2.models.llama)": [[25, "fairseq2.models.llama.get_llama_tokenizer_hub", false]], "get_qwen_model_hub() (in module fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.get_qwen_model_hub", false]], "get_qwen_shard_specs() (in module fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.get_qwen_shard_specs", false]], "get_qwen_tokenizer_hub() (in module fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.get_qwen_tokenizer_hub", false]], "head_dim (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.head_dim", false]], "increment_step_nr() (fairseq2.nn.incrementalstatebag method)": [[29, "fairseq2.nn.IncrementalStateBag.increment_step_nr", false]], "incrementalstate (class in fairseq2.nn)": [[29, "fairseq2.nn.IncrementalState", false]], "incrementalstatebag (class in fairseq2.nn)": [[29, "fairseq2.nn.IncrementalStateBag", false]], "init_scaled_embedding() (in module fairseq2.nn)": [[28, "fairseq2.nn.init_scaled_embedding", false]], "init_std (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.init_std", false]], "init_std_scale (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.init_std_scale", false]], "k_norm (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.k_norm", false]], "layernorm (class in fairseq2.nn)": [[31, "fairseq2.nn.LayerNorm", false]], "learnedpositionencoder (class in fairseq2.nn)": [[32, "fairseq2.nn.LearnedPositionEncoder", false]], "linear (class in fairseq2.nn)": [[33, "fairseq2.nn.Linear", false]], "llamaconfig (class in fairseq2.models.llama)": [[25, "fairseq2.models.llama.LLaMAConfig", false]], "llamatokenizerconfig (class in fairseq2.models.llama)": [[25, "fairseq2.models.llama.LLaMATokenizerConfig", false]], "load_model() (in module fairseq2.models.hub)": [[23, "fairseq2.models.hub.load_model", false]], "load_tokenizer() (in module fairseq2.data.tokenizers.hub)": [[13, "fairseq2.data.tokenizers.hub.load_tokenizer", false]], "max (fairseq2.gang.reduceoperation attribute)": [[19, "fairseq2.gang.ReduceOperation.MAX", false]], "max_num_steps (fairseq2.nn.incrementalstatebag property)": [[29, "fairseq2.nn.IncrementalStateBag.max_num_steps", false]], "max_seq_len (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.max_seq_len", false]], "max_seq_len (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.max_seq_len", false]], "max_seq_len (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.max_seq_len", false]], "maybe_get_state() (fairseq2.nn.incrementalstatebag method)": [[29, "fairseq2.nn.IncrementalStateBag.maybe_get_state", false]], "maybe_raise_param_group_length_error() (in module fairseq2.recipe.optim)": [[18, "fairseq2.recipe.optim.maybe_raise_param_group_length_error", false]], "mean (fairseq2.gang.reduceoperation attribute)": [[19, "fairseq2.gang.ReduceOperation.MEAN", false]], "min (fairseq2.gang.reduceoperation attribute)": [[19, "fairseq2.gang.ReduceOperation.MIN", false]], "min_seq_len (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.min_seq_len", false]], "model_dim (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.model_dim", false]], "model_dim (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.model_dim", false]], "modelarchitecturenotknownerror": [[23, "fairseq2.models.hub.ModelArchitectureNotKnownError", false]], "modelfamilynotknownerror": [[23, "fairseq2.models.hub.ModelFamilyNotKnownError", false]], "modelhub (class in fairseq2.models.hub)": [[23, "fairseq2.models.hub.ModelHub", false]], "modelhubaccessor (class in fairseq2.models.hub)": [[23, "fairseq2.models.hub.ModelHubAccessor", false]], "modelnotknownerror": [[23, "fairseq2.models.hub.ModelNotKnownError", false]], "module": [[10, "module-fairseq2.assets", false], [18, "module-fairseq2.recipe.optim", false]], "num_attn_heads (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.num_attn_heads", false]], "num_attn_heads (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.num_attn_heads", false]], "num_key_value_heads (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.num_key_value_heads", false]], "num_key_value_heads (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.num_key_value_heads", false]], "num_layers (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.num_layers", false]], "num_layers (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.num_layers", false]], "of() (fairseq2.nn.batchlayout static method)": [[27, "fairseq2.nn.BatchLayout.of", false]], "packed (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.packed", false]], "pad_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[14, "fairseq2.data.tokenizers.VocabularyInfo.pad_idx", false]], "pad_idx (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.pad_idx", false]], "padded (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.padded", false]], "position_indices (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.position_indices", false]], "positionencoder (class in fairseq2.nn)": [[32, "fairseq2.nn.PositionEncoder", false]], "pp (fairseq2.gang.gangs attribute)": [[19, "fairseq2.gang.Gangs.pp", false]], "prefix_indices (fairseq2.data.tokenizers.tokenencoder property)": [[14, "fairseq2.data.tokenizers.TokenEncoder.prefix_indices", false]], "processgroupgang (class in fairseq2.gang)": [[19, "fairseq2.gang.ProcessGroupGang", false]], "product (fairseq2.gang.reduceoperation attribute)": [[19, "fairseq2.gang.ReduceOperation.PRODUCT", false]], "projection (class in fairseq2.nn)": [[33, "fairseq2.nn.Projection", false]], "q_norm (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.q_norm", false]], "qkv_proj_bias (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.qkv_proj_bias", false]], "qwen_family (in module fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.QWEN_FAMILY", false]], "qwenconfig (class in fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.QwenConfig", false]], "qwenfactory (class in fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.QwenFactory", false]], "qwentokenizer (class in fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.QwenTokenizer", false]], "qwentokenizerconfig (class in fairseq2.models.qwen)": [[26, "fairseq2.models.qwen.QwenTokenizerConfig", false]], "rank (fairseq2.gang.fakegang property)": [[19, "fairseq2.gang.FakeGang.rank", false]], "rank (fairseq2.gang.gang property)": [[19, "fairseq2.gang.Gang.rank", false]], "rank (fairseq2.gang.processgroupgang property)": [[19, "fairseq2.gang.ProcessGroupGang.rank", false]], "rdp (fairseq2.gang.gangs attribute)": [[19, "fairseq2.gang.Gangs.rdp", false]], "reduceoperation (class in fairseq2.gang)": [[19, "fairseq2.gang.ReduceOperation", false]], "reorder() (fairseq2.nn.incrementalstate method)": [[29, "fairseq2.nn.IncrementalState.reorder", false]], "reorder() (fairseq2.nn.incrementalstatebag method)": [[29, "fairseq2.nn.IncrementalStateBag.reorder", false]], "reset_non_persistent_buffers() (fairseq2.nn.rotaryencoder method)": [[32, "fairseq2.nn.RotaryEncoder.reset_non_persistent_buffers", false]], "reset_non_persistent_buffers() (fairseq2.nn.sinusoidalpositionencoder method)": [[32, "fairseq2.nn.SinusoidalPositionEncoder.reset_non_persistent_buffers", false]], "reset_parameters() (fairseq2.nn.learnedpositionencoder method)": [[32, "fairseq2.nn.LearnedPositionEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.linear method)": [[33, "fairseq2.nn.Linear.reset_parameters", false]], "reset_parameters() (fairseq2.nn.rmsnorm method)": [[31, "fairseq2.nn.RMSNorm.reset_parameters", false]], "reset_parameters() (fairseq2.nn.rotaryencoder method)": [[32, "fairseq2.nn.RotaryEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.shardedembedding method)": [[28, "fairseq2.nn.ShardedEmbedding.reset_parameters", false]], "reset_parameters() (fairseq2.nn.sinusoidalpositionencoder method)": [[32, "fairseq2.nn.SinusoidalPositionEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.standardembedding method)": [[28, "fairseq2.nn.StandardEmbedding.reset_parameters", false]], "reset_parameters() (fairseq2.nn.standardlayernorm method)": [[31, "fairseq2.nn.StandardLayerNorm.reset_parameters", false]], "residualconnect (class in fairseq2.nn)": [[34, "fairseq2.nn.ResidualConnect", false]], "rmsnorm (class in fairseq2.nn)": [[31, "fairseq2.nn.RMSNorm", false]], "root (fairseq2.gang.gangs attribute)": [[19, "fairseq2.gang.Gangs.root", false]], "rope_scale (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.rope_scale", false]], "rope_theta (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.rope_theta", false]], "rope_theta (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.rope_theta", false]], "rotaryencoder (class in fairseq2.nn)": [[32, "fairseq2.nn.RotaryEncoder", false]], "scaledresidualconnect (class in fairseq2.nn)": [[34, "fairseq2.nn.ScaledResidualConnect", false]], "sdp (fairseq2.gang.gangs attribute)": [[19, "fairseq2.gang.Gangs.sdp", false]], "seq_begin_indices (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.seq_begin_indices", false]], "seq_begin_indices_pt (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.seq_begin_indices_pt", false]], "seq_lens (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.seq_lens", false]], "seq_lens_pt (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.seq_lens_pt", false]], "set_state() (fairseq2.nn.incrementalstatebag method)": [[29, "fairseq2.nn.IncrementalStateBag.set_state", false]], "shard_embed_dim (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.shard_embed_dim", false]], "shardedembedding (class in fairseq2.nn)": [[28, "fairseq2.nn.ShardedEmbedding", false]], "sinusoidalpositionencoder (class in fairseq2.nn)": [[32, "fairseq2.nn.SinusoidalPositionEncoder", false]], "size (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[14, "fairseq2.data.tokenizers.VocabularyInfo.size", false]], "size (fairseq2.gang.fakegang property)": [[19, "fairseq2.gang.FakeGang.size", false]], "size (fairseq2.gang.gang property)": [[19, "fairseq2.gang.Gang.size", false]], "size (fairseq2.gang.processgroupgang property)": [[19, "fairseq2.gang.ProcessGroupGang.size", false]], "size_bytes() (fairseq2.nn.incrementalstate method)": [[29, "fairseq2.nn.IncrementalState.size_bytes", false]], "size_bytes() (fairseq2.nn.incrementalstatebag method)": [[29, "fairseq2.nn.IncrementalStateBag.size_bytes", false]], "standardembedding (class in fairseq2.nn)": [[28, "fairseq2.nn.StandardEmbedding", false]], "standardlayernorm (class in fairseq2.nn)": [[31, "fairseq2.nn.StandardLayerNorm", false]], "step_nr (fairseq2.nn.incrementalstatebag property)": [[29, "fairseq2.nn.IncrementalStateBag.step_nr", false]], "suffix_indices (fairseq2.data.tokenizers.tokenencoder property)": [[14, "fairseq2.data.tokenizers.TokenEncoder.suffix_indices", false]], "sum (fairseq2.gang.reduceoperation attribute)": [[19, "fairseq2.gang.ReduceOperation.SUM", false]], "supports_process_group (fairseq2.gang.fakegang property)": [[19, "fairseq2.gang.FakeGang.supports_process_group", false]], "supports_process_group (fairseq2.gang.gang property)": [[19, "fairseq2.gang.Gang.supports_process_group", false]], "supports_process_group (fairseq2.gang.processgroupgang property)": [[19, "fairseq2.gang.ProcessGroupGang.supports_process_group", false]], "tied_embeddings (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.tied_embeddings", false]], "tied_embeddings (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.tied_embeddings", false]], "tiedprojection (class in fairseq2.nn)": [[33, "fairseq2.nn.TiedProjection", false]], "to_embedding() (fairseq2.nn.shardedembedding method)": [[28, "fairseq2.nn.ShardedEmbedding.to_embedding", false]], "tokendecoder (class in fairseq2.data.tokenizers)": [[14, "fairseq2.data.tokenizers.TokenDecoder", false]], "tokenencoder (class in fairseq2.data.tokenizers)": [[14, "fairseq2.data.tokenizers.TokenEncoder", false]], "tokenizer (class in fairseq2.data.tokenizers)": [[14, "fairseq2.data.tokenizers.Tokenizer", false]], "tokenizerfamilynotknownerror": [[13, "fairseq2.data.tokenizers.hub.TokenizerFamilyNotKnownError", false]], "tokenizerhub (class in fairseq2.data.tokenizers.hub)": [[13, "fairseq2.data.tokenizers.hub.TokenizerHub", false]], "tokenizerhubaccessor (class in fairseq2.data.tokenizers.hub)": [[13, "fairseq2.data.tokenizers.hub.TokenizerHubAccessor", false]], "tokenizernotknownerror": [[13, "fairseq2.data.tokenizers.hub.TokenizerNotKnownError", false]], "tp (fairseq2.gang.gangs attribute)": [[19, "fairseq2.gang.Gangs.tp", false]], "unk_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[14, "fairseq2.data.tokenizers.VocabularyInfo.unk_idx", false]], "use_scaled_rope (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.use_scaled_rope", false]], "vocab_info (fairseq2.data.tokenizers.tokenizer property)": [[14, "fairseq2.data.tokenizers.Tokenizer.vocab_info", false]], "vocab_info (fairseq2.models.qwen.qwentokenizer property)": [[26, "fairseq2.models.qwen.QwenTokenizer.vocab_info", false]], "vocab_size (fairseq2.models.llama.llamaconfig attribute)": [[25, "fairseq2.models.llama.LLaMAConfig.vocab_size", false]], "vocab_size (fairseq2.models.qwen.qwenconfig attribute)": [[26, "fairseq2.models.qwen.QwenConfig.vocab_size", false]], "vocabularyinfo (class in fairseq2.data.tokenizers)": [[14, "fairseq2.data.tokenizers.VocabularyInfo", false]], "width (fairseq2.nn.batchlayout property)": [[27, "fairseq2.nn.BatchLayout.width", false]]}, "objects": {"fairseq2": [[10, 0, 0, "-", "assets"]], "fairseq2.data.tokenizers": [[14, 1, 1, "", "TokenDecoder"], [14, 1, 1, "", "TokenEncoder"], [14, 1, 1, "", "Tokenizer"], [14, 1, 1, "", "VocabularyInfo"]], "fairseq2.data.tokenizers.TokenDecoder": [[14, 2, 1, "", "decode_from_tokens"]], "fairseq2.data.tokenizers.TokenEncoder": [[14, 2, 1, "", "encode_as_tokens"], [14, 3, 1, "", "prefix_indices"], [14, 3, 1, "", "suffix_indices"]], "fairseq2.data.tokenizers.Tokenizer": [[14, 2, 1, "", "create_decoder"], [14, 2, 1, "", "create_encoder"], [14, 2, 1, "", "create_raw_encoder"], [14, 3, 1, "", "vocab_info"]], "fairseq2.data.tokenizers.VocabularyInfo": [[14, 4, 1, "", "boh_idx"], [14, 4, 1, "", "bos_idx"], [14, 4, 1, "", "eoh_idx"], [14, 4, 1, "", "eos_idx"], [14, 4, 1, "", "pad_idx"], [14, 4, 1, "", "size"], [14, 4, 1, "", "unk_idx"]], "fairseq2.data.tokenizers.hub": [[13, 5, 1, "", "TokenizerFamilyNotKnownError"], [13, 1, 1, "", "TokenizerHub"], [13, 1, 1, "", "TokenizerHubAccessor"], [13, 5, 1, "", "TokenizerNotKnownError"], [13, 6, 1, "", "load_tokenizer"]], "fairseq2.datasets.hub": [[15, 5, 1, "", "DatasetFamilyNotKnownError"], [15, 1, 1, "", "DatasetHub"], [15, 1, 1, "", "DatasetHubAccessor"], [15, 5, 1, "", "DatasetNotKnownError"]], "fairseq2.gang": [[19, 1, 1, "", "FakeGang"], [19, 1, 1, "", "Gang"], [19, 1, 1, "", "Gangs"], [19, 1, 1, "", "ProcessGroupGang"], [19, 1, 1, "", "ReduceOperation"], [19, 6, 1, "", "all_sum"], [19, 6, 1, "", "broadcast_flag"], [19, 6, 1, "", "create_fake_gangs"], [19, 6, 1, "", "create_fsdp_gangs"], [19, 6, 1, "", "create_parallel_gangs"]], "fairseq2.gang.FakeGang": [[19, 2, 1, "", "all_gather"], [19, 2, 1, "", "all_gather_to_list"], [19, 2, 1, "", "all_reduce"], [19, 2, 1, "", "as_process_group"], [19, 2, 1, "", "barrier"], [19, 2, 1, "", "broadcast"], [19, 2, 1, "", "broadcast_objects"], [19, 2, 1, "", "close"], [19, 2, 1, "", "create_gang"], [19, 3, 1, "", "device"], [19, 3, 1, "", "rank"], [19, 3, 1, "", "size"], [19, 3, 1, "", "supports_process_group"]], "fairseq2.gang.Gang": [[19, 2, 1, "", "all_gather"], [19, 2, 1, "", "all_gather_to_list"], [19, 2, 1, "", "all_reduce"], [19, 2, 1, "", "as_process_group"], [19, 2, 1, "", "barrier"], [19, 2, 1, "", "broadcast"], [19, 2, 1, "", "broadcast_objects"], [19, 2, 1, "", "create_gang"], [19, 3, 1, "", "device"], [19, 3, 1, "", "rank"], [19, 3, 1, "", "size"], [19, 3, 1, "", "supports_process_group"]], "fairseq2.gang.Gangs": [[19, 2, 1, "", "close"], [19, 4, 1, "", "dp"], [19, 4, 1, "", "pp"], [19, 4, 1, "", "rdp"], [19, 4, 1, "", "root"], [19, 4, 1, "", "sdp"], [19, 4, 1, "", "tp"]], "fairseq2.gang.ProcessGroupGang": [[19, 2, 1, "", "all_gather"], [19, 2, 1, "", "all_gather_to_list"], [19, 2, 1, "", "all_reduce"], [19, 2, 1, "", "as_process_group"], [19, 2, 1, "", "barrier"], [19, 2, 1, "", "broadcast"], [19, 2, 1, "", "broadcast_objects"], [19, 2, 1, "", "close"], [19, 2, 1, "", "create_default_process_group"], [19, 2, 1, "", "create_gang"], [19, 3, 1, "", "device"], [19, 3, 1, "", "rank"], [19, 3, 1, "", "size"], [19, 3, 1, "", "supports_process_group"]], "fairseq2.gang.ReduceOperation": [[19, 4, 1, "", "MAX"], [19, 4, 1, "", "MEAN"], [19, 4, 1, "", "MIN"], [19, 4, 1, "", "PRODUCT"], [19, 4, 1, "", "SUM"]], "fairseq2.models.hub": [[23, 5, 1, "", "ModelArchitectureNotKnownError"], [23, 5, 1, "", "ModelFamilyNotKnownError"], [23, 1, 1, "", "ModelHub"], [23, 1, 1, "", "ModelHubAccessor"], [23, 5, 1, "", "ModelNotKnownError"], [23, 6, 1, "", "load_model"]], "fairseq2.models.llama": [[25, 1, 1, "", "LLaMAConfig"], [25, 1, 1, "", "LLaMATokenizerConfig"], [25, 6, 1, "", "get_llama_model_hub"], [25, 6, 1, "", "get_llama_tokenizer_hub"]], "fairseq2.models.llama.LLaMAConfig": [[25, 4, 1, "", "dropout_p"], [25, 4, 1, "", "ffn_inner_dim"], [25, 4, 1, "", "ffn_inner_dim_multiple_of"], [25, 4, 1, "", "ffn_inner_dim_multiplier"], [25, 4, 1, "", "ffn_inner_dim_scale"], [25, 4, 1, "", "init_std"], [25, 4, 1, "", "init_std_scale"], [25, 4, 1, "", "max_seq_len"], [25, 4, 1, "", "model_dim"], [25, 4, 1, "", "num_attn_heads"], [25, 4, 1, "", "num_key_value_heads"], [25, 4, 1, "", "num_layers"], [25, 4, 1, "", "pad_idx"], [25, 4, 1, "", "rope_scale"], [25, 4, 1, "", "rope_theta"], [25, 4, 1, "", "shard_embed_dim"], [25, 4, 1, "", "tied_embeddings"], [25, 4, 1, "", "use_scaled_rope"], [25, 4, 1, "", "vocab_size"]], "fairseq2.models.qwen": [[26, 7, 1, "", "QWEN_FAMILY"], [26, 1, 1, "", "QwenConfig"], [26, 1, 1, "", "QwenFactory"], [26, 1, 1, "", "QwenTokenizer"], [26, 1, 1, "", "QwenTokenizerConfig"], [26, 6, 1, "", "convert_qwen_state_dict"], [26, 6, 1, "", "create_qwen_model"], [26, 6, 1, "", "export_qwen"], [26, 6, 1, "", "get_qwen_model_hub"], [26, 6, 1, "", "get_qwen_shard_specs"], [26, 6, 1, "", "get_qwen_tokenizer_hub"]], "fairseq2.models.qwen.QwenConfig": [[26, 4, 1, "", "dropout_p"], [26, 4, 1, "", "ffn_inner_dim"], [26, 4, 1, "", "head_dim"], [26, 4, 1, "", "k_norm"], [26, 4, 1, "", "max_seq_len"], [26, 4, 1, "", "model_dim"], [26, 4, 1, "", "num_attn_heads"], [26, 4, 1, "", "num_key_value_heads"], [26, 4, 1, "", "num_layers"], [26, 4, 1, "", "q_norm"], [26, 4, 1, "", "qkv_proj_bias"], [26, 4, 1, "", "rope_theta"], [26, 4, 1, "", "tied_embeddings"], [26, 4, 1, "", "vocab_size"]], "fairseq2.models.qwen.QwenTokenizer": [[26, 2, 1, "", "create_decoder"], [26, 2, 1, "", "create_encoder"], [26, 2, 1, "", "create_raw_encoder"], [26, 3, 1, "", "vocab_info"]], "fairseq2.nn": [[34, 1, 1, "", "AdditiveResidualConnect"], [27, 1, 1, "", "BatchLayout"], [28, 1, 1, "", "Embedding"], [29, 1, 1, "", "IncrementalState"], [29, 1, 1, "", "IncrementalStateBag"], [31, 1, 1, "", "LayerNorm"], [32, 1, 1, "", "LearnedPositionEncoder"], [33, 1, 1, "", "Linear"], [32, 1, 1, "", "PositionEncoder"], [33, 1, 1, "", "Projection"], [31, 1, 1, "", "RMSNorm"], [34, 1, 1, "", "ResidualConnect"], [32, 1, 1, "", "RotaryEncoder"], [34, 1, 1, "", "ScaledResidualConnect"], [28, 1, 1, "", "ShardedEmbedding"], [32, 1, 1, "", "SinusoidalPositionEncoder"], [28, 1, 1, "", "StandardEmbedding"], [31, 1, 1, "", "StandardLayerNorm"], [33, 1, 1, "", "TiedProjection"], [28, 6, 1, "", "init_scaled_embedding"]], "fairseq2.nn.AdditiveResidualConnect": [[34, 2, 1, "", "forward"]], "fairseq2.nn.BatchLayout": [[27, 4, 1, "", "compiled_max_seq_len"], [27, 3, 1, "", "max_seq_len"], [27, 3, 1, "", "min_seq_len"], [27, 2, 1, "", "of"], [27, 3, 1, "", "packed"], [27, 3, 1, "", "padded"], [27, 3, 1, "", "position_indices"], [27, 3, 1, "", "seq_begin_indices"], [27, 3, 1, "", "seq_begin_indices_pt"], [27, 3, 1, "", "seq_lens"], [27, 3, 1, "", "seq_lens_pt"], [27, 3, 1, "", "width"]], "fairseq2.nn.Embedding": [[28, 2, 1, "", "forward"]], "fairseq2.nn.IncrementalState": [[29, 2, 1, "", "capacity_bytes"], [29, 2, 1, "", "reorder"], [29, 2, 1, "", "size_bytes"]], "fairseq2.nn.IncrementalStateBag": [[29, 2, 1, "", "capacity_bytes"], [29, 3, 1, "", "capacity_increment"], [29, 2, 1, "", "increment_step_nr"], [29, 3, 1, "", "max_num_steps"], [29, 2, 1, "", "maybe_get_state"], [29, 2, 1, "", "reorder"], [29, 2, 1, "", "set_state"], [29, 2, 1, "", "size_bytes"], [29, 3, 1, "", "step_nr"]], "fairseq2.nn.LayerNorm": [[31, 2, 1, "", "forward"]], "fairseq2.nn.LearnedPositionEncoder": [[32, 2, 1, "", "forward"], [32, 2, 1, "", "reset_parameters"]], "fairseq2.nn.Linear": [[33, 2, 1, "", "forward"], [33, 2, 1, "", "reset_parameters"]], "fairseq2.nn.PositionEncoder": [[32, 2, 1, "", "forward"]], "fairseq2.nn.Projection": [[33, 2, 1, "", "forward"]], "fairseq2.nn.RMSNorm": [[31, 2, 1, "", "extra_repr"], [31, 2, 1, "", "forward"], [31, 2, 1, "", "reset_parameters"]], "fairseq2.nn.ResidualConnect": [[34, 2, 1, "", "forward"]], "fairseq2.nn.RotaryEncoder": [[32, 2, 1, "", "forward"], [32, 2, 1, "", "reset_non_persistent_buffers"], [32, 2, 1, "", "reset_parameters"]], "fairseq2.nn.ScaledResidualConnect": [[34, 2, 1, "", "forward"]], "fairseq2.nn.ShardedEmbedding": [[28, 2, 1, "", "forward"], [28, 2, 1, "", "from_embedding"], [28, 2, 1, "", "reset_parameters"], [28, 2, 1, "", "to_embedding"]], "fairseq2.nn.SinusoidalPositionEncoder": [[32, 2, 1, "", "forward"], [32, 2, 1, "", "reset_non_persistent_buffers"], [32, 2, 1, "", "reset_parameters"]], "fairseq2.nn.StandardEmbedding": [[28, 2, 1, "", "forward"], [28, 2, 1, "", "reset_parameters"]], "fairseq2.nn.StandardLayerNorm": [[31, 2, 1, "", "extra_repr"], [31, 2, 1, "", "forward"], [31, 2, 1, "", "reset_parameters"]], "fairseq2.nn.TiedProjection": [[33, 2, 1, "", "forward"]], "fairseq2.nn.utils.mask": [[35, 6, 1, "", "apply_mask"], [35, 6, 1, "", "compute_row_mask"]], "fairseq2.recipe": [[18, 0, 0, "-", "optim"]], "fairseq2.recipe.optim": [[18, 6, 1, "", "maybe_raise_param_group_length_error"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "exception", "Python exception"], "6": ["py", "function", "Python function"], "7": ["py", "data", "Python data"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:exception", "6": "py:function", "7": "py:data"}, "terms": {"": [1, 2, 3, 4, 6, 8, 12, 16, 25, 27, 32, 34, 35, 39, 40], "0": [13, 14, 19, 25, 26, 27, 28, 32, 35], "03762": 38, "05": 31, "064": 26, "06450": 38, "07467": 38, "09864": 38, "1": [16, 19, 25, 26, 27, 28, 29, 31, 33], "100": 27, "10000": [25, 32], "1000000": 26, "10h": 16, "11477": 38, "11_008": 39, "12": [4, 5, 6, 7], "128": 39, "13971": 38, "14": [6, 7, 27, 35], "14b": 26, "15": [19, 35], "151_936": 39, "152": 26, "152064": 26, "16": [19, 29, 35], "1607": 38, "16384": [25, 26], "1706": 38, "18": 7, "18944": 26, "1910": 38, "1_000_000": [26, 39], "1d": 27, "1e": 31, "1t": 9, "2": [5, 16, 19, 25, 26, 27, 28, 31, 32, 35], "20": 1, "2006": 38, "2016": 38, "2019": 38, "2020": 38, "2023": 38, "2024": [7, 39], "2048": [25, 26, 32, 39], "21": 7, "2104": 38, "22": 7, "2302": 38, "24": [26, 40], "25": 27, "250": 27, "256": 25, "28": 26, "3": [0, 7, 9, 16, 19, 25, 26, 27, 28, 31, 32, 35], "32": [25, 26], "32000": [25, 28], "32768": [23, 26], "32_768": 39, "32b": 26, "3584": 26, "36": 39, "37": 27, "3b": [26, 39], "4": [19, 25, 26, 27, 28, 32, 35], "400": 27, "4096": [0, 25, 26], "4b": 26, "5": [8, 19, 25, 26, 27, 28, 31, 32, 35, 39], "50": 27, "512": [27, 28, 32, 35], "5b": [23, 26], "6": [5, 7, 27, 28, 31, 32, 38], "65": 35, "6666666666666666": 25, "6899": 40, "6b": [13, 14, 24, 26, 39], "7": [5, 19], "70": 6, "75": 27, "768": 26, "7b": [0, 26], "8": [6, 19, 27, 40], "80": [6, 40], "8084": 4, "8192": 0, "8b": [0, 9, 25, 26], "9": [7, 27], "95": 39, "A": [0, 1, 9, 18, 19, 29, 32, 39], "And": 6, "As": [1, 6], "By": [4, 6], "For": [0, 1, 3, 4, 5, 6, 9, 16, 19, 25, 27, 31, 39, 40], "If": [0, 4, 6, 14, 19, 25, 26, 28, 29, 31, 32, 33, 39], "In": [0, 4, 6, 39, 40], "It": [9, 12, 13, 15, 16, 19, 25, 26, 27, 29, 30], "No": [0, 7, 9, 25], "Not": 0, "ON": [4, 6], "On": 40, "One": [1, 2], "Or": [3, 14, 26], "That": 1, "The": [1, 2, 3, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40], "Then": [1, 3, 6, 25], "There": 39, "These": [0, 2, 7], "To": [0, 4, 5, 6, 31], "Will": 25, "With": 7, "_": [0, 6, 27], "__init__": [1, 2, 3, 27], "__main__": 3, "__name__": 3, "__source__": 0, "__str__": 26, "__version__": 7, "_base": 0, "_chat": 0, "_devic": 19, "_eos_token": 25, "_file": 1, "_instruct": 0, "_legacy_pad_idx": 32, "_model": [1, 25], "_pg": 19, "_tok": 25, "a100": 6, "ab": [38, 39], "abbrevi": 2, "abc": [2, 14, 28, 29, 31, 32, 33, 34], "abdelrahman": 38, "abi": [4, 5], "abil": 9, "abl": 4, "about": [0, 1, 6, 29], "abov": [4, 5, 6, 7], "absolut": 16, "abstract": [0, 2, 12, 14, 17, 19, 28, 29, 31, 32, 33, 34], "accept": [4, 31], "access": [2, 13, 15, 16, 23, 25, 26, 39, 40], "accessor": [13, 15, 23], "accident": 7, "accomod": 19, "accompani": 4, "accord": 29, "achiev": 6, "across": [0, 1, 9, 19, 23, 28], "act": 2, "activ": [6, 7, 9], "actual": [6, 39], "ad": [4, 9, 16, 23, 25, 26, 34], "adamw": 36, "adapt": 14, "add": [0, 3, 4, 7, 8, 16, 18, 23, 25, 26, 31], "add_generation_prompt": 25, "addit": [0, 4, 5, 7, 26, 31, 33, 40], "additiveresidualconnect": 34, "address": 4, "adjac": 19, "adjust": 40, "advanc": [1, 6, 14, 24, 39], "advanced_open": 16, "advantag": 9, "affin": 31, "after": [4, 7, 16, 29, 39], "aggreg": 22, "agnost": 13, "agre": 4, "ahm": 38, "ai": [13, 14, 25, 26], "aidan": 38, "aim": 25, "al": [25, 31, 32], "alexei": 38, "algorithm": [2, 14, 32], "all": [0, 2, 3, 4, 9, 13, 14, 15, 16, 19, 23, 26, 27, 33, 38, 39, 40], "all_gath": 19, "all_gather_to_list": 19, "all_reduc": 19, "all_sum": 19, "alloc": [27, 40], "allow": [0, 1, 2, 3, 7, 8, 32], "allow_uneven": 1, "along": [2, 6], "alreadi": [4, 6], "also": [4, 5, 6, 16, 24, 35], "altern": [4, 9], "alwai": [7, 35], "amper": 6, "an": [0, 2, 4, 5, 6, 14, 16, 19, 26, 28, 29, 31, 32, 33, 39, 40], "analysi": 9, "and_return": 1, "ani": [0, 1, 2, 3, 4, 6, 16, 23, 28, 29, 32, 35], "ann": 38, "annot": 2, "anoth": 33, "api": [0, 1, 2, 4, 5, 8, 9, 19, 23, 25, 26, 27, 32], "appear": [39, 40], "appli": [25, 26, 27, 31, 33, 34, 35, 39], "applic": 21, "apply_chat_templ": 25, "apply_mask": [27, 35], "approach": [1, 2], "appropri": [23, 39, 40], "approx": 26, "apt": [5, 6], "ar": [0, 1, 2, 3, 4, 6, 7, 9, 14, 16, 19, 25, 26, 27, 31, 33, 39], "arch": [3, 6, 23, 26, 39], "architectur": [0, 1, 2, 3, 23, 24, 25, 30], "area": 20, "arg": [2, 19, 31, 34], "argument": [1, 14, 26, 32, 40], "armand": 38, "around": [2, 3], "arrow": [4, 5], "art": 9, "arxiv": [38, 39], "as_": [1, 23, 24], "as_auto_regress": 1, "as_i": 25, "as_input": 1, "as_process_group": 19, "ashish": 38, "ask": 6, "aspect": 1, "assert": 25, "asset": [1, 2, 3, 7, 8, 9, 13, 14, 15, 23, 24, 25, 26], "asset_nam": 0, "asset_stor": [0, 2, 13, 15, 23, 24], "assetnotfounderror": 0, "assetstor": 2, "assist": 25, "associ": [14, 19, 26], "astral": 7, "async": 9, "asynchron": 9, "atmeta": [4, 5, 7], "attempt": [13, 15], "attent": [2, 9, 25, 26, 27, 38, 39], "attentionlay": 27, "attn_mask": 27, "audiocol": 12, "audiodataset": 12, "auli": 38, "aurelien": 38, "authent": 39, "auto": 2, "auto_activate_bas": 7, "autocomplet": 1, "automat": [1, 2, 19, 23, 27], "avail": [0, 4, 6, 9, 13, 15, 23, 25, 39], "avoid": 6, "awar": 9, "azhar": 38, "b": [4, 6], "ba": [31, 38], "back": 7, "backend": 19, "background": 1, "baevski": 38, "bag": 29, "baptist": 38, "barrier": 19, "base": [1, 2, 4, 6, 7, 9, 12, 13, 15, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40], "base_model": 0, "base_model_instruct": 0, "baselin": 9, "basic": [0, 1, 7, 16, 18, 19, 39, 40], "batch": [1, 12, 28, 29, 30, 32, 34, 35], "batch_first": 27, "batch_layout": [27, 28, 32, 35], "batch_siz": 27, "batch_tensor": [27, 35], "batchlayout": [1, 9, 12, 26, 28, 32, 35], "beam": 29, "becaus": 4, "becom": [4, 6, 7], "been": 9, "befor": [0, 6, 34, 40], "begin": [14, 25, 27], "begin_of_text": 25, "beginn": [1, 9], "behavior": 19, "behind": 14, "being": [4, 8, 10, 11, 17, 21, 22, 36, 37], "belong": 19, "below": [0, 2, 4, 7, 32], "benefit": 0, "better": [9, 27], "between": [0, 2, 4, 5, 7, 14, 19, 26, 29], "beyond": 39, "bia": [26, 31, 33, 39], "biao": 38, "bibliographi": 8, "bibtex": 7, "bin": [6, 7], "binari": 4, "black": 4, "block": 30, "bo": [14, 25, 38], "boh": 14, "boh_idx": 14, "boilerpl": 1, "bool": [14, 19, 25, 26, 27, 31, 33], "boolean": [19, 35], "bos_idx": 14, "both": [0, 1, 7, 9, 12, 16, 27, 28, 31, 32, 33, 34, 40], "boundari": [19, 27], "branch": 4, "brew": [5, 6], "broadcast": [19, 35], "broadcast_flag": 19, "broadcast_object": 19, "broader": 9, "browser": 4, "budget": 9, "buffer": 26, "bug": 4, "build": [4, 5, 7, 8, 16, 30], "build_typ": 6, "builder": 1, "built": [0, 1, 2, 3, 4, 6, 16], "byte": 29, "bytes_or_buff": 26, "c": [4, 5, 6, 7, 9, 12, 39], "cach": [0, 7, 9, 10, 13, 14, 29], "call": [16, 29], "callabl": [28, 32, 33], "caller": [2, 19], "can": [0, 1, 2, 3, 4, 6, 7, 13, 14, 15, 16, 23, 24, 32, 40], "capabl": [3, 9, 39], "capac": 29, "capacity_byt": 29, "capacity_incr": 29, "capit": 26, "card": [2, 9, 13, 14, 15, 24, 25, 26], "care": 27, "carefulli": 4, "case": [6, 16, 29, 39, 40], "cast_fp32": 31, "catalog": 10, "caus": 32, "cc": 4, "cd": [4, 5, 6, 7], "cento": 5, "central": [0, 2, 13, 15], "chain": 12, "chang": [4, 7, 9, 29, 39], "channel": 19, "chatbot": 1, "check": [0, 1, 7, 9, 18, 24, 39], "checkpoint": [0, 1, 2, 39], "checkpoint_path": [23, 26], "chicken": 25, "choic": 26, "choos": [4, 40], "chosen": 40, "chunk": [1, 2], "ci": 7, "cl": 0, "cla": 4, "clang": 4, "class": [12, 16, 25, 26, 27, 28, 29, 31, 32, 33, 34], "classmethod": [0, 19], "classvar": 27, "clean": [2, 7], "clear": [0, 1, 2, 4, 7], "clearer": 9, "cli": 1, "clip": 36, "clone": [4, 5], "closabl": 19, "close": 19, "cluster": [0, 6, 16, 40], "clusterscop": 7, "cmake": [4, 6], "cmake_cuda_architectur": 6, "cmakelist": 6, "code": [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 17, 21, 22, 25, 26, 36, 37, 39], "codebas": 3, "coeffici": [25, 26, 32], "collat": 12, "collect": [0, 2, 19], "com": [0, 4, 5, 6, 7, 39, 40], "combin": [5, 19], "come": [0, 10, 11, 12, 17, 21, 22, 36, 37], "command": [0, 1, 4, 5, 6, 7, 14, 24, 39, 40], "comment": 0, "commit": [0, 4, 5], "common": [1, 16, 37], "commonsect": 1, "commun": [9, 19], "companion": 16, "compar": 26, "comparison": 27, "compat": [4, 5, 7, 27, 39], "compil": [1, 6, 9], "compiled_max_seq_len": 27, "complet": [1, 3, 4, 6, 7, 20], "complex": [1, 2, 4, 13, 16, 19], "compon": [0, 1, 3, 39], "compos": 2, "composit": [0, 1, 2, 3, 16], "comprehens": [12, 27], "comput": [1, 6, 17, 19, 22, 27, 40], "compute_row_mask": 35, "concept": 2, "concern": 7, "concret": [2, 13, 14, 15, 26], "conda": [6, 7], "condit": 9, "config": [0, 1, 3, 6, 7, 13, 14, 15, 16, 18, 23, 25, 26, 39, 40], "config_kl": [1, 3, 13, 15, 23], "config_registri": 3, "config_yaml": 40, "configregistrar": 3, "configur": [2, 6, 9, 13, 14, 15, 16, 18, 21, 23, 24, 36, 37, 40], "conflict": [6, 7], "connect": [30, 39, 40], "consid": 32, "consist": [0, 1, 4, 9, 27, 39], "consolid": [9, 27], "constant": 34, "construct": [2, 14, 26, 28], "constructor": 2, "consult": 6, "consum": 12, "contain": [1, 2, 3, 4, 16, 19, 20, 25], "content": [8, 23, 25], "context": [0, 1], "continu": 9, "contract": [2, 14], "contribut": [6, 8, 28], "control": [0, 1, 9, 14, 26], "conveni": [0, 6, 39], "convent": [4, 39], "convert": [1, 9, 26, 28], "coordin": 19, "copi": [2, 19, 32], "core": [1, 3, 12, 30], "cornerston": 27, "correctli": 39, "correspond": [16, 25, 26, 28, 29], "could": 16, "coupl": 2, "cover": [4, 39], "coverag": 9, "cpu": [4, 5, 7, 17, 19, 27, 35, 40], "crash": [4, 5], "creat": [3, 4, 6, 7, 13, 14, 15, 19, 23, 25, 26, 28, 30, 35], "create_decod": [13, 14, 26], "create_default_process_group": 19, "create_encod": [13, 14, 25, 26], "create_fake_gang": 19, "create_fsdp_gang": 19, "create_gang": 19, "create_my_custom_model": [1, 3], "create_new_model": [23, 26, 39], "create_parallel_gang": 19, "create_raw_encod": [14, 26], "create_read": [1, 16], "create_train": 1, "creation": [0, 16], "critic": [2, 12], "cross": [17, 25], "csv": 12, "csvdataset": 12, "cu124": [5, 7], "cu126": 5, "cu128": [4, 5, 6, 7], "cuda": [4, 7, 19, 27], "cuda_arch": 6, "cuda_vers": 6, "curl": 7, "current": [0, 29], "custom": [1, 3, 7, 8, 9, 13, 14, 15, 25, 31, 37, 39], "custom_dataset": [1, 3, 15, 16], "custom_load": [1, 3], "custom_model": 39, "custom_open": [1, 3, 16], "custom_path": [13, 14], "custom_qwen": 0, "custom_token": [1, 3, 13, 14], "customdataset": [1, 3, 16], "customdatasetconfig": [1, 3, 16], "customiz": 1, "customtoken": [1, 3], "customtokenizerconfig": [1, 3], "cut": 9, "cxx": 4, "data": [0, 1, 7, 15, 16, 19, 23, 25, 26, 30, 31, 33], "data_read": 1, "dataclass": [0, 1, 16, 19], "dataload": 12, "datapipelin": [1, 12], "datapipelineread": 1, "dataread": [1, 16], "dataset": [3, 9, 12, 13, 20, 23], "dataset_config": [0, 16], "dataset_famili": [0, 16], "datasetconfigt": 15, "datasetsect": 1, "datasett": 15, "date": 4, "dclm": 9, "dcmake_build_typ": 6, "dcmake_cuda_architectur": 6, "dcp": 9, "de": [14, 26], "deadlock": 40, "debian": 5, "debug": [1, 8, 21], "decai": [25, 26, 32], "decid": 40, "decod": [13, 14, 25, 26, 29, 32], "decode_from_token": 14, "decor": [2, 39], "def": [0, 1, 2, 3, 16, 18, 27, 39], "default": [0, 1, 2, 3, 4, 6, 7, 19, 25, 26], "default_dataset": 1, "default_encod": 25, "default_factori": [0, 1], "defin": [0, 2, 7, 14, 16, 26, 32, 39], "definit": [0, 16], "demand": 2, "demonstr": [0, 2], "denomin": 31, "denot": 19, "dens": 9, "dep": 6, "depend": [0, 1, 3, 4, 5, 7, 9, 16, 39], "dependencycontain": [0, 1, 2, 3, 16], "dependencyprovid": 2, "dependencyresolv": [2, 16], "deploi": 0, "deploy": 0, "depth": 25, "describ": [0, 4, 6, 14, 16, 25, 31, 32, 39], "descript": [0, 4], "design": [0, 1, 3, 7, 8, 9, 12, 27, 39, 40], "desir": [5, 6], "detail": [0, 1, 3, 9, 13], "detect": [0, 17], "determin": 23, "determinist": [2, 9], "dev": [6, 7], "devel": [4, 5, 6], "develop": [0, 5, 6, 7, 8, 9, 10, 11, 17, 19, 21, 22, 36, 37, 39], "deviat": 25, "devic": [2, 4, 6, 14, 19, 20, 23, 24, 26, 27, 28, 31, 32, 33, 35], "dfairseq2n_perform_lto": 6, "dfairseq2n_python_devel": 6, "dfairseq2n_run_clang_tidi": 4, "dfairseq2n_sanit": 6, "dfairseq2n_treat_warnings_as_error": 6, "dfairseq2n_use_cuda": 6, "di": 2, "diagram": [2, 32], "dict": [1, 26], "dictionari": [26, 28], "did": 25, "differ": [0, 2, 6, 14, 16, 19, 25, 26, 27, 39], "dim": [26, 27], "dimens": [25, 26, 28, 31, 32, 33, 35, 39], "dimension": [25, 26, 28, 32, 33, 34, 39], "dir": [0, 1, 6, 13, 14, 16], "direct": [0, 39], "directli": [9, 13, 14], "directori": [0, 1, 4, 6, 24, 25], "disabl": 7, "discov": [13, 15, 23], "discover": 9, "discoveri": 0, "disk": 9, "distinguish": [14, 26], "distribut": [1, 6, 9, 19, 26], "divers": 2, "dnf": [5, 6], "do": [1, 4, 28], "doc": [4, 7, 40], "docstr": 4, "document": [0, 6, 7, 9, 10, 11, 12, 13, 15, 17, 21, 22, 23, 36, 37], "doe": [5, 18, 29], "don": 16, "done": 14, "download": [0, 6, 7, 9, 10, 13, 14], "dp": 19, "driven": 9, "dropout": [0, 25, 26, 39], "dropout_p": [0, 25, 26, 39], "dtype": [23, 28, 31, 32, 33], "due": [6, 35], "dummi": 0, "dump": 1, "duplic": 2, "dure": [9, 11, 27, 28, 29], "dynam": [0, 9, 27], "e": [0, 2, 4, 5, 6, 7, 9, 15, 16, 19, 23, 25, 26, 28, 31, 32, 38, 39, 40], "each": [1, 2, 7, 19, 23, 27, 35, 39], "earlier": 1, "eas": 9, "easi": [0, 1, 4, 19, 39], "easier": [9, 27], "easili": 7, "echo": [0, 40], "ecosystem": 9, "edit": [4, 5, 7], "edouard": 38, "effect": [6, 35], "effici": [1, 9, 12, 19, 27, 30, 38], "either": 16, "element": [14, 19, 27, 32, 35], "elementwise_affin": 31, "elimin": 1, "els": [1, 27], "emb": 28, "embed": [25, 26, 30, 32, 38, 39], "embed_dim": 28, "empti": 6, "en": [14, 26], "enabl": [2, 9, 19], "encod": [2, 13, 14, 25, 26, 30], "encode_as_token": 14, "encoder_decoder_attn": 2, "encoder_decoder_attn_layer_norm": 2, "encoding_dim": 32, "end": [0, 6, 14, 25], "end_header_id": 25, "end_of_text": 25, "enforc": 4, "enhanc": [9, 38, 40], "ensur": [2, 4, 7, 39, 40], "entir": [4, 9, 39], "entri": [0, 3, 28, 39], "entry_point": 0, "env": 40, "environ": [3, 7, 19, 40], "eo": [14, 25], "eoh": 14, "eoh_idx": 14, "eos_idx": 14, "eos_token": 26, "eot_id": 25, "ep": 31, "equal": 19, "eric": 38, "error": [1, 7, 26], "especi": 9, "essenti": [0, 2], "et": [25, 31, 32], "etc": [0, 2, 7, 16, 39, 40], "eval": 26, "evalrecip": 16, "evalu": [0, 9, 12, 22], "even": 32, "everi": 29, "everyth": 1, "exactli": [4, 5], "exampl": [0, 1, 2, 6, 7, 9, 10, 11, 13, 15, 16, 17, 21, 22, 27, 28, 31, 32, 35, 36, 37, 40], "exce": 32, "except": [0, 39], "exclus": 7, "execut": [1, 19], "exist": [0, 6, 7, 9, 27], "expand": [9, 27], "expandus": 1, "expect": [2, 4, 29, 32, 40], "expens": 2, "experi": [4, 5, 40], "experiment": [7, 19], "explain": [7, 40], "explan": 40, "explicit": 7, "explor": [2, 40], "export": [3, 26], "expos": [9, 23, 26, 39], "extend": 3, "extens": [0, 2, 8, 9, 16], "extensionerror": 3, "extra": [0, 3, 4, 5, 6, 7, 31], "extra_path": [0, 1, 16], "extra_repr": 31, "extract": 12, "f": [0, 1, 2, 7, 13, 14, 15, 19, 23, 24, 26, 27, 39], "face": [0, 4, 26], "facebook": [0, 4], "facebookresearch": [4, 5, 6, 7], "factor": [25, 34], "factori": [1, 3, 13, 15, 25], "fail": [3, 6, 39], "failur": 4, "fair": [4, 5, 6, 7], "fairseq2": [0, 1, 2, 3, 5, 7, 9, 20, 27, 28, 29, 31, 32, 33, 34, 39], "fairseq2_asset_dir": [0, 16], "fairseq2_cache_dir": 0, "fairseq2_ext": 0, "fairseq2_extension_trac": 3, "fairseq2_user_asset_dir": [0, 16], "fairseq2n": [4, 7], "fairseq2n_use_cuda": 6, "faisal": 38, "fake": 19, "fakegang": 19, "fallback": 0, "fals": [2, 7, 14, 19, 23, 25, 26, 27, 31, 39], "famili": [0, 1, 3, 13, 14, 15, 16, 26], "familiar": [6, 39, 40], "family_nam": [13, 15, 23], "fashion": 19, "fast": 7, "favicon": 7, "featur": [2, 4, 7, 9, 12, 27, 32, 40], "fedora": [5, 6], "feed": [2, 25, 26, 39], "feedforwardnetwork": 2, "few": 1, "ffn": 2, "ffn_inner_dim": [25, 26, 39], "ffn_inner_dim_multiple_of": 25, "ffn_inner_dim_multipli": 25, "ffn_inner_dim_scal": 25, "ffn_layer_norm": 2, "field": [1, 18, 23, 24], "file": [1, 3, 4, 9, 12, 16, 25, 40], "file_rank": 1, "file_world_s": 1, "filesystem": 0, "fill_valu": [27, 35], "final": [0, 1, 2, 6, 13, 15, 19, 23, 26, 27, 28, 29, 31, 32, 33, 34], "find": [0, 39], "fine": [0, 9], "first": [1, 2, 3, 6, 9, 16, 19, 32, 39], "fix": [28, 32], "flag": 19, "flake8": 4, "flash3": 9, "flexibl": [0, 1, 3, 9, 12, 16], "float": [18, 25, 26, 31, 32, 34], "focu": 1, "focus": [1, 9, 39], "follow": [0, 2, 4, 5, 6, 9, 16, 40], "foo": 0, "foo1": 0, "foo2": 0, "forg": 6, "fork": [2, 4], "form": [0, 4, 6], "format": [0, 1, 7, 9, 12, 16, 21, 25, 26, 39], "formatt": 6, "formatted_text": 25, "formula": 26, "forward": [2, 25, 26, 27, 28, 31, 32, 33, 34, 39], "found": [0, 1, 6, 13, 14, 15, 23], "foundat": [7, 9, 38], "four": 1, "frac": [28, 33], "framework": [1, 2, 9, 38], "franc": 26, "free": [0, 7], "freqs_init_fn": 32, "frequenc": [25, 32], "frequent": 29, "fresh": 7, "from": [0, 1, 2, 3, 4, 5, 7, 9, 11, 13, 14, 15, 16, 18, 19, 23, 24, 25, 27, 28, 32, 33, 35, 39, 40], "from_embed": 28, "from_path": 0, "fs2_build_wheel": 6, "fs2_state_dict": 26, "fsdp": 19, "full": [1, 4, 9, 23, 27], "fulli": [9, 19, 27], "function": [1, 3, 14, 15, 16, 18, 20, 27, 39, 40], "furo": 7, "further": 9, "futur": [9, 13, 14, 25, 26], "g": [0, 2, 4, 5, 6, 9, 16, 19, 25, 26, 39, 40], "g0": 19, "g1": 19, "g2": 19, "g3": 19, "g4": 19, "g5": 19, "g6": 19, "g7": 19, "gang": [1, 20, 23, 28], "gangsect": 1, "gather": 19, "gautier": 38, "gener": [0, 6, 8, 9, 13, 14, 15, 23, 25, 26, 35], "generationrecip": 16, "generic_instruct": 0, "geoffrei": 38, "germani": 26, "get": [1, 4, 14, 15, 16, 23, 25, 26, 27, 29, 39, 40], "get_arch": [23, 26, 39], "get_arch_config": [23, 26, 39], "get_asset_stor": [0, 24], "get_dataset_config": 15, "get_default_devic": [19, 24, 26, 27], "get_dependency_resolv": 2, "get_llama_model_hub": 23, "get_mistral_model_hub": 23, "get_my_dataset_hub": 15, "get_qwen_model_hub": [23, 39], "get_qwen_tokenizer_hub": [13, 14], "get_rank": 40, "get_start_lr": 18, "get_tokenizer_config": [13, 14], "getdefaultencod": 26, "git": [4, 5, 6, 7], "github": [4, 5, 6, 7, 40], "give": 9, "given": [19, 26, 39], "glob": 1, "global": [2, 13], "gloo": 19, "gninja": [4, 6], "go": 1, "goal": 2, "gomez": 38, "goyal": 38, "gpu": [1, 4, 6, 7, 17, 19, 27, 40], "gqa": [26, 39], "grace": 1, "gradient": [28, 36], "grain": 9, "graph": 2, "grave": 38, "greater": [9, 35], "grep": 39, "group": [0, 1, 7, 9, 18, 19, 25, 26, 39], "guarante": 35, "guid": 7, "guidanc": 9, "guidelin": 4, "guillaum": 38, "h": 31, "h_": 33, "ha": [2, 4, 5, 6, 9, 14, 19, 23, 29], "hambro": 38, "handl": [1, 2, 9, 13, 14, 19, 25, 26, 27, 32, 39], "handler": 26, "hang": 40, "hardwar": 7, "hash": [4, 5], "have": [0, 2, 4, 5, 6, 9, 16, 19, 32, 39, 40], "haven": 4, "head": [25, 26, 27, 39], "head_dim": [26, 39], "header": [14, 25], "hello": 25, "help": [9, 14, 25], "helper": [1, 14, 18], "henri": 38, "here": [1, 3, 4, 14, 16, 19, 39, 40], "hf": [9, 13, 14], "hf_state_dict": 26, "hg": [0, 9, 25, 39], "hide": 27, "high": [9, 12, 13, 19], "high_prior": 19, "hinton": 38, "hold": [18, 19, 25, 29, 32], "home": 0, "homebrew": 6, "host": [6, 19, 40], "hostnam": 40, "hour": 4, "how": [0, 1, 2, 3, 4, 6, 7, 14, 39, 40], "howev": 6, "html": 4, "http": [0, 4, 5, 6, 7, 38, 40], "hub": [0, 7, 9, 10, 14, 16, 24], "hug": [0, 26], "huggingfac": [13, 14], "huggingfaceexport": 26, "hugo": 38, "hyperparamet": 37, "i": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "icanon": 40, "id": 1, "idea": 2, "ideal": 4, "ident": [19, 33], "identifi": [0, 1, 26], "ignor": 31, "illia": 38, "illustr": 2, "immedi": [4, 5], "impl": 25, "implement": [4, 9, 12, 13, 14, 15, 16, 26, 31, 32, 35], "implementor": [13, 15, 23], "import": [0, 1, 2, 3, 7, 13, 14, 15, 16, 18, 19, 23, 24, 25, 26, 27, 28, 32, 35, 39, 40], "improv": [1, 2, 9], "includ": [0, 2, 3, 4, 9, 10, 11, 12, 17, 21, 22, 24, 25, 26, 30, 32, 35, 36, 37, 40], "incom": [31, 33], "incompat": 7, "increas": 25, "increment": [30, 32], "increment_step_nr": 29, "incrementalst": 29, "incrementalstatebag": [29, 32], "independ": 16, "index": [4, 5, 6, 7, 8, 14, 25, 27], "index_select": 29, "indic": [0, 14, 26, 28], "individu": [1, 9, 27], "induc": 40, "infer": [12, 25, 26, 29], "inference_mod": 26, "inform": [0, 1, 3, 6, 9, 14, 19, 26, 29, 31, 32, 39], "init": [6, 7], "init_fairseq2": [0, 2, 3], "init_fn": [28, 31, 33], "init_scaled_embed": 28, "init_std": 25, "init_std_scal": 25, "initi": [1, 2, 7, 19, 23, 25, 28, 31, 32, 33, 34, 39], "inject": [1, 3, 9, 16], "inner": [25, 26, 39], "inp": 33, "input": [1, 19, 25, 26, 28, 29, 31, 32, 33, 34, 35, 39], "input_batch": 1, "input_dim": 33, "input_tensor": 19, "insert": 40, "inspect": [2, 9, 39], "instal": [4, 7, 8, 39, 40], "instanc": [1, 2, 3, 6, 13, 15, 16, 19, 23, 26, 28, 33], "instanti": 26, "instead": [2, 6, 9, 25, 32], "instruct": [0, 4, 5, 6, 25, 39, 40], "int": [14, 18, 19, 25, 26, 27, 28, 29, 31, 32, 33], "integ": 39, "integr": [2, 4, 12, 16], "inter": 19, "interact": [0, 16], "interchang": 2, "interest": 4, "interfac": [1, 14, 19, 23, 24, 27, 39, 40], "intern": [9, 13, 28, 31, 32, 33, 34], "internet": 39, "intra": 19, "intra_node_s": 19, "introduc": [1, 2], "intuit": 9, "invalid": 3, "invalid_arch": 23, "invok": 40, "is_avail": 7, "is_dir": 1, "isinst": 18, "isol": 6, "isort": 4, "issu": [0, 5, 6, 7], "iter_card": [13, 14, 15, 23, 26], "iter_checkpoint": 23, "its": [2, 3, 6, 14, 19, 23, 28], "izacard": 38, "jakob": 38, "jami": 38, "jepa_vith16": 0, "jepa_vith16_384": 0, "jepa_vitl16": 0, "jianlin": 38, "jimmi": 38, "job": [9, 40], "joke": 25, "jone": 38, "joulin": 38, "json": [12, 25], "jsondataset": 12, "jsonl": [1, 12], "jupyt": 7, "just": [1, 4], "k": 33, "k_norm": 26, "kaiser": 38, "keep": [0, 29], "kei": [0, 2, 9, 12, 23, 25, 26, 27, 39], "kernel": 6, "key_padding_mask": 27, "kind": [0, 7, 14, 24, 39], "kiro": 38, "kl": [1, 2, 3, 13, 15, 23, 29], "know": [0, 19], "kw_onli": 1, "kwarg": [2, 19, 31, 34], "l": [0, 6, 40], "la": 0, "lab": 7, "lachaux": 38, "lacroix": 38, "lambda": 1, "lampl": 38, "lang": [14, 26], "languag": [1, 8, 9, 14, 24, 25, 26, 38, 39], "larg": [2, 9, 12], "larger": 4, "last": [31, 32, 33], "later": 19, "latest": [4, 7], "launch": 40, "lavril": 38, "layer": [0, 2, 19, 25, 26, 30, 38, 39], "layernorm": [2, 31], "layout": [1, 9, 30, 35], "learn": [0, 1, 3, 6, 12, 18, 26, 31, 32, 33, 36, 37, 38, 39, 40], "learnedpositionencod": [2, 32], "least": 35, "legaci": 7, "lei": 38, "len": 18, "length": [0, 12, 18, 25, 26, 27, 29, 32, 34, 35, 39], "let": [1, 39], "level": [12, 13, 16], "leverag": 9, "librari": [2, 4, 6], "librilight": 16, "libsndfil": [5, 6], "libsndfile1": 5, "lightweight": 9, "like": [4, 5, 6, 13, 14, 19, 23, 35], "line": [1, 14, 24, 31, 39], "linear": 33, "link": 39, "lint": 7, "linter": 6, "linux": 6, "list": [0, 1, 7, 13, 15, 18, 19, 23, 26, 27, 39], "listen": 40, "liter": 25, "liu": 38, "ll": 39, "llama": [0, 9, 24, 38, 39], "llama2": 0, "llama2_13b": 0, "llama2_13b_chat": 0, "llama3": 25, "llama3_1_8b_instruct": 2, "llama3_2_1b": [25, 39], "llama3_2_1b_instruct": [1, 25], "llama3_70b": 39, "llama3_8b": [0, 23, 39], "llama3_8b_instruct": 0, "llamaropescaleconfig": 25, "llion": 38, "llm": [0, 40], "lm": [1, 40], "lm_train_dataset": 1, "lmtrainconfig": 1, "lmtraindataset": 1, "lmtraindatasetconfig": 1, "lmtraindatasetsect": 1, "lmtrainrecip": 1, "lmtrainunit": 1, "load": [0, 1, 6, 9, 10, 11, 12, 13, 15, 25], "load_custom_model": [23, 26, 39], "load_custom_token": [13, 14, 25], "load_model": [2, 7, 24, 25, 26, 39], "load_token": [14, 25, 26], "loader": [0, 1, 2, 3, 12], "local": [0, 7, 13, 14, 16, 19, 40], "localhost": 4, "locat": [0, 16, 39], "log": [1, 3, 20], "logic": [1, 39], "long": [25, 26, 29, 32], "longer": [9, 32], "look": [0, 39], "lookup": 9, "loos": 2, "loss": 1, "lower": 35, "lr_schedul": 1, "lrschedulersect": 1, "lssf": 7, "lto": 6, "lu": 38, "lukasz": 38, "m": [0, 1, 4, 6, 7, 14, 24, 26, 29, 34, 39, 40], "machin": [0, 6, 12, 24, 37, 40], "maco": 6, "made": 4, "mai": [9, 27, 39], "main": [0, 1, 4, 13, 14, 15, 23, 39, 40], "maintain": [3, 19], "major": [2, 9], "make": [0, 2, 4, 6, 9, 16, 19, 27, 39], "manag": [0, 1, 2, 3, 6, 7, 10, 11, 13, 15, 16, 17, 19, 37], "mani": [9, 19], "manual": 6, "manylinux_2_28_": 6, "map": [0, 1], "mari": 38, "mark": 27, "marker": 25, "martinet": 38, "masked_batch": [27, 35], "masked_fil": 27, "match": [0, 4, 5, 6, 7, 16, 18, 29, 39], "mathcal": [28, 33], "matter": 1, "max": [19, 27], "max_len": 27, "max_length": 0, "max_mask_prob": 35, "max_num_step": 29, "max_seq_len": [0, 23, 25, 26, 27, 32, 39], "maxim": 1, "maximum": [25, 26, 29, 32, 39], "maybe_get_st": 29, "maybe_raise_param_group_length_error": 18, "me": 25, "mean": [2, 4, 5, 19, 25, 31, 38], "meaning": 0, "meantim": [10, 11, 17, 21, 22, 36, 37], "mechan": 16, "mel": 12, "memori": [1, 12, 14, 19, 26, 27, 28], "mermaid": 7, "messag": [0, 25], "meta": [0, 25, 40], "metadata": [0, 10, 11, 27, 39], "meth": 1, "method": [1, 2, 13, 14, 15, 23, 25, 29, 31, 39], "metric": [1, 20], "metric_bag": 1, "metricbag": [1, 9], "mfcc": 12, "michael": 38, "might": [4, 5], "mileston": 9, "min": [9, 19, 27], "min_num_span": 35, "min_seq_len": 27, "minim": [1, 2], "minut": 19, "mismatch": 7, "mistral": [0, 24, 39], "mistral_7b": [23, 39], "mistral_8x7b": 39, "mix": 7, "mkdir": 7, "mlm": 35, "mmap": 23, "mode": [6, 7, 9, 14, 26, 27, 29, 32], "model": [1, 2, 3, 7, 8, 10, 11, 12, 13, 15, 19, 30, 34, 38], "model_arch": [0, 23, 24, 39], "model_config": 0, "model_dim": [25, 26, 39], "model_famili": [0, 24, 39], "modelarchitecturenotknownerror": 23, "modelconfigt": [23, 25, 26], "modelfamilynotknownerror": 23, "modelhub": [25, 26], "modelnotknownerror": [23, 39], "modelsect": 1, "modelt": [23, 25, 26], "modern": 7, "modifi": [2, 3, 4, 6, 23, 26, 39], "modul": [0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37], "moham": 38, "monolith": 2, "more": [0, 1, 2, 3, 4, 6, 9, 14, 16, 19, 23, 26, 27, 29, 39, 40], "most": [1, 4, 6, 16, 39], "mqa": 39, "much": 1, "multi": [0, 31, 40], "multihead": 2, "multiheadattent": [2, 27], "multilingu": [14, 26], "multipl": [0, 2, 14, 19, 25, 29, 39], "multipli": 25, "murtadha": 38, "must": [4, 5, 6, 16, 19, 26, 29, 35, 39], "mutual": 7, "my": [0, 7, 23, 26, 39], "my_advanced_open": 16, "my_asset": 0, "my_clust": 0, "my_custom_arch_vari": 3, "my_custom_dataset": 0, "my_custom_llama": 0, "my_custom_model": [0, 1, 3], "my_data_family_nam": 15, "my_dataset": [0, 15, 16], "my_dataset_famili": 15, "my_extens": 3, "my_in_mem_sourc": 0, "my_model": [0, 39], "my_model_nam": 0, "my_packag": [0, 3], "myclust": 16, "myconfig": 15, "mycustommodel": [1, 3], "mycustommodelconfig": [1, 3], "mydataset": [0, 15, 16], "mydatasetconfig": [0, 15, 16], "mylelrconfig": 18, "mypi": [4, 7], "myrecip": 0, "myst": 7, "myvenv": 6, "n": [0, 28, 29, 32, 34, 35, 38], "naman": 38, "name": [0, 1, 3, 6, 7, 13, 14, 15, 16, 18, 19, 23, 25, 26, 39], "nativ": [4, 5, 6, 9], "navig": 39, "nbsphinx": 7, "nc": 40, "nccl": 19, "nearest": 25, "necessari": [6, 9, 39], "need": [0, 1, 4, 9, 16, 23, 27, 29, 38, 39, 40], "network": [2, 12, 25, 26, 30, 36, 39], "neural": [12, 30, 36], "new": [1, 2, 3, 4, 6, 7, 18, 19, 23, 25, 26, 29, 39], "new_model": 39, "new_ord": 29, "newli": [23, 39], "next": 29, "nf": 9, "nightli": [4, 5, 6], "niki": 38, "ninja": 6, "nll_loss": 1, "nllb": 24, "nlp": 9, "nltk": 7, "nn": [9, 12, 20, 26, 27, 28, 29, 31, 32, 33, 34], "noam": 38, "node": [19, 40], "non": 19, "non_existent_dataset": 15, "none": [0, 1, 2, 3, 13, 14, 16, 19, 23, 25, 26, 27, 28, 29, 31, 32, 33, 35], "nonexistent_model": 23, "normal": [26, 30, 38, 40], "normalized_shap": 31, "nosan": 6, "note": [6, 16, 35, 39], "notebook": 7, "novel": 2, "now": [0, 9], "ntask": 40, "num_attn_head": [25, 26, 39], "num_embed": 28, "num_head": 27, "num_key_value_head": [25, 26, 39], "num_lay": [25, 26, 39], "num_param_group": 18, "num_step": 1, "num_warmup_step": 1, "number": [14, 18, 19, 25, 26, 29, 32, 35, 39], "numel": 39, "numer": [9, 31], "nvidia": [6, 7], "o": 40, "object": [1, 2, 3, 14, 16, 18, 19, 25, 26, 27, 29, 35], "object_nam": 16, "observ": 4, "obtain": 40, "off": [6, 27], "offer": [9, 13, 15, 40], "offlin": 9, "onboard": 9, "onc": [1, 4, 6, 40], "one": [2, 4, 6, 35, 40], "onli": [0, 1, 2, 4, 7, 9, 16, 25, 27, 29, 39, 40], "onlin": [8, 9], "op": 19, "open": [0, 1, 3, 4, 15, 38, 40], "open_custom_dataset": [15, 16], "open_dataset": 15, "open_lm_train_dataset": 1, "open_my_dataset": 0, "oper": [9, 12, 14, 17, 19, 23, 24, 26, 27, 30, 32], "optim": [1, 12, 27], "optimizersect": 1, "option": [0, 1, 4, 7, 16], "orchestr": 2, "order": [0, 2, 4, 29], "org": [6, 7, 38, 39], "organ": [0, 9, 20], "other": [0, 1, 3, 6, 8, 10, 12, 16, 17, 26, 30, 36, 39, 40], "otherwis": [4, 5, 25, 26], "our": [1, 4, 8, 40], "out": [4, 6, 33], "output": [0, 1, 19, 25, 26, 27, 29, 31, 33, 34, 39], "output_dim": 33, "output_dir": 40, "output_tensor": 19, "over": [4, 9, 19, 28, 31], "overal": 9, "overhaul": 9, "overhead": 9, "overlap": 35, "overrid": [1, 6, 16], "overridden": [0, 16, 33], "overview": 23, "own": [1, 8, 14, 23, 25, 26, 31], "p": [4, 39, 40], "pack": [1, 9, 27], "packag": [0, 3, 4, 6, 7], "packed_layout": 27, "packed_memori": 27, "pad": [9, 14, 25, 27, 35], "pad_idx": [14, 25, 28], "padded_layout": 27, "padded_memori": 27, "padding_mask": [27, 35], "page": 8, "pan": 38, "pane": 40, "paper": [32, 39], "parallel": [1, 19, 25], "param": 26, "param_group": 18, "paramet": [1, 3, 14, 16, 18, 19, 23, 25, 26, 28, 29, 31, 32, 33, 34, 35, 40], "parent": 0, "pariti": 9, "parmar": 38, "parquet": 12, "parquetdataset": 12, "pars": 1, "parser": 7, "part": [16, 19], "parti": [6, 9], "partition": 9, "pass": [3, 4, 6, 27, 32], "past": 2, "path": [13, 14, 16, 23, 25, 26], "pathlib": [0, 14, 23, 25, 26, 39], "pattern": [0, 1, 19, 25], "pdb": 40, "pedant": 4, "pep517": 6, "per": [0, 25, 40], "perform": [1, 12, 19, 21], "persist": 4, "person": 0, "phase": 2, "philosophi": [1, 3, 8, 39, 40], "picklabl": 19, "pin": [1, 7, 14, 26], "pin_memori": [14, 26], "pip": [4, 5, 7, 40], "pipelin": [1, 9, 19, 30, 37], "pkg": [4, 5, 7], "place": 4, "plan": [4, 6], "plat": 6, "pleas": [0, 4, 6, 9, 10, 11, 17, 21, 22, 24, 36, 37, 40], "pluggabl": [1, 2], "point": [3, 39], "polosukhin": 38, "port": 40, "portion": [4, 6], "pos_encod": 32, "pos_indic": 27, "posit": [2, 25, 26, 29, 30, 38, 39], "position_indic": [27, 35], "positionencod": [2, 32], "possibl": [2, 4], "post": 9, "post1": 7, "potenti": 16, "power": [1, 2], "pp": 19, "pre": [4, 5, 6, 10, 24, 26, 30, 37], "prealloc": 29, "prefetch": 1, "prefix": 14, "prefix_indic": 14, "prepar": [25, 26], "preprocess": [1, 12], "prereleas": 7, "prerequisit": [39, 40], "present": 29, "preset": 39, "press": 40, "pretrain": [0, 1, 9], "pretrained_llm": [13, 14], "pretti": 4, "prevent": [7, 9, 40], "preview": 1, "previou": 29, "primit": 19, "principl": [1, 2], "print": [0, 2, 7, 13, 14, 15, 19, 23, 24, 26, 27, 31, 39], "priorit": 4, "prioriti": 19, "probabl": [25, 26, 35, 39], "problem": 4, "process": [1, 4, 5, 7, 19, 26, 30, 39, 40], "process_batch": [1, 27], "processgroup": 19, "processgroupgang": 19, "produc": 29, "product": [0, 7, 19], "programmat": 14, "progress": [13, 23], "project": [3, 4, 6, 25, 26, 30, 39], "prompt": 25, "prompt_encod": 25, "prompt_respons": 25, "proper": [1, 32, 35, 39], "properli": 39, "properti": [1, 14, 19, 26, 27, 29], "protocol": [2, 35], "provid": [0, 1, 2, 3, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 36, 37, 39], "pt": [0, 9, 23, 26, 39], "pt2": [4, 5, 7], "ptx": 6, "public": 4, "publish": 4, "pudb": 8, "pure": 4, "purpos": 0, "put": [3, 19], "py": [1, 3, 7, 39], "pyarrow": 7, "pyproject": [3, 7], "pytest": [4, 6, 7], "python": [0, 1, 3, 4, 7, 12, 14, 24, 39, 40], "python3": 6, "python_vers": 6, "pytorch": [2, 4, 7, 9, 19, 27, 32, 39], "q": 40, "q_norm": 26, "qkv_proj_bia": [26, 39], "qualiti": [7, 9], "qualnam": 19, "queri": [0, 25, 26, 39], "quick": [1, 39], "quickli": 9, "quit": 40, "qwen": [0, 9, 13, 14, 24, 39], "qwen2": [0, 26, 39], "qwen25_0": 23, "qwen25_1": 23, "qwen25_14b": [26, 39], "qwen25_1_5b": 26, "qwen25_32b": 26, "qwen25_3b": [23, 26, 39], "qwen25_3b_instruct": 39, "qwen25_7b": [0, 23, 24, 26], "qwen25_7b_instruct": 0, "qwen3": [0, 13, 14, 26], "qwen3_0": [13, 14, 24, 26, 39], "qwen3_1": 26, "qwen3_14b": 26, "qwen3_32b": 26, "qwen3_4b": 26, "qwen3_8b": [0, 26, 39], "qwen_checkpoint": 26, "qwen_hf_checkpoint": 26, "qwenconfig": 39, "qwentoken": [13, 14], "qwentokenizerconfig": [13, 14], "r": [4, 5, 6], "race": 9, "rais": [3, 13, 15, 18, 23, 32], "randint": 28, "randn": [27, 32, 35], "random": [35, 39], "random_mask": 35, "rang": [9, 39], "rank": [1, 19, 40], "rate": [1, 18, 36], "raw": [14, 26], "rdp": 19, "re": [4, 31, 39], "reach": 40, "read": [1, 4, 6, 9, 16], "read_fil": 1, "read_sequ": 1, "readabl": [4, 39], "reader": 1, "readi": 1, "readm": 4, "real": 6, "rearrang": 29, "reason": [4, 5, 6], "receiv": 29, "recip": [0, 8, 16, 20, 40], "recipecontext": 1, "recipemodel": 1, "recogn": 39, "recognit": 24, "recommend": [6, 7, 16, 25], "recurs": [6, 16], "reduc": [9, 19, 26], "reduceoper": 19, "reduct": 19, "redund": 2, "refer": [1, 2, 9, 10, 11, 14, 15, 17, 21, 22, 23, 25, 26, 32, 36, 37, 39, 40], "refrain": 4, "regex": 25, "regim": 1, "regimesect": 1, "regist": [0, 1, 2, 3, 13, 15, 16, 23, 39], "register_dataset_famili": [0, 1, 3, 16], "register_file_asset": [0, 3], "register_in_memory_asset": 0, "register_model_famili": [1, 3], "register_package_asset": [0, 3], "register_tokenizer_famili": [1, 3], "registr": 39, "registri": [2, 10], "regular": 9, "reinstal": 7, "rel": [0, 16, 32], "relat": [0, 39], "relationship": 0, "releas": [4, 5, 6, 9], "relev": [0, 9], "reli": [4, 5], "reliabl": 7, "remark": 1, "reorder": 29, "replac": [5, 40], "replic": 19, "repo": [7, 40], "report": [4, 22], "repositori": [0, 2, 4], "repr": 26, "repres": [9, 14, 19, 28, 34], "represent": [31, 38], "reproduc": [4, 7], "request": [9, 23, 39], "requir": [0, 4, 5, 6, 7, 9, 19, 27, 39], "research": [2, 8], "reserv": 29, "reset_non_persistent_buff": 32, "reset_paramet": [28, 31, 32, 33], "reshard": 9, "residu": 30, "residualconnect": 34, "resolut": [2, 7], "resolv": [1, 2, 7, 16, 25], "resourc": [0, 2, 40], "respect": [2, 32], "rest": 2, "restart": [7, 39], "result": [26, 27], "resum": 11, "retrain": 9, "retriev": [2, 16], "retrieve_card": [0, 2, 24], "return": [0, 1, 2, 3, 13, 14, 16, 18, 19, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 39], "reus": 6, "revers": 40, "review": 39, "revis": [4, 9], "rf": 7, "rico": 38, "rm": 7, "rmsnorm": 31, "road": 25, "robust": 9, "rodriguez": 38, "roform": 38, "role": 25, "root": [4, 6, 19, 31, 38], "root_gang": 19, "rope": 39, "rope_scal": 25, "rope_theta": [25, 26, 39], "rotari": [25, 26, 38], "rotaryencod": [2, 32], "round": 25, "row": 35, "row_len": 35, "rowmaskfactori": 35, "rozi\u00e8r": 38, "rst": 4, "ruff": 7, "run": [4, 5, 6, 7, 9, 19, 26], "runner": 2, "runtim": [0, 2, 4, 8, 16], "ryan": 38, "safe": 1, "safetensor": [0, 39], "safeti": 1, "salloc": 40, "same": [0, 4, 5, 6, 19, 31, 32, 33, 34, 35, 39], "sampl": 12, "sampler": 12, "sanit": 6, "save": [1, 9, 11, 27], "scale": [19, 25, 34], "scaledresidualconnect": 34, "scenario": [19, 39], "scene": 14, "schedul": [1, 18, 36], "scheme": 9, "scope": 4, "scratch": [6, 9], "screenshot": 40, "script": [3, 6], "scriptmodul": [28, 31, 32, 33, 34], "sdp": 19, "seamless": [9, 12, 16], "seamlessli": 27, "search": [0, 8, 29], "second": [19, 39], "section": [1, 7, 16, 20, 32], "see": [6, 7, 29, 39], "segfault": [4, 5], "select": [1, 17, 29], "self": [0, 1, 2, 16, 27, 38], "self_attn": 2, "self_attn_layer_norm": 2, "sennrich": [31, 38], "sensibl": 1, "sent": 19, "sentencepiec": [0, 14, 25], "separ": [0, 7], "seq": [1, 27, 28, 32, 34, 35], "seq_begin_indic": 27, "seq_begin_indices_pt": 27, "seq_boundari": 27, "seq_len": [1, 27, 28, 32, 35], "seq_lens_pt": [27, 35], "seq_lens_tensor": 27, "seqs_layout": [1, 26, 32], "sequenc": [0, 1, 2, 8, 12, 14, 18, 19, 25, 26, 29, 31, 32, 34, 35], "sequencebatch": 1, "seri": 26, "serv": 9, "server": 4, "servic": 16, "session": [39, 40], "set": [0, 1, 2, 3, 7, 9, 16, 19, 25, 29, 39, 40], "set_stat": 29, "set_trac": 40, "setup": [5, 19], "setup_fs2_extens": 0, "setup_my_fairseq2": 0, "setup_my_fairseq2_extens": 3, "setuptool": [0, 3], "sever": [2, 25, 26, 40], "sh": [6, 7], "shape": [14, 23, 27, 28, 29, 31, 32, 33, 34, 35], "shard": [1, 19, 25, 28], "shard_embed_dim": 25, "shard_spec": 26, "shardedembed": 28, "shardspec": 26, "share": [28, 31, 32, 33, 34, 39], "shazeer": 38, "shell": 7, "shengfeng": 38, "short": [4, 6, 9], "shorter": 0, "should": [4, 9, 19, 25, 29, 31, 39], "show": [0, 1, 2, 3, 32, 39, 40], "showcas": 1, "shown": 6, "shuffl": 12, "shutdown": 1, "signific": 9, "significantli": [2, 9], "similar": [6, 9, 14], "similarli": 6, "simpl": [1, 3, 16, 39], "simpler": 27, "simplest": 6, "simpli": [4, 5], "simplif": 9, "simplifi": [1, 2, 9, 26], "simul": 19, "sinc": [4, 40], "singl": [0, 1, 2, 9, 19, 27, 31], "singleton": 2, "sinusoid": 32, "sinusoidalpositionencod": [2, 32], "size": [0, 14, 19, 25, 26, 27, 28, 29, 31, 32, 34, 35, 39, 40], "size_byt": 29, "skeleton": 1, "skip_special_token": [14, 26], "slurm": 40, "smi": 7, "so": [1, 6], "solid": 7, "some": [13, 14, 25, 26, 39], "some_object": 16, "soon": [8, 10, 11, 12, 17, 21, 22, 36, 37], "sort": [1, 26], "sourc": [0, 1, 2, 4, 5, 7, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40], "source_rank": 19, "sp": 25, "sp_llama": 25, "span": 35, "span_len": 35, "special": [0, 9, 12, 29], "special_tokens_map": 25, "specif": [1, 2, 4, 5, 6, 9, 13, 15, 16, 19, 23, 26, 35, 37, 39], "specifi": [0, 1, 7, 14, 19, 25, 26, 28, 35, 39, 40], "spectrogram": 12, "speech": [24, 38], "sphinx": [4, 7], "sphinxcontrib": 7, "split": [1, 19], "split_group": 19, "split_regex": 25, "spuriou": [4, 5], "sqrt": 33, "squar": [31, 38], "src": [7, 24, 39], "srun": 40, "stabil": [3, 31], "stack": 25, "stai": 9, "standalon": 3, "standard": [0, 6, 25, 26, 27, 40], "standardembed": 28, "standardlayernorm": 31, "standardtransformerdecoderlay": 2, "start": [1, 2, 19, 40], "start_header_id": 25, "start_lr": 18, "state": [9, 26, 28, 30, 31, 32, 33, 34], "state_bag": 32, "state_dict": 26, "static": [27, 28], "step": [6, 29], "step_nr": [29, 32], "stop": 40, "store": [1, 10, 13, 15, 23, 28, 29], "str": [1, 14, 18, 23, 24, 25, 26, 31], "straightforward": [1, 6, 39], "strategi": [12, 19, 27], "stream": [12, 19], "streamlin": 9, "strict": 26, "string": [26, 31, 39], "strong": 1, "strongli": 6, "structur": [0, 1, 21, 25, 39], "stty": 40, "studi": 4, "su": [32, 38], "subclass": [2, 9, 14, 26, 33], "submit": 4, "submodul": 6, "subsystem": 5, "success": 39, "sudo": [5, 6], "suffici": [4, 6, 16], "suffix": [0, 14], "suffix_indic": 14, "suit": [4, 6], "sum": [19, 27, 34, 39], "summar": 8, "super": 27, "supervis": 38, "support": [0, 1, 2, 6, 7, 12, 16, 18, 19, 26, 27, 39, 40], "supports_process_group": 19, "sure": [4, 6, 19], "swap": 1, "switch": 7, "sy": 26, "symbol": [14, 25, 26], "sync": 7, "synchron": 19, "syntax": [0, 4, 39], "system": [1, 2, 3, 4, 5, 10, 12, 13, 15, 16, 19, 23, 25, 26, 27, 30, 37, 39], "t": [4, 16, 29, 40], "t_co": 2, "tabl": [25, 26, 28, 32], "take": [16, 29], "target": [1, 14, 26], "target_batch": 1, "task": [0, 2, 8, 14, 16, 24, 26, 37, 40], "team": 9, "technic": [2, 32], "tell": [25, 39], "tensor": [1, 9, 14, 17, 19, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35], "tensorboard": 7, "term": [25, 26, 29, 32], "term_siz": 40, "termin": 40, "test": [0, 2, 6, 7, 39], "testabl": 9, "text": [13, 14, 25, 26, 28, 33], "than": [4, 32, 35], "thank": 9, "them": [4, 6, 19, 34, 39], "therefor": 28, "theta": [32, 39], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 28, 29, 31, 33, 36, 37, 39, 40], "thibaut": 38, "third": 6, "three": 0, "through": [1, 2, 3, 16, 25, 26, 39], "throughout": 1, "throughput": [9, 12], "thu": 29, "ti": [1, 25, 26], "tidi": 4, "tie": 39, "tied_embed": [25, 26, 39], "tiedproject": 33, "tightli": 9, "tiktoken": 14, "tiktoken_llama_instruct": 25, "time": [4, 29], "timedelta": 19, "timeout": 19, "timoth\u00e9": 38, "to_batch": 1, "to_embed": 28, "todo": 1, "togeth": [1, 19, 39], "token": [0, 1, 3, 9, 10, 12, 15, 23, 28, 39], "tokendecod": [14, 26], "tokenencod": [14, 26], "tokenizer_config": [0, 25, 39], "tokenizer_config_overrid": 25, "tokenizer_famili": [0, 25, 39], "tokenizer_hub": 26, "tokenizerconfigt": [13, 25, 26], "tokenizerhub": [25, 26], "tokenizerhubaccessor": 14, "tokenizersect": 1, "tokenizert": [13, 25, 26], "toml": [3, 7], "too": 4, "tool": [4, 6, 7, 12], "toolkit": [4, 6, 8, 9], "top": 16, "torch": [1, 6, 7, 9, 18, 26, 28, 29, 32, 33, 35], "torch_vers": 6, "torchaudio": 7, "torchvis": 7, "total": [19, 25, 27], "touch": [3, 4], "touvron": [25, 38], "tp": 19, "tp_size": 19, "trace": 3, "track": [0, 4, 22, 29], "trade": 27, "train": [0, 1, 7, 8, 9, 10, 11, 12, 19, 22, 24, 26, 27, 28, 30, 35, 36, 37, 40], "train_main": 1, "train_model": 7, "trainer": 1, "trainersect": 1, "trainrecip": [0, 1, 16], "trainunit": 1, "transcript": [14, 26], "transform": [0, 12, 25, 26, 30, 31, 33, 34, 38, 39], "transformer_lm": 0, "transformerdecoderlay": 2, "transformerlm": 26, "translat": [8, 14, 24, 26], "tree": 4, "tricki": 6, "troubleshoot": 9, "true": [13, 14, 19, 23, 25, 26, 27, 31, 33], "try": [0, 15, 23, 39], "tune": [0, 9], "tupl": 1, "turn": [6, 25], "tutori": [1, 9, 23, 25, 26, 39, 40], "two": [3, 4, 19, 39], "txt": [4, 5, 6], "type": [0, 1, 2, 9, 12, 13, 14, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 39], "typic": [6, 14, 26, 29], "u": [14, 26, 33], "ubuntu": [5, 6], "under": [4, 9, 27], "underli": [19, 39], "understand": [23, 25, 26], "unifi": [0, 9, 17, 23, 27, 30, 39], "uniform": 27, "uniniti": 23, "uniqu": [0, 19], "unit": [1, 4, 9], "unk": 14, "unk_idx": 14, "unknown": 14, "unknown_famili": 15, "unless": [6, 33], "unmask": 35, "unsqueez": 27, "up": [0, 2, 3, 7, 9, 19, 25], "updat": [1, 4, 6, 8, 9, 28], "update_nll_loss_metr": 1, "update_seq_batch_metr": 1, "upgrad": [4, 5, 9], "uri": 0, "url": [0, 4, 5, 6, 7, 38], "us": [0, 1, 2, 3, 4, 5, 6, 7, 9, 13, 15, 16, 18, 19, 23, 26, 27, 28, 29, 32, 33, 39, 40], "usag": [1, 7, 9, 13, 15, 16, 19, 28, 32, 35], "use_eot": 25, "use_im_end": [0, 26, 39], "use_scaled_rop": 25, "user": [0, 4, 6, 7, 16, 25, 39], "usual": 40, "uszkoreit": 38, "util": [1, 11, 12, 17, 21, 22, 24, 25, 26, 27, 30, 36, 40], "uv": 5, "v": [7, 27], "v0": [1, 2, 7, 8, 27], "v04": 7, "valid": [1, 14, 26, 27], "validationerror": 18, "valu": [1, 18, 19, 25, 26, 29, 31, 39], "valueerror": 32, "vari": 39, "variabl": [0, 3, 12, 27], "variant": [0, 4, 6, 7, 16, 39], "variou": [0, 9, 12, 16, 24, 30], "varlen": 9, "vaswani": 38, "ve": [1, 4], "venv": [6, 7], "verif": 39, "verifi": 7, "version": 26, "via": [0, 1, 2, 4, 6, 13, 16, 25], "view": 40, "virtual": 2, "visit": 4, "vllm": [7, 9], "vocab_info": [14, 26], "vocab_s": [25, 26, 39], "vocabulari": [14, 25, 26, 28], "vocabularyinfo": [14, 26], "volta": 6, "vstack": 26, "w": 16, "wa": 6, "wai": [3, 13, 15, 17], "wait": 40, "walk": 39, "want": [4, 6, 14, 39, 40], "warn": 3, "wast": 27, "wav2vec": 38, "wav2vec2": 24, "wav2vec2_larg": 0, "wav2vec2_large_lv60k": 0, "we": [1, 4, 6, 19, 40], "websit": 6, "weight": [25, 33, 39], "well": 2, "wen": 38, "what": [1, 2, 8, 39, 40], "wheel": 6, "wheelhous": 6, "when": [0, 6, 7, 9, 13, 14, 15, 23, 25, 29, 32, 39], "where": [0, 3, 7, 14, 16, 28, 29, 31, 32, 33, 34, 35, 39, 40], "wherev": [2, 32], "whether": 25, "which": [1, 2, 3, 4, 5, 6, 14, 19, 25, 26, 28, 29, 31, 39, 40], "while": [9, 14, 16, 19, 26], "whl": [4, 5, 6, 7], "who": 6, "whose": [18, 19], "why": 25, "wide": [0, 16], "width": 27, "wire": [1, 2], "wise": 19, "within": [0, 2, 9], "without": [2, 3, 6, 23], "work": [0, 6, 7, 9, 12, 13, 14, 15, 17, 19, 25, 26], "workflow": [9, 12], "workload": 12, "world": [19, 25], "worldinfo": 2, "would": [6, 40], "wrap": 19, "write": 9, "wsl": 5, "x": [27, 28, 31, 33], "x86_64": 6, "xavier": 38, "xxxxx": 39, "yaml": [1, 3, 16, 39], "ye": 0, "yet": [4, 9], "yet_other_asset": [0, 1], "yield_from": 1, "you": [0, 1, 3, 4, 5, 6, 7, 14, 16, 24, 25, 31, 38, 39, 40], "your": [3, 5, 6, 7, 8, 14, 15, 16, 23, 25, 26, 31, 40], "your_packag": 1, "yourrecip": 16, "yourself": 40, "yu": 38, "yunfeng": 38, "zhang": [31, 38], "zhou": 38}, "titles": ["<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-container\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.41.24l4.711 2.774A1.767 1.767 0 0116 4.54v5.01a1.77 1.77 0 01-.88 1.53l-7.753 4.521-.002.001a1.767 1.767 0 01-1.774 0H5.59L.873 12.85A1.762 1.762 0 010 11.327V6.292c0-.304.078-.598.22-.855l.004-.005.01-.019c.15-.262.369-.486.64-.643L8.641.239a1.75 1.75 0 011.765 0l.002.001zM9.397 1.534a.25.25 0 01.252 0l4.115 2.422-7.152 4.148a.267.267 0 01-.269 0L2.227 5.716l7.17-4.182zM7.365 9.402L8.73 8.61v4.46l-1.5.875V9.473a1.77 1.77 0 00.136-.071zm2.864 2.794V7.741l1.521-.882v4.45l-1.521.887zm3.021-1.762l1.115-.65h.002a.268.268 0 00.133-.232V5.264l-1.25.725v4.445zm-11.621 1.12l4.1 2.393V9.474a1.77 1.77 0 01-.138-.072L1.5 7.029v4.298c0 .095.05.181.129.227z\"></path></svg> Assets", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-rocket\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z\"></path></svg> Building Recipes", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-infinity\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.5 6c-1.086 0-2 .914-2 2 0 1.086.914 2 2 2 .525 0 1.122-.244 1.825-.727.51-.35 1.025-.79 1.561-1.273-.536-.483-1.052-.922-1.56-1.273C4.621 6.244 4.025 6 3.5 6zm4.5.984c-.59-.533-1.204-1.066-1.825-1.493-.797-.548-1.7-.991-2.675-.991C1.586 4.5 0 6.086 0 8s1.586 3.5 3.5 3.5c.975 0 1.878-.444 2.675-.991.621-.427 1.235-.96 1.825-1.493.59.533 1.204 1.066 1.825 1.493.797.547 1.7.991 2.675.991 1.914 0 3.5-1.586 3.5-3.5s-1.586-3.5-3.5-3.5c-.975 0-1.878.443-2.675.991-.621.427-1.235.96-1.825 1.493zM9.114 8c.536.483 1.052.922 1.56 1.273.704.483 1.3.727 1.826.727 1.086 0 2-.914 2-2 0-1.086-.914-2-2-2-.525 0-1.122.244-1.825.727-.51.35-1.025.79-1.561 1.273z\"></path></svg> Design Philosophy", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-plug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.276 3.09a.25.25 0 01.192-.09h.782a.25.25 0 01.25.25v8.5a.25.25 0 01-.25.25h-.782a.25.25 0 01-.192-.09l-.95-1.14a.75.75 0 00-.483-.264l-3.124-.39a.25.25 0 01-.219-.249V5.133a.25.25 0 01.219-.248l3.124-.39a.75.75 0 00.483-.265l.95-1.14zM4 8v1.867a1.75 1.75 0 001.533 1.737l2.83.354.761.912c.332.4.825.63 1.344.63h.782A1.75 1.75 0 0013 11.75V11h2.25a.75.75 0 000-1.5H13v-4h2.25a.75.75 0 000-1.5H13v-.75a1.75 1.75 0 00-1.75-1.75h-.782c-.519 0-1.012.23-1.344.63l-.76.913-2.831.353A1.75 1.75 0 004 5.133V6.5H2.5A2.5 2.5 0 000 9v5.25a.75.75 0 001.5 0V9a1 1 0 011-1H4z\"></path></svg> Runtime Extension", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-heart\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z\"></path></svg> Contributing to fairseq2", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-download\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.47 10.78a.75.75 0 001.06 0l3.75-3.75a.75.75 0 00-1.06-1.06L8.75 8.44V1.75a.75.75 0 00-1.5 0v6.69L4.78 5.97a.75.75 0 00-1.06 1.06l3.75 3.75zM3.75 13a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5z\"></path></svg> Installation", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-file-binary\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0114.25 15h-9a.75.75 0 010-1.5h9a.25.25 0 00.25-.25V6h-2.75A1.75 1.75 0 0110 4.25V1.5H5.75a.25.25 0 00-.25.25v2a.75.75 0 01-1.5 0v-2zm7.5-.188V4.25c0 .138.112.25.25.25h2.688a.252.252 0 00-.011-.013l-2.914-2.914a.272.272 0 00-.013-.011zM0 7.75C0 6.784.784 6 1.75 6h1.5C4.216 6 5 6.784 5 7.75v2.5A1.75 1.75 0 013.25 12h-1.5A1.75 1.75 0 010 10.25v-2.5zm1.75-.25a.25.25 0 00-.25.25v2.5c0 .138.112.25.25.25h1.5a.25.25 0 00.25-.25v-2.5a.25.25 0 00-.25-.25h-1.5zm5-1.5a.75.75 0 000 1.5h.75v3h-.75a.75.75 0 000 1.5h3a.75.75 0 000-1.5H9V6.75A.75.75 0 008.25 6h-1.5z\"></path></svg> Installing from Source", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-lock\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 4v2h-.25A1.75 1.75 0 002 7.75v5.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 13.25v-5.5A1.75 1.75 0 0012.25 6H12V4a4 4 0 10-8 0zm6.5 2V4a2.5 2.5 0 00-5 0v2h5zM12 7.5h.25a.25.25 0 01.25.25v5.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-5.5a.25.25 0 01.25-.25H12z\"></path></svg> UV Setup", "Welcome to fairseq2 Documentation", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-report\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M1.75 1.5a.25.25 0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 01.75.75v2.19l2.72-2.72a.75.75 0 01.53-.22h6.5a.25.25 0 00.25-.25v-9.5a.25.25 0 00-.25-.25H1.75zM0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0114.25 13H8.06l-2.573 2.573A1.457 1.457 0 013 14.543V13H1.75A1.75 1.75 0 010 11.25v-9.5zM9 9a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z\"></path></svg> What\u2019s New in v0.5", "fairseq2.assets", "fairseq2.checkpoint", "fairseq2.data", "fairseq2.data.tokenizers.hub", "fairseq2.data.tokenizers", "fairseq2.datasets.hub", "fairseq2.datasets", "fairseq2.device", "fairseq2.recipe.optim", "fairseq2.gang", "API Reference", "fairseq2.logging", "fairseq2.metrics", "fairseq2.models.hub", "fairseq2.models", "fairseq2.models.llama", "fairseq2.models.qwen", "Batch Layout", "Embeddings", "Incremental State", "fairseq2.nn", "Normalization Layers", "Position Encoders", "Projection Layers", "Residual Connections", "fairseq2.nn.utils", "fairseq2.optim", "fairseq2.recipe", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-book\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M0 1.75A.75.75 0 01.75 1h4.253c1.227 0 2.317.59 3 1.501A3.744 3.744 0 0111.006 1h4.245a.75.75 0 01.75.75v10.5a.75.75 0 01-.75.75h-4.507a2.25 2.25 0 00-1.591.659l-.622.621a.75.75 0 01-1.06 0l-.622-.621A2.25 2.25 0 005.258 13H.75a.75.75 0 01-.75-.75V1.75zm8.755 3a2.25 2.25 0 012.25-2.25H14.5v9h-3.757c-.71 0-1.4.201-1.992.572l.004-7.322zm-1.504 7.324l.004-5.073-.002-2.253A2.25 2.25 0 005.003 2.5H1.5v9h3.757a3.75 3.75 0 011.994.574z\"></path></svg> Bibliography", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-ruby\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.637 2.291A.75.75 0 014.23 2h7.54a.75.75 0 01.593.291l3.48 4.5a.75.75 0 01-.072.999l-7.25 7a.75.75 0 01-1.042 0l-7.25-7a.75.75 0 01-.072-.999l3.48-4.5zM4.598 3.5L1.754 7.177 8 13.207l6.246-6.03L11.402 3.5H4.598z\"></path></svg> Add Your Own Model", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-bug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.72.22a.75.75 0 011.06 0l1 .999a3.492 3.492 0 012.441 0l.999-1a.75.75 0 111.06 1.061l-.775.776c.616.63.995 1.493.995 2.444v.327c0 .1-.009.197-.025.292.408.14.764.392 1.029.722l1.968-.787a.75.75 0 01.556 1.392L13 7.258V9h2.25a.75.75 0 010 1.5H13v.5c0 .409-.049.806-.141 1.186l2.17.868a.75.75 0 01-.557 1.392l-2.184-.873A4.997 4.997 0 018 16a4.997 4.997 0 01-4.288-2.427l-2.183.873a.75.75 0 01-.558-1.392l2.17-.868A5.013 5.013 0 013 11v-.5H.75a.75.75 0 010-1.5H3V7.258L.971 6.446a.75.75 0 01.558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.684 1.684 0 01-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 010-1.06zM6.173 5h3.654A.173.173 0 0010 4.827V4.5a2 2 0 10-4 0v.327c0 .096.077.173.173.173zM5.25 6.5a.75.75 0 00-.75.75V11a3.5 3.5 0 107 0V7.25a.75.75 0 00-.75-.75h-5.5z\"></path></svg> Debugging with PuDB"], "titleterms": {"": [9, 14, 19], "0": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "00": [0, 1, 3, 5, 6, 7, 9, 38, 40], "000": [3, 5, 6], "001": [1, 3, 4, 5, 9], "0010": 40, "0012": 7, "0013": 3, "0014": [1, 7], "0016": 1, "001a1": 0, "001zm9": 0, "002": [0, 4, 7, 38], "002a": 0, "002l8": 4, "002zm12": 1, "003": [4, 38], "003a": 1, "003h": 4, "004": [0, 3, 38], "005": [0, 1, 38], "006": [4, 38], "008": [4, 6], "009": 40, "01": [0, 1, 3, 4, 6, 7, 9, 38, 39, 40], "010": [0, 6, 9, 40], "011": [0, 3, 6, 38, 40], "0110": 6, "0111": 38, "0114": [1, 6, 9], "0116": 0, "011zm0": 6, "012": [1, 3, 9, 38, 40], "013": [6, 9, 40], "013l": 6, "014": 39, "018": [4, 40], "019c": 0, "01a1": 0, "01a7": 4, "02": [1, 4], "021": 0, "025": [2, 40], "026": 40, "029": [4, 40], "029v4": 0, "02l": 1, "03": 40, "037": 1, "03l11": 39, "042": 39, "045": 4, "046": 1, "047": 1, "049": 40, "05": 0, "051": 1, "052": 2, "058": 1, "06": [1, 5, 38, 40], "061l": 40, "063": 1, "064": 1, "066": 2, "066zm3": 1, "06l": 9, "06l3": 5, "06l8": 5, "06zm6": 40, "071zm2": 0, "072": 39, "072l1": 0, "073": 38, "075": 4, "077": 40, "078": 0, "079": 1, "08": 4, "086": [2, 4], "088": 1, "09": 1, "094": 1, "095": 0, "096": 40, "09a": 3, "09h": 3, "09l": 3, "0a8": 1, "0c6": 4, "0em": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "0h": 1, "0h12": 9, "0h5": [0, 6], "0l": [0, 4, 38, 39, 40], "0l1": 40, "0l2": 0, "0l3": 5, "0l4": 0, "0l8": 4, "0v": [6, 9, 40], "0v2": 9, "0v2h5zm12": 7, "0v6": 5, "0v7": 40, "0v9a1": 3, "0zm": [1, 9], "0zm6": 7, "1": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "10": [1, 4, 5, 6, 7, 40], "102": 1, "102a": 1, "103": 1, "107": 40, "11": [0, 1, 3, 4, 9], "111": 40, "112": [6, 9], "114": 2, "115": 0, "116l5": 1, "117": 1, "118": 1, "119": 1, "119l": 1, "11l3": 1, "11v": 40, "12": [0, 1], "122": 2, "123": 1, "124": [1, 3], "125l": 1, "127l": 1, "129": 0, "12c": 1, "12h": 6, "12l4": 0, "13": [4, 7, 39], "133": 0, "133a": 3, "133v6": 3, "135": 4, "136": 0, "138": [0, 6, 9], "13a": 5, "13h": 38, "13h8": 9, "14": [4, 9, 40], "141": 40, "143": 1, "144": 4, "145": 1, "145l2": 1, "148a": 0, "148z": 1, "14a": 3, "14zm4": 3, "15": [0, 1, 4], "152": 0, "153": 4, "15h": 6, "16": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "164": 4, "16a4": 40, "17": [0, 4, 40], "173": 40, "173zm5": 40, "175l": 1, "176": 1, "177": [1, 39], "178": 1, "181": 0, "182zm7": 0, "183": 40, "184": [6, 40], "186a": 1, "186a7": 1, "186l2": 40, "186zm10": 1, "187": 1, "188v4": 6, "192": 3, "197": 40, "19l2": 9, "1a": 40, "1h4": 38, "1h4z": 3, "2": [0, 1, 2, 3, 4, 6, 7, 9, 38, 39, 40], "20": 4, "201": 38, "203": 4, "204": 2, "207l6": 39, "21": 1, "211c12": 4, "213": 1, "213v": 1, "216": [6, 9], "219": 3, "22": [0, 4], "227": [0, 38], "227z": 0, "22a": 40, "22h6": 9, "23": [1, 3, 39], "231": 4, "232v5": 0, "235": 2, "237": 6, "237v8": 6, "239a1": 0, "244": 2, "245a": 38, "246": 39, "248l3": 3, "249v5": 3, "24l4": 0, "25": [0, 1, 3, 4, 6, 7, 9, 38, 39, 40], "252": [0, 6], "253a2": 38, "253c1": 38, "258": 38, "258l": 40, "258v9h2": 40, "25a": [3, 6, 7, 9, 40], "25a1": 7, "25c0": 6, "25h": [3, 6, 7], "25h1": [6, 9], "25h12z": 7, "25h14": 38, "25h2": 6, "25h2a": 9, "25l": 4, "25v": [1, 6, 7, 9], "25v1": 6, "25v2": 6, "25v2a": 6, "25v5": 7, "25v6h": 6, "25v8": 3, "25v9": 9, "25z": 4, "25zm0": 4, "26": 1, "262": 0, "264l": [0, 3], "265": [1, 40], "265c": 1, "265l": 3, "266": 1, "266h3": 1, "267": 0, "268": 0, "269": 0, "272": 6, "273": [1, 2], "273c4": 2, "273z": 2, "276": 3, "288": [1, 40], "28a": 40, "291a": 39, "291l3": 39, "292": 40, "292c0": 0, "292v4": 40, "298c0": 0, "2a": 1, "2h7": 39, "2v4a2": 7, "2zm7": 6, "3": [1, 2, 3, 4, 5, 6, 38, 39, 40], "304": 0, "309a": 1, "31": 4, "314": 1, "317": [1, 38], "317a15": 1, "31a1": 1, "322zm": 38, "324l": 38, "327c0": 40, "327v6": 0, "328": 6, "329": 6, "33": 40, "332": [1, 3], "336": 4, "338": 1, "344": 3, "345": 4, "35": [1, 2, 4], "353a1": 3, "354": 3, "365": [0, 4], "369": 0, "373": 4, "38": 40, "392": 40, "392l": 40, "392l1": 40, "392l13": 40, "392l2": 40, "393a20": 4, "393v9": 0, "397": 0, "39a": 3, "3a2": 38, "4": [0, 1, 2, 3, 4, 6, 7, 38, 39, 40], "402": 39, "402l8": 0, "408": 40, "409": 40, "41": 0, "414": 4, "414c2": 4, "416": 1, "418": 1, "418l2": 1, "422": 0, "427": 2, "427l": 40, "428c": 1, "429": 1, "434": 4, "44": 1, "441": 40, "442": 4, "443": 2, "444": 2, "444l4": 40, "444v": 40, "445zm": 0, "446a": 40, "44v1": 5, "456a": 4, "457": 9, "458": 1, "458a15": 1, "458c": 1, "458h": 1, "459": 1, "459a8": 1, "45l": 0, "464": 6, "46l": 0, "47": 5, "473a1": 0, "474a1": 0, "48": 39, "483": [2, 3], "485c": 1, "486": [0, 4], "49": 1, "492": 40, "493": [2, 40], "493a7": 1, "493zm9": 2, "499": 1, "49v9": 1, "4h2": 3, "4v2h": 7, "5": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 40], "501a3": 38, "504": 38, "507a2": 38, "51": 2, "513": 6, "513l2": 6, "519": 3, "521": [0, 1], "525": 2, "53": 9, "533": [2, 3], "534a": 0, "536": 2, "53l": 0, "543v13h1": 9, "547": 2, "547zm5": 1, "548": [1, 2], "54a": 39, "54v5": 0, "556": 40, "557": 40, "558": 40, "56": 2, "561": [2, 4], "563l": 1, "565": 4, "56a1": 1, "572l": 38, "573": 9, "573a1": 9, "574z": 38, "58": 4, "583": 40, "584l": 4, "586": 2, "586a1": 6, "586c": 6, "59": [1, 2, 38], "591": 38, "593": 39, "598": [0, 39], "598z": 39, "59l": 0, "5a": [3, 5, 6, 7, 9, 38, 39, 40], "5a1": [1, 6, 7, 9], "5a2": [3, 40], "5c": [2, 4], "5c0": [4, 6, 7, 9, 40], "5c15": 9, "5c4": 6, "5h": [1, 5, 6, 7, 40], "5h1": 38, "5h13v": [3, 40], "5h2": 3, "5h3": 40, "5h3a": 6, "5h3v7": 40, "5h4": 39, "5h5": 6, "5h8": 5, "5h9a": 6, "5h9v6": 6, "5l": 1, "5l1": 39, "5v9h": 38, "5v9h3": 38, "5z": [5, 6, 9, 40], "5zm1": 6, "5zm4": 39, "5zm5": 6, "5zm8": 4, "5zm9": 9, "6": [1, 2, 4, 6, 39, 40], "607a": 1, "609": 4, "616": [1, 40], "61v4": 0, "62": 40, "621": [0, 2], "621a": 38, "621a2": 38, "622": 38, "623": 4, "625c": 1, "63": [3, 40], "637": 39, "63h": 3, "63l": 3, "64": 0, "641": [0, 1], "643": 4, "643l8": 0, "644": 4, "65": 4, "654a": 40, "659l": 38, "65h": 0, "665": 1, "666": 4, "666a": 4, "671": 1, "675": 2, "678": 1, "682a20": 4, "684": 40, "688a": 6, "69": 4, "69l4": 5, "6c": 2, "6h": 6, "6h1": 6, "6h12v4a4": 7, "6zm4": 2, "7": [0, 1, 2, 4, 6, 7, 38, 39, 40], "704": 2, "707a1": 1, "71": 38, "711": 0, "716l7": 0, "72": [9, 40], "722a1": 40, "722l1": 40, "725v4": 0, "727": 2, "72a": 9, "73": [0, 1], "731": 4, "734": 1, "737l2": 3, "741l1": 0, "744": [4, 38], "75": [0, 1, 3, 4, 5, 6, 7, 9, 38, 39, 40], "752": 4, "753": 0, "754": 39, "755": 38, "757a3": 38, "757c": 38, "75a": [5, 6, 38, 40], "75a1": [1, 3, 6, 9], "75c0": [6, 9], "75c4": 6, "75h": [3, 38, 40], "75h8": 7, "75v1": 38, "75v10": 38, "75v11a3": 40, "75v11h2": 3, "75v2": [6, 9], "75v3h": 6, "75v5": 7, "75v9": 9, "75zm0": 9, "75zm3": 5, "75zm8": 38, "76": 3, "761": 3, "762": 0, "762l1": 0, "764": 40, "765": 0, "766c": 1, "767": 0, "77": 0, "773": 6, "774": [0, 1], "774a1": 0, "775": 40, "776c": 40, "78": 5, "782": 1, "782a": 3, "782a1": 3, "782c": 3, "783": 1, "784": [6, 7, 9], "787a": 40, "787c": 40, "78a": 5, "79": 2, "794v7": 0, "797": [2, 4], "7a": 39, "8": [0, 1, 4, 5, 7, 39], "802": 4, "806": 40, "814": 40, "818a22": 4, "825": [2, 3], "826": 2, "827v4": 40, "83": 3, "831": 3, "833": 1, "833l": 1, "836": 4, "847": 4, "85": 4, "855l": 0, "859": 4, "85a1": 0, "864": 0, "867a1": 3, "868a": 40, "868a5": 40, "873": 0, "873a": 40, "873a4": 40, "875v9": 0, "878": 2, "88": 0, "882v4": 0, "885": 4, "887zm3": 0, "8c": 2, "8s1": 2, "8v1": 3, "9": [0, 1, 4, 9], "904": 1, "904l": 1, "909": 6, "912c": 3, "913": 3, "914": [2, 4, 6], "914a": 6, "914c": 6, "92": 4, "922": 2, "936v1": 1, "949": 1, "95": [1, 3], "951": 40, "954": 1, "954c": 1, "96": 2, "966": 7, "967": 40, "968": 40, "971": 40, "975": 2, "979": 1, "979h3": 1, "97a": 5, "984c": 2, "986": 4, "991": 2, "991c1": 2, "992": 38, "994": 38, "995": 40, "997": 40, "999": 40, "999a3": 40, "999l": 39, "999l3": 39, "9a": 6, "9a1": 9, "9v5": 3, "A": 7, "Not": 39, "The": 0, "ad": [0, 39], "add": 39, "advanc": [0, 5, 9, 16, 23], "agreement": 4, "also": [0, 1, 2, 3, 12, 13, 15, 19, 23, 25, 26, 30], "api": 20, "appl": 5, "architectur": [6, 9, 26, 39], "aria": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "asset": [0, 10, 16, 20, 39], "audio": 12, "author": 9, "avail": [14, 24, 26], "base": [0, 14], "basic": [2, 3, 8, 26], "batch": [9, 27], "batchlayout": 27, "best": [0, 7], "bibliographi": 38, "binari": 6, "book": 38, "breakpoint": 40, "bug": 40, "build": [1, 6], "card": [0, 16, 23, 39], "chat": 25, "check": [4, 6], "checkpoint": [9, 11, 20, 23, 26], "class": [0, 1, 2, 3, 4, 5, 6, 7, 9, 13, 14, 15, 19, 23, 38, 39, 40], "cli": 0, "clone": 6, "code": 40, "common": [0, 7, 23, 39], "comparison": 26, "compil": 27, "complet": [25, 26, 39], "compon": [2, 12], "comput": 20, "concept": 7, "configur": [0, 1, 7, 19, 25, 26, 39], "connect": 34, "consider": 27, "constant": 26, "contain": 0, "contribut": 4, "contributor": 4, "convent": 2, "convert_qwen_state_dict": 26, "core": [2, 13, 15, 19, 23, 39], "cpu": 6, "creat": [0, 1, 16, 27, 39], "create_qwen_model": 26, "cuda": [5, 6], "custom": [0, 16, 23, 26], "d": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "data": [9, 12, 13, 14, 20], "dataset": [0, 1, 15, 16], "datasetfamilynotknownerror": 15, "datasethub": 15, "datasethubaccessor": 15, "datasetnotknownerror": 15, "debug": 40, "debugg": 40, "defin": 1, "depend": [2, 6], "design": 2, "detail": [7, 39], "develop": 4, "devic": 17, "distribut": 20, "document": [4, 8], "download": [5, 39], "edit": 6, "embed": 28, "encod": 32, "entri": 1, "enum": 19, "environ": [0, 4, 6], "error": [3, 23, 39], "evenodd": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "exampl": [3, 19, 23, 25, 26, 39], "except": [13, 15, 23], "execut": 2, "exist": 39, "exit": 40, "experi": 9, "export_qwen": 26, "extens": 3, "face": [9, 39], "factori": [19, 26], "fairseq2": [4, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 30, 35, 36, 37, 40], "fairseq2n": 6, "famili": [23, 24, 39], "faq": 8, "featur": 16, "field": 0, "file": [0, 6, 39], "fill": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "flow": 2, "format": 4, "found": 39, "from": [6, 26], "function": [13, 19, 23], "gang": 19, "get": [8, 9, 24], "get_llama_model_hub": 25, "get_llama_tokenizer_hub": 25, "get_qwen_model_hub": 26, "get_qwen_shard_spec": 26, "get_qwen_tokenizer_hub": 26, "global": 23, "guid": [9, 39], "handl": [3, 23], "heart": 4, "height": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "hidden": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "http": 39, "hub": [13, 15, 23, 25, 26, 39], "hug": [9, 39], "huggingfac": 25, "implement": [1, 2, 19, 25, 39], "increment": 29, "indic": [8, 27], "infin": 2, "inform": [24, 27], "inherit": 0, "initi": 40, "inject": 2, "inspect": 23, "instal": [5, 6], "integr": [9, 27, 39], "interfac": 2, "interoper": 26, "invers": 2, "issu": 4, "iter": 23, "kei": [7, 16], "latest": 8, "layer": [27, 31, 33], "layout": 27, "licens": 4, "lint": 4, "linux": 5, "list": [4, 14, 24], "llama": [23, 25], "llamaconfig": 25, "llamatokenizerconfig": 25, "load": [14, 23, 24, 26, 39], "load_model": 23, "load_token": 13, "local": 39, "lock": 7, "log": 21, "m0": 38, "m1": 9, "m10": [0, 3], "m14": 1, "m3": [2, 39], "m4": [4, 6, 7, 40], "m7": 5, "maco": 5, "maintain": 9, "manag": 9, "mask": [27, 35], "memori": 9, "metric": [9, 22], "migrat": 9, "mistral": 23, "mode": 25, "model": [0, 9, 14, 20, 23, 24, 25, 26, 39], "modelhub": 23, "modelhubaccessor": 23, "monitor": 9, "network": [20, 27], "neural": [20, 27], "new": [8, 9], "next": 9, "nn": [30, 35], "normal": 31, "octicon": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "onli": 6, "open": 16, "optim": [9, 18, 20, 36], "option": [6, 39], "over": 23, "overrid": 0, "overview": [1, 3, 7, 39], "own": 39, "paramet": 39, "path": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "perform": [9, 27], "philosophi": 2, "pip": 6, "pipelin": 12, "place": 40, "plug": 3, "point": 1, "posit": [27, 32], "practic": [0, 7], "prerequisit": 7, "process": [9, 12, 20], "programmat": 0, "project": [7, 33], "pudb": 40, "pull": 4, "python": 6, "pytorch": [5, 6], "quick": [5, 7, 13, 14, 23, 24, 25, 26], "qwen": [23, 26], "qwen_famili": 26, "qwenconfig": 26, "qwenfactori": 26, "qwentoken": 26, "qwentokenizerconfig": 26, "recip": [1, 2, 9, 18, 37], "recommend": 39, "refer": [0, 8, 13, 20], "registr": [0, 16], "remot": 40, "report": 9, "repositori": 6, "request": 4, "residu": 34, "rocket": 1, "rubi": 39, "rule": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "run": [1, 40], "runtim": 3, "saniti": 6, "sd": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "see": [0, 1, 2, 3, 12, 13, 15, 19, 23, 25, 26, 30], "sequenc": [27, 39], "set": [4, 6], "setup": [1, 3, 7], "shard": [9, 26], "silicon": 5, "socket": 40, "sourc": [6, 39], "special": 25, "specif": [0, 14], "start": [7, 8, 9, 14, 23, 24, 25, 26], "state": 29, "step": [1, 39], "store": 0, "structur": 12, "support": [5, 9, 24, 25], "svg": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "system": [0, 6], "tabl": 8, "templat": 25, "test": 4, "text": 12, "tiktoken": 25, "tip": 7, "token": [13, 14, 25, 26], "tokenizerfamilynotknownerror": 13, "tokenizerhub": [13, 14], "tokenizerhubaccessor": 13, "tokenizernotknownerror": 13, "topologi": 19, "torch": 27, "train": [20, 39], "troubleshoot": [0, 7, 39], "true": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "tutori": 8, "type": 19, "understand": [0, 39], "up": [4, 6], "url": 39, "us": [14, 25], "usag": [0, 2, 3, 23, 26], "user": 9, "util": [19, 20, 35], "uv": 7, "v0": 9, "valid": 39, "variant": 5, "verifi": 39, "version": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "viewbox": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "virtual": 6, "vocabulari": 39, "welcom": 8, "what": [9, 19], "width": [0, 1, 2, 3, 4, 5, 6, 7, 9, 38, 39, 40], "window": 5, "work": [4, 23, 27, 39], "workflow": 7, "yaml": 0, "your": [1, 4, 39]}})