Search.setIndex({"alltitles": {"1. Clone the Repository": [[6, "clone-the-repository"]], "2. Set up a Python Virtual Environment": [[6, "set-up-a-python-virtual-environment"]], "3. Install Dependencies": [[6, "install-dependencies"]], "3.1 System Dependencies": [[6, "system-dependencies"]], "3.2 PyTorch": [[6, "pytorch"]], "3.3 CUDA": [[6, "cuda"]], "3.4 pip": [[6, "pip"]], "4. Build fairseq2n": [[6, "build-fairseq2n"]], "4.1 CPU-Only Builds": [[6, "cpu-only-builds"]], "4.2 CUDA Builds": [[6, "cuda-builds"]], "4.3 CUDA Architectures": [[6, "cuda-architectures"]], "5. Install fairseq2": [[6, "install-fairseq2"]], "5.1 Editable Install": [[6, "editable-install"]], "6. Optional Sanity Check": [[6, "optional-sanity-check"]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-book\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M0 1.75A.75.75 0 01.75 1h4.253c1.227 0 2.317.59 3 1.501A3.744 3.744 0 0111.006 1h4.245a.75.75 0 01.75.75v10.5a.75.75 0 01-.75.75h-4.507a2.25 2.25 0 00-1.591.659l-.622.621a.75.75 0 01-1.06 0l-.622-.621A2.25 2.25 0 005.258 13H.75a.75.75 0 01-.75-.75V1.75zm8.755 3a2.25 2.25 0 012.25-2.25H14.5v9h-3.757c-.71 0-1.4.201-1.992.572l.004-7.322zm-1.504 7.324l.004-5.073-.002-2.253A2.25 2.25 0 005.003 2.5H1.5v9h3.757a3.75 3.75 0 011.994.574z\"></path></svg> Bibliography": [[12, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-bug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.72.22a.75.75 0 011.06 0l1 .999a3.492 3.492 0 012.441 0l.999-1a.75.75 0 111.06 1.061l-.775.776c.616.63.995 1.493.995 2.444v.327c0 .1-.009.197-.025.292.408.14.764.392 1.029.722l1.968-.787a.75.75 0 01.556 1.392L13 7.258V9h2.25a.75.75 0 010 1.5H13v.5c0 .409-.049.806-.141 1.186l2.17.868a.75.75 0 01-.557 1.392l-2.184-.873A4.997 4.997 0 018 16a4.997 4.997 0 01-4.288-2.427l-2.183.873a.75.75 0 01-.558-1.392l2.17-.868A5.013 5.013 0 013 11v-.5H.75a.75.75 0 010-1.5H3V7.258L.971 6.446a.75.75 0 01.558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.684 1.684 0 01-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 010-1.06zM6.173 5h3.654A.173.173 0 0010 4.827V4.5a2 2 0 10-4 0v.327c0 .096.077.173.173.173zM5.25 6.5a.75.75 0 00-.75.75V11a3.5 3.5 0 107 0V7.25a.75.75 0 00-.75-.75h-5.5z\"></path></svg> Debugging with PuDB": [[9, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-container\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.41.24l4.711 2.774A1.767 1.767 0 0116 4.54v5.01a1.77 1.77 0 01-.88 1.53l-7.753 4.521-.002.001a1.767 1.767 0 01-1.774 0H5.59L.873 12.85A1.762 1.762 0 010 11.327V6.292c0-.304.078-.598.22-.855l.004-.005.01-.019c.15-.262.369-.486.64-.643L8.641.239a1.75 1.75 0 011.765 0l.002.001zM9.397 1.534a.25.25 0 01.252 0l4.115 2.422-7.152 4.148a.267.267 0 01-.269 0L2.227 5.716l7.17-4.182zM7.365 9.402L8.73 8.61v4.46l-1.5.875V9.473a1.77 1.77 0 00.136-.071zm2.864 2.794V7.741l1.521-.882v4.45l-1.521.887zm3.021-1.762l1.115-.65h.002a.268.268 0 00.133-.232V5.264l-1.25.725v4.445zm-11.621 1.12l4.1 2.393V9.474a1.77 1.77 0 01-.138-.072L1.5 7.029v4.298c0 .095.05.181.129.227z\"></path></svg> Assets": [[0, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-download\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.47 10.78a.75.75 0 001.06 0l3.75-3.75a.75.75 0 00-1.06-1.06L8.75 8.44V1.75a.75.75 0 00-1.5 0v6.69L4.78 5.97a.75.75 0 00-1.06 1.06l3.75 3.75zM3.75 13a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5z\"></path></svg> Installation": [[5, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-file-binary\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0114.25 15h-9a.75.75 0 010-1.5h9a.25.25 0 00.25-.25V6h-2.75A1.75 1.75 0 0110 4.25V1.5H5.75a.25.25 0 00-.25.25v2a.75.75 0 01-1.5 0v-2zm7.5-.188V4.25c0 .138.112.25.25.25h2.688a.252.252 0 00-.011-.013l-2.914-2.914a.272.272 0 00-.013-.011zM0 7.75C0 6.784.784 6 1.75 6h1.5C4.216 6 5 6.784 5 7.75v2.5A1.75 1.75 0 013.25 12h-1.5A1.75 1.75 0 010 10.25v-2.5zm1.75-.25a.25.25 0 00-.25.25v2.5c0 .138.112.25.25.25h1.5a.25.25 0 00.25-.25v-2.5a.25.25 0 00-.25-.25h-1.5zm5-1.5a.75.75 0 000 1.5h.75v3h-.75a.75.75 0 000 1.5h3a.75.75 0 000-1.5H9V6.75A.75.75 0 008.25 6h-1.5z\"></path></svg> Installing from Source": [[6, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-heart\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z\"></path></svg> Contributing to fairseq2": [[13, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-infinity\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.5 6c-1.086 0-2 .914-2 2 0 1.086.914 2 2 2 .525 0 1.122-.244 1.825-.727.51-.35 1.025-.79 1.561-1.273-.536-.483-1.052-.922-1.56-1.273C4.621 6.244 4.025 6 3.5 6zm4.5.984c-.59-.533-1.204-1.066-1.825-1.493-.797-.548-1.7-.991-2.675-.991C1.586 4.5 0 6.086 0 8s1.586 3.5 3.5 3.5c.975 0 1.878-.444 2.675-.991.621-.427 1.235-.96 1.825-1.493.59.533 1.204 1.066 1.825 1.493.797.547 1.7.991 2.675.991 1.914 0 3.5-1.586 3.5-3.5s-1.586-3.5-3.5-3.5c-.975 0-1.878.443-2.675.991-.621.427-1.235.96-1.825 1.493zM9.114 8c.536.483 1.052.922 1.56 1.273.704.483 1.3.727 1.826.727 1.086 0 2-.914 2-2 0-1.086-.914-2-2-2-.525 0-1.122.244-1.825.727-.51.35-1.025.79-1.561 1.273z\"></path></svg> Design Philosophy": [[2, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-lock\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 4v2h-.25A1.75 1.75 0 002 7.75v5.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 13.25v-5.5A1.75 1.75 0 0012.25 6H12V4a4 4 0 10-8 0zm6.5 2V4a2.5 2.5 0 00-5 0v2h5zM12 7.5h.25a.25.25 0 01.25.25v5.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-5.5a.25.25 0 01.25-.25H12z\"></path></svg> UV Setup": [[7, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-plug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.276 3.09a.25.25 0 01.192-.09h.782a.25.25 0 01.25.25v8.5a.25.25 0 01-.25.25h-.782a.25.25 0 01-.192-.09l-.95-1.14a.75.75 0 00-.483-.264l-3.124-.39a.25.25 0 01-.219-.249V5.133a.25.25 0 01.219-.248l3.124-.39a.75.75 0 00.483-.265l.95-1.14zM4 8v1.867a1.75 1.75 0 001.533 1.737l2.83.354.761.912c.332.4.825.63 1.344.63h.782A1.75 1.75 0 0013 11.75V11h2.25a.75.75 0 000-1.5H13v-4h2.25a.75.75 0 000-1.5H13v-.75a1.75 1.75 0 00-1.75-1.75h-.782c-.519 0-1.012.23-1.344.63l-.76.913-2.831.353A1.75 1.75 0 004 5.133V6.5H2.5A2.5 2.5 0 000 9v5.25a.75.75 0 001.5 0V9a1 1 0 011-1H4z\"></path></svg> Runtime Extension": [[3, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-report\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M1.75 1.5a.25.25 0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 01.75.75v2.19l2.72-2.72a.75.75 0 01.53-.22h6.5a.25.25 0 00.25-.25v-9.5a.25.25 0 00-.25-.25H1.75zM0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0114.25 13H8.06l-2.573 2.573A1.457 1.457 0 013 14.543V13H1.75A1.75 1.75 0 010 11.25v-9.5zM9 9a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z\"></path></svg> What\u2019s New in v0.5": [[11, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-rocket\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z\"></path></svg> Building Recipes": [[1, null]], "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-ruby\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.637 2.291A.75.75 0 014.23 2h7.54a.75.75 0 01.593.291l3.48 4.5a.75.75 0 01-.072.999l-7.25 7a.75.75 0 01-1.042 0l-7.25-7a.75.75 0 01-.072-.999l3.48-4.5zM4.598 3.5L1.754 7.177 8 13.207l6.246-6.03L11.402 3.5H4.598z\"></path></svg> Add Your Own Model": [[8, null]], "A Detailed Project Setup": [[7, "a-detailed-project-setup"]], "API Reference": [[10, null]], "Adding a Custom Dataset": [[0, "adding-a-custom-dataset"]], "Adding a Custom Model": [[0, "adding-a-custom-model"]], "Advanced Configuration": [[0, "advanced-configuration"]], "Advanced Dataset Opening": [[20, "advanced-dataset-opening"]], "Advanced Installation": [[5, null]], "Advanced Usage": [[27, "advanced-usage"]], "Architecture Comparison": [[30, "architecture-comparison"]], "Architecture Configuration Error": [[8, "architecture-configuration-error"]], "Asset Card Reference": [[0, "asset-card-reference"]], "Asset Cards: YAML Configuration Files": [[0, "asset-cards-yaml-configuration-files"]], "Asset Source Options": [[8, "asset-source-options"]], "Asset Store Configuration": [[0, "asset-store-configuration"]], "Audio Processing": [[16, "audio-processing"]], "Available Models": [[30, "available-models"]], "Base Assets and Inheritance": [[0, "base-assets-and-inheritance"]], "Base Classes": [[18, "base-classes"]], "Basic Model Usage": [[30, "basic-model-usage"]], "Basic Usage": [[2, "basic-usage"], [3, "basic-usage"]], "Basics": [[10, null]], "Batch Layout": [[31, null]], "Best Practices": [[0, "best-practices"]], "CLI Usage": [[0, "cli-usage"]], "Chat Template Support": [[29, "chat-template-support"]], "Check List for Pull Requests": [[13, "check-list-for-pull-requests"]], "Checkpoint Inspection": [[27, "checkpoint-inspection"]], "Classes": [[22, "classes"]], "Common Asset Fields": [[0, "common-asset-fields"]], "Common Exceptions": [[27, "common-exceptions"]], "Common Model Parameters": [[8, "common-model-parameters"]], "Common Workflows": [[7, "common-workflows"]], "Complete Examples": [[29, "complete-examples"], [30, "complete-examples"]], "Concepts": [[10, null]], "Configuration": [[7, "configuration"]], "Configuration Overrides": [[0, "configuration-overrides"]], "Configuration Validation Errors": [[8, "configuration-validation-errors"]], "Constants": [[30, "constants"]], "Contributor License Agreement": [[13, "contributor-license-agreement"]], "Core Architecture": [[8, "core-architecture"]], "Core Classes": [[17, "core-classes"], [19, "core-classes"], [27, "core-classes"]], "Core Components": [[2, "core-components"]], "Creating BatchLayout": [[31, "creating-batchlayout"]], "Creating Custom Assets": [[0, "creating-custom-assets"]], "Creating Custom Datasets": [[20, "creating-custom-datasets"]], "Custom Architecture": [[30, "custom-architecture"]], "Custom Model Loading": [[27, "custom-model-loading"]], "Data Pipeline Components": [[16, "data-pipeline-components"]], "Dataset Registration and Asset Cards": [[20, "dataset-registration-and-asset-cards"]], "DatasetFamilyNotKnownError": [[19, "datasetfamilynotknownerror"]], "DatasetHub": [[19, "datasethub"]], "DatasetHubAccessor": [[19, "datasethubaccessor"]], "DatasetNotKnownError": [[19, "datasetnotknownerror"]], "Dependency Injection": [[2, "dependency-injection"]], "Dependency Inversion": [[2, "dependency-inversion"]], "Documenting Your Work": [[13, "documenting-your-work"]], "Download/Loading Errors": [[8, "download-loading-errors"]], "Embeddings": [[32, null]], "Enums": [[22, "enums"]], "Environment-Specific Assets": [[0, "environment-specific-assets"]], "Error Handling": [[3, "error-handling"], [27, "error-handling"]], "Example Error Handling": [[27, "example-error-handling"]], "Example Extension Setup": [[3, "example-extension-setup"]], "Example: Complete Implementation": [[8, "example-complete-implementation"]], "Exceptions": [[17, "exceptions"], [19, "exceptions"], [22, "exceptions"]], "Exiting the debugger": [[9, "exiting-the-debugger"]], "Factory Functions": [[22, "factory-functions"]], "Formatting Your Work": [[13, "formatting-your-work"]], "Functions": [[17, "functions"], [23, "functions"]], "Getting Model Information": [[28, "getting-model-information"]], "Getting Started": [[10, null]], "Global Functions": [[27, "global-functions"]], "Guides": [[10, null]], "HTTP URLs": [[8, "http-urls"]], "How is Gang different from PyTorch DeviceMesh?": [[4, "how-is-gang-different-from-pytorch-devicemesh"]], "How is Gang different from PyTorch ProcessGroup?": [[4, "how-is-gang-different-from-pytorch-processgroup"]], "How is Gang used in fairseq2?": [[4, "how-is-gang-used-in-fairseq2"]], "How to create Gangs for data and model parallelism?": [[4, "how-to-create-gangs-for-data-and-model-parallelism"]], "How to create a Gang?": [[4, "how-to-create-a-gang"]], "Hugging Face Hub (Recommended)": [[8, "hugging-face-hub-recommended"]], "Incremental State": [[33, null]], "Indices and tables": [[10, "indices-and-tables"]], "Initializing the socket for remote debugger": [[9, "initializing-the-socket-for-remote-debugger"]], "Integration with Neural Network Layers": [[31, "integration-with-neural-network-layers"]], "Interface/Implementation Convention": [[2, "interface-implementation-convention"]], "Interoperability": [[30, "interoperability"]], "Issues": [[13, "issues"]], "Iterating Over Model Cards": [[27, "iterating-over-model-cards"]], "Key Concepts": [[7, "key-concepts"]], "Key Features": [[20, "key-features"]], "LLaMA Models": [[27, "llama-models"]], "LLaMAConfig": [[29, "llamaconfig"]], "LLaMATokenizerConfig": [[29, "llamatokenizerconfig"]], "Latest News": [[10, null]], "License": [[13, "license"]], "Linting Your Work": [[13, "linting-your-work"]], "Listing Available Models": [[28, "listing-available-models"]], "Listing Available Tokenizers": [[18, "listing-available-tokenizers"]], "Loading a Model": [[28, "loading-a-model"]], "Loading a Specific Model\u2019s Tokenizer": [[18, "loading-a-specific-model-s-tokenizer"]], "Loading a Tokenizer": [[18, "loading-a-tokenizer"]], "Loading from Custom Checkpoint": [[30, "loading-from-custom-checkpoint"]], "Local Files": [[8, "local-files"]], "Masking Utilities": [[39, "masking-utilities"]], "Mistral Models": [[27, "mistral-models"]], "Model Configuration": [[29, "model-configuration"], [30, "model-configuration"]], "Model Factory": [[30, "model-factory"]], "Model Hub": [[29, "model-hub"], [30, "model-hub"]], "Model Not Found Error": [[8, "model-not-found-error"]], "ModelHub": [[27, "modelhub"]], "ModelHubAccessor": [[27, "modelhubaccessor"]], "Normalization Layers": [[35, null]], "Other": [[10, null]], "Overview": [[1, "overview"], [3, "overview"], [7, "overview"], [8, "overview"]], "Performance Considerations": [[31, "performance-considerations"]], "Placing the debugger breakpoint in the code": [[9, "placing-the-debugger-breakpoint-in-the-code"]], "Position Encoders": [[36, null]], "Prerequisites": [[7, "prerequisites"]], "Programmatic Asset Registration": [[0, "programmatic-asset-registration"]], "Projection Layers": [[37, null]], "QWEN_FAMILY": [[30, "qwen-family"]], "Quick Install": [[5, "quick-install"]], "Quick Reference": [[17, "quick-reference"]], "Quick Start": [[7, "quick-start"], [18, "quick-start"], [27, "quick-start"], [28, "quick-start"], [29, "quick-start"], [30, "quick-start"]], "Qwen Models": [[27, "qwen-models"]], "QwenConfig": [[30, "qwenconfig"]], "QwenFactory": [[30, "qwenfactory"]], "QwenTokenizer": [[30, "qwentokenizer"]], "QwenTokenizerConfig": [[30, "qwentokenizerconfig"]], "Recipe Execution Flow": [[2, "recipe-execution-flow"]], "Residual Connections": [[38, null]], "Running Your Recipe": [[1, "running-your-recipe"]], "Running fairseq2 with debugger": [[9, "running-fairseq2-with-debugger"]], "See Also": [[0, "see-also"], [1, "see-also"], [2, "see-also"], [3, "see-also"], [16, "see-also"], [17, "see-also"], [19, "see-also"], [27, "see-also"], [29, "see-also"], [30, "see-also"], [34, "see-also"]], "Sequence Information": [[31, "sequence-information"]], "Setting up Development Environment": [[13, "setting-up-development-environment"]], "Sharding": [[30, "sharding"]], "Special Tokens": [[29, "special-tokens"]], "Step 0: Setup the Entry Point": [[1, "step-0-setup-the-entry-point"]], "Step 1: Add Model Architecture Configuration": [[8, "step-1-add-model-architecture-configuration"]], "Step 1: Define Your Configuration": [[1, "step-1-define-your-configuration"]], "Step 2: Create Asset Card": [[8, "step-2-create-asset-card"]], "Step 2: Implement Your Dataset": [[1, "step-2-implement-your-dataset"]], "Step 3: Create Your Recipe Class": [[1, "step-3-create-your-recipe-class"]], "Step 3: Verify the Integration": [[8, "step-3-verify-the-integration"]], "Step-by-Step Guide: Adding a Model to Existing Family": [[8, "step-by-step-guide-adding-a-model-to-existing-family"]], "Structured Data": [[16, "structured-data"]], "Supported Model Families": [[28, "supported-model-families"]], "Supported PyTorch Versions (macOS Apple Silicon)": [[5, "id2"]], "Supported PyTorch Versions and CUDA Variants (Linux)": [[5, "id1"]], "Supported Variants": [[5, "supported-variants"]], "Testing Your Work": [[13, "testing-your-work"]], "Text Processing": [[16, "text-processing"]], "The Asset Store System": [[0, "the-asset-store-system"]], "Tips & Best Practices": [[7, "tips-best-practices"]], "Tokenizer": [[29, "tokenizer"], [30, "tokenizer"]], "Tokenizer Configuration": [[29, "tokenizer-configuration"]], "Tokenizer Modes": [[29, "tokenizer-modes"]], "TokenizerFamilyNotKnownError": [[17, "tokenizerfamilynotknownerror"]], "TokenizerHub": [[17, "tokenizerhub"]], "TokenizerHubAccessor": [[17, "tokenizerhubaccessor"]], "TokenizerNotKnownError": [[17, "tokenizernotknownerror"]], "Torch.compile Integration": [[31, "torch-compile-integration"]], "Training & Architecture Details": [[8, "training-architecture-details"]], "Troubleshooting": [[0, "troubleshooting"], [7, "troubleshooting"], [8, "troubleshooting"]], "Understanding Model Families": [[8, "understanding-model-families"]], "Understanding the Asset System": [[0, "understanding-the-asset-system"]], "Using HuggingFace Tokenizer": [[29, "using-huggingface-tokenizer"]], "Using Tiktoken Implementation": [[29, "using-tiktoken-implementation"]], "Using TokenizerHub": [[18, "using-tokenizerhub"]], "Utilities": [[22, "utilities"]], "Vocabulary & Sequence": [[8, "vocabulary-sequence"]], "Welcome to fairseq2 Documentation": [[10, null]], "What is a Gang?": [[4, null]], "What\u2019s Next": [[11, "what-s-next"]], "Windows": [[5, "windows"]], "Working with Model Families": [[27, "working-with-model-families"]], "Working with Model Hubs": [[8, "working-with-model-hubs"]], "Working with Position Indices and Masks": [[31, "working-with-position-indices-and-masks"]], "convert_qwen_state_dict": [[30, "convert-qwen-state-dict"]], "create_qwen_model": [[30, "create-qwen-model"]], "export_qwen": [[30, "export-qwen"]], "fairseq2.assets": [[14, null]], "fairseq2.checkpoint": [[15, null]], "fairseq2.data": [[16, null]], "fairseq2.data.tokenizers": [[18, null]], "fairseq2.data.tokenizers.hub": [[17, null]], "fairseq2.datasets": [[20, null]], "fairseq2.datasets.hub": [[19, null]], "fairseq2.device": [[21, null]], "fairseq2.gang": [[22, null]], "fairseq2.logging": [[25, null]], "fairseq2.metrics": [[26, null]], "fairseq2.models": [[28, null]], "fairseq2.models.hub": [[27, null]], "fairseq2.models.llama": [[29, null]], "fairseq2.models.qwen": [[30, null]], "fairseq2.nn": [[34, null]], "fairseq2.nn.utils": [[39, null]], "fairseq2.optim": [[40, null]], "fairseq2.recipe": [[41, null]], "fairseq2.recipe.optim": [[23, null]], "fairseq2.utils.validation": [[24, null]], "get_llama_model_hub": [[29, "get-llama-model-hub"]], "get_llama_tokenizer_hub": [[29, "get-llama-tokenizer-hub"]], "get_qwen_model_hub": [[30, "get-qwen-model-hub"]], "get_qwen_shard_specs": [[30, "get-qwen-shard-specs"]], "get_qwen_tokenizer_hub": [[30, "get-qwen-tokenizer-hub"]], "load_model": [[27, "load-model"]], "load_tokenizer": [[17, "load-tokenizer"]], "\u2699\ufe0f Advanced Model Sharding": [[11, "advanced-model-sharding"]], "\u26a1 Performance & Memory Optimizations": [[11, "performance-memory-optimizations"]], "\ud83c\udfaf Migration Guide": [[11, "migration-guide"]], "\ud83d\udcbe Advanced Checkpoint Management": [[11, "advanced-checkpoint-management"]], "\ud83d\udcc8 Metrics & Monitoring": [[11, "metrics-monitoring"]], "\ud83d\udcca Data Processing & Batching": [[11, "data-processing-batching"]], "\ud83d\udd17 Hugging Face Integration": [[11, "hugging-face-integration"]], "\ud83d\udd27 Architecture & Maintainability": [[11, "architecture-maintainability"]], "\ud83d\ude80 Recipe Authoring & User Experience": [[11, "recipe-authoring-user-experience"]], "\ud83e\udd16 New Model Support": [[11, "new-model-support"]]}, "docnames": ["basics/assets", "basics/building_recipes", "basics/design_philosophy", "basics/runtime_extension", "concepts/gang", "getting_started/installation/index", "getting_started/installation/installation_from_source", "getting_started/installation/setup_with_uv", "guides/add_model", "guides/pudb", "index", "news/whats_new_v0_5", "other/bibliography", "other/contributing", "reference/assets", "reference/checkpoint", "reference/data/index", "reference/data/tokenizers/hub", "reference/data/tokenizers/index", "reference/datasets/hub", "reference/datasets/index", "reference/device", "reference/fairseq2.gang", "reference/fairseq2.recipe.optim", "reference/fairseq2.utils.validation", "reference/logging", "reference/metrics", "reference/models/hub", "reference/models/index", "reference/models/llama", "reference/models/qwen", "reference/nn/batch_layout", "reference/nn/embedding", "reference/nn/incremental_state", "reference/nn/index", "reference/nn/normalization", "reference/nn/position_encoder", "reference/nn/projection", "reference/nn/residual", "reference/nn/utils", "reference/optim", "reference/recipe"], "envversion": {"nbsphinx": 4, "sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["basics/assets.rst", "basics/building_recipes.rst", "basics/design_philosophy.rst", "basics/runtime_extension.rst", "concepts/gang.rst", "getting_started/installation/index.rst", "getting_started/installation/installation_from_source.rst", "getting_started/installation/setup_with_uv.rst", "guides/add_model.rst", "guides/pudb.rst", "index.rst", "news/whats_new_v0_5.rst", "other/bibliography.rst", "other/contributing.rst", "reference/assets.rst", "reference/checkpoint.rst", "reference/data/index.rst", "reference/data/tokenizers/hub.rst", "reference/data/tokenizers/index.rst", "reference/datasets/hub.rst", "reference/datasets/index.rst", "reference/device.rst", "reference/fairseq2.gang.rst", "reference/fairseq2.recipe.optim.rst", "reference/fairseq2.utils.validation.rst", "reference/logging.rst", "reference/metrics.rst", "reference/models/hub.rst", "reference/models/index.rst", "reference/models/llama.rst", "reference/models/qwen.rst", "reference/nn/batch_layout.rst", "reference/nn/embedding.rst", "reference/nn/incremental_state.rst", "reference/nn/index.rst", "reference/nn/normalization.rst", "reference/nn/position_encoder.rst", "reference/nn/projection.rst", "reference/nn/residual.rst", "reference/nn/utils.rst", "reference/optim.rst", "reference/recipe.rst"], "indexentries": {"add_error() (fairseq2.utils.validation.validationresult method)": [[24, "fairseq2.utils.validation.ValidationResult.add_error", false]], "add_sub_result() (fairseq2.utils.validation.validationresult method)": [[24, "fairseq2.utils.validation.ValidationResult.add_sub_result", false]], "additiveresidualconnect (class in fairseq2.nn)": [[38, "fairseq2.nn.AdditiveResidualConnect", false]], "all_gather() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.all_gather", false]], "all_gather() (fairseq2.gang.gang method)": [[22, "fairseq2.gang.Gang.all_gather", false]], "all_gather() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.all_gather", false]], "all_gather_to_list() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.all_gather_to_list", false]], "all_gather_to_list() (fairseq2.gang.gang method)": [[22, "fairseq2.gang.Gang.all_gather_to_list", false]], "all_gather_to_list() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.all_gather_to_list", false]], "all_reduce() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.all_reduce", false]], "all_reduce() (fairseq2.gang.gang method)": [[22, "fairseq2.gang.Gang.all_reduce", false]], "all_reduce() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.all_reduce", false]], "all_sum() (in module fairseq2.gang)": [[22, "fairseq2.gang.all_sum", false]], "apply_mask() (in module fairseq2.nn.utils.mask)": [[39, "fairseq2.nn.utils.mask.apply_mask", false]], "as_process_group() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.as_process_group", false]], "as_process_group() (fairseq2.gang.gang method)": [[22, "fairseq2.gang.Gang.as_process_group", false]], "as_process_group() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.as_process_group", false]], "barrier() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.barrier", false]], "barrier() (fairseq2.gang.gang method)": [[22, "fairseq2.gang.Gang.barrier", false]], "barrier() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.barrier", false]], "batchlayout (class in fairseq2.nn)": [[31, "fairseq2.nn.BatchLayout", false]], "boh_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.boh_idx", false]], "bos_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.bos_idx", false]], "broadcast() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.broadcast", false]], "broadcast() (fairseq2.gang.gang method)": [[22, "fairseq2.gang.Gang.broadcast", false]], "broadcast() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.broadcast", false]], "broadcast_flag() (in module fairseq2.gang)": [[22, "fairseq2.gang.broadcast_flag", false]], "broadcast_objects() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.broadcast_objects", false]], "broadcast_objects() (fairseq2.gang.gang method)": [[22, "fairseq2.gang.Gang.broadcast_objects", false]], "broadcast_objects() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.broadcast_objects", false]], "capacity_bytes() (fairseq2.nn.incrementalstate method)": [[33, "fairseq2.nn.IncrementalState.capacity_bytes", false]], "capacity_bytes() (fairseq2.nn.incrementalstatebag method)": [[33, "fairseq2.nn.IncrementalStateBag.capacity_bytes", false]], "capacity_increment (fairseq2.nn.incrementalstatebag property)": [[33, "fairseq2.nn.IncrementalStateBag.capacity_increment", false]], "close() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.close", false]], "close() (fairseq2.gang.gangs method)": [[22, "fairseq2.gang.Gangs.close", false]], "close() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.close", false]], "compiled_max_seq_len (fairseq2.nn.batchlayout attribute)": [[31, "fairseq2.nn.BatchLayout.compiled_max_seq_len", false]], "compute_row_mask() (in module fairseq2.nn.utils.mask)": [[39, "fairseq2.nn.utils.mask.compute_row_mask", false]], "convert_qwen_state_dict() (in module fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.convert_qwen_state_dict", false]], "create_decoder() (fairseq2.data.tokenizers.tokenizer method)": [[18, "fairseq2.data.tokenizers.Tokenizer.create_decoder", false]], "create_decoder() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_decoder", false]], "create_decoder() (fairseq2.models.qwen.qwentokenizer method)": [[30, "fairseq2.models.qwen.QwenTokenizer.create_decoder", false]], "create_decoder_frontend() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_decoder_frontend", false]], "create_decoder_layer() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_decoder_layer", false]], "create_default_process_group() (fairseq2.gang.processgroupgang class method)": [[22, "fairseq2.gang.ProcessGroupGang.create_default_process_group", false]], "create_embedding() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_embedding", false]], "create_encoder() (fairseq2.data.tokenizers.tokenizer method)": [[18, "fairseq2.data.tokenizers.Tokenizer.create_encoder", false]], "create_encoder() (fairseq2.models.qwen.qwentokenizer method)": [[30, "fairseq2.models.qwen.QwenTokenizer.create_encoder", false]], "create_fake_gangs() (in module fairseq2.gang)": [[22, "fairseq2.gang.create_fake_gangs", false]], "create_ffn() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_ffn", false]], "create_final_projection() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_final_projection", false]], "create_fsdp_gangs() (in module fairseq2.gang)": [[22, "fairseq2.gang.create_fsdp_gangs", false]], "create_gang() (fairseq2.gang.fakegang method)": [[22, "fairseq2.gang.FakeGang.create_gang", false]], "create_gang() (fairseq2.gang.gang method)": [[22, "fairseq2.gang.Gang.create_gang", false]], "create_gang() (fairseq2.gang.processgroupgang method)": [[22, "fairseq2.gang.ProcessGroupGang.create_gang", false]], "create_layer_norm() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_layer_norm", false]], "create_model() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_model", false]], "create_new_model() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.create_new_model", false]], "create_parallel_gangs() (in module fairseq2.gang)": [[22, "fairseq2.gang.create_parallel_gangs", false]], "create_position_encoder() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_position_encoder", false]], "create_qwen_model() (in module fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.create_qwen_model", false]], "create_raw_encoder() (fairseq2.data.tokenizers.tokenizer method)": [[18, "fairseq2.data.tokenizers.Tokenizer.create_raw_encoder", false]], "create_raw_encoder() (fairseq2.models.qwen.qwentokenizer method)": [[30, "fairseq2.models.qwen.QwenTokenizer.create_raw_encoder", false]], "create_self_attention() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.create_self_attention", false]], "datasetfamilynotknownerror": [[19, "fairseq2.datasets.hub.DatasetFamilyNotKnownError", false]], "datasethub (class in fairseq2.datasets.hub)": [[19, "fairseq2.datasets.hub.DatasetHub", false]], "datasethubaccessor (class in fairseq2.datasets.hub)": [[19, "fairseq2.datasets.hub.DatasetHubAccessor", false]], "datasetnotknownerror": [[19, "fairseq2.datasets.hub.DatasetNotKnownError", false]], "decode_from_tokens() (fairseq2.data.tokenizers.tokendecoder method)": [[18, "fairseq2.data.tokenizers.TokenDecoder.decode_from_tokens", false]], "device (fairseq2.gang.fakegang property)": [[22, "fairseq2.gang.FakeGang.device", false]], "device (fairseq2.gang.gang property)": [[22, "fairseq2.gang.Gang.device", false]], "device (fairseq2.gang.processgroupgang property)": [[22, "fairseq2.gang.ProcessGroupGang.device", false]], "dp (fairseq2.gang.gangs attribute)": [[22, "fairseq2.gang.Gangs.dp", false]], "dropout_p (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.dropout_p", false]], "dropout_p (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.dropout_p", false]], "embedding (class in fairseq2.nn)": [[32, "fairseq2.nn.Embedding", false]], "encode_as_tokens() (fairseq2.data.tokenizers.tokenencoder method)": [[18, "fairseq2.data.tokenizers.TokenEncoder.encode_as_tokens", false]], "eoh_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.eoh_idx", false]], "eos_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.eos_idx", false]], "errors (fairseq2.utils.validation.validationresult property)": [[24, "fairseq2.utils.validation.ValidationResult.errors", false]], "export_qwen() (in module fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.export_qwen", false]], "extra_repr() (fairseq2.nn.rmsnorm method)": [[35, "fairseq2.nn.RMSNorm.extra_repr", false]], "extra_repr() (fairseq2.nn.standardlayernorm method)": [[35, "fairseq2.nn.StandardLayerNorm.extra_repr", false]], "fairseq2.assets": [[14, "module-fairseq2.assets", false]], "fairseq2.gang": [[22, "module-fairseq2.gang", false]], "fairseq2.recipe.optim": [[23, "module-fairseq2.recipe.optim", false]], "fairseq2.utils.validation": [[24, "module-fairseq2.utils.validation", false]], "fakegang (class in fairseq2.gang)": [[22, "fairseq2.gang.FakeGang", false]], "ffn_inner_dim (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim", false]], "ffn_inner_dim (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.ffn_inner_dim", false]], "ffn_inner_dim_multiple_of (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_multiple_of", false]], "ffn_inner_dim_multiplier (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_multiplier", false]], "ffn_inner_dim_scale (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.ffn_inner_dim_scale", false]], "forward() (fairseq2.nn.additiveresidualconnect method)": [[38, "fairseq2.nn.AdditiveResidualConnect.forward", false]], "forward() (fairseq2.nn.embedding method)": [[32, "fairseq2.nn.Embedding.forward", false]], "forward() (fairseq2.nn.layernorm method)": [[35, "fairseq2.nn.LayerNorm.forward", false]], "forward() (fairseq2.nn.learnedpositionencoder method)": [[36, "fairseq2.nn.LearnedPositionEncoder.forward", false]], "forward() (fairseq2.nn.linear method)": [[37, "fairseq2.nn.Linear.forward", false]], "forward() (fairseq2.nn.positionencoder method)": [[36, "fairseq2.nn.PositionEncoder.forward", false]], "forward() (fairseq2.nn.projection method)": [[37, "fairseq2.nn.Projection.forward", false]], "forward() (fairseq2.nn.residualconnect method)": [[38, "fairseq2.nn.ResidualConnect.forward", false]], "forward() (fairseq2.nn.rmsnorm method)": [[35, "fairseq2.nn.RMSNorm.forward", false]], "forward() (fairseq2.nn.rotaryencoder method)": [[36, "fairseq2.nn.RotaryEncoder.forward", false]], "forward() (fairseq2.nn.scaledresidualconnect method)": [[38, "fairseq2.nn.ScaledResidualConnect.forward", false]], "forward() (fairseq2.nn.shardedembedding method)": [[32, "fairseq2.nn.ShardedEmbedding.forward", false]], "forward() (fairseq2.nn.sinusoidalpositionencoder method)": [[36, "fairseq2.nn.SinusoidalPositionEncoder.forward", false]], "forward() (fairseq2.nn.standardembedding method)": [[32, "fairseq2.nn.StandardEmbedding.forward", false]], "forward() (fairseq2.nn.standardlayernorm method)": [[35, "fairseq2.nn.StandardLayerNorm.forward", false]], "forward() (fairseq2.nn.tiedprojection method)": [[37, "fairseq2.nn.TiedProjection.forward", false]], "from_embedding() (fairseq2.nn.shardedembedding static method)": [[32, "fairseq2.nn.ShardedEmbedding.from_embedding", false]], "gang (class in fairseq2.gang)": [[22, "fairseq2.gang.Gang", false]], "gangerror (class in fairseq2.gang)": [[22, "fairseq2.gang.GangError", false]], "gangs (class in fairseq2.gang)": [[22, "fairseq2.gang.Gangs", false]], "get_arch_config() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.get_arch_config", false]], "get_archs() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.get_archs", false]], "get_dataset_config() (fairseq2.datasets.hub.datasethub method)": [[19, "fairseq2.datasets.hub.DatasetHub.get_dataset_config", false]], "get_llama_model_hub() (in module fairseq2.models.llama)": [[29, "fairseq2.models.llama.get_llama_model_hub", false]], "get_llama_tokenizer_hub() (in module fairseq2.models.llama)": [[29, "fairseq2.models.llama.get_llama_tokenizer_hub", false]], "get_model_config() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.get_model_config", false]], "get_qwen_model_hub() (in module fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.get_qwen_model_hub", false]], "get_qwen_shard_specs() (in module fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.get_qwen_shard_specs", false]], "get_qwen_tokenizer_hub() (in module fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.get_qwen_tokenizer_hub", false]], "get_std_scale_factor() (fairseq2.models.qwen.qwenfactory method)": [[30, "fairseq2.models.qwen.QwenFactory.get_std_scale_factor", false]], "get_tokenizer_config() (fairseq2.data.tokenizers.hub.tokenizerhub method)": [[17, "fairseq2.data.tokenizers.hub.TokenizerHub.get_tokenizer_config", false]], "has_error() (fairseq2.utils.validation.validationresult method)": [[24, "fairseq2.utils.validation.ValidationResult.has_error", false]], "head_dim (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.head_dim", false]], "impl (fairseq2.models.llama.llamatokenizerconfig attribute)": [[29, "fairseq2.models.llama.LLaMATokenizerConfig.impl", false]], "increment_step_nr() (fairseq2.nn.incrementalstatebag method)": [[33, "fairseq2.nn.IncrementalStateBag.increment_step_nr", false]], "incrementalstate (class in fairseq2.nn)": [[33, "fairseq2.nn.IncrementalState", false]], "incrementalstatebag (class in fairseq2.nn)": [[33, "fairseq2.nn.IncrementalStateBag", false]], "init_scaled_embedding() (in module fairseq2.nn)": [[32, "fairseq2.nn.init_scaled_embedding", false]], "init_std (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.init_std", false]], "init_std_scale (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.init_std_scale", false]], "iter_cards() (fairseq2.data.tokenizers.hub.tokenizerhub method)": [[17, "fairseq2.data.tokenizers.hub.TokenizerHub.iter_cards", false]], "iter_cards() (fairseq2.datasets.hub.datasethub method)": [[19, "fairseq2.datasets.hub.DatasetHub.iter_cards", false]], "iter_cards() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.iter_cards", false]], "iter_checkpoint() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.iter_checkpoint", false]], "k_norm (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.k_norm", false]], "layernorm (class in fairseq2.nn)": [[35, "fairseq2.nn.LayerNorm", false]], "learnedpositionencoder (class in fairseq2.nn)": [[36, "fairseq2.nn.LearnedPositionEncoder", false]], "linear (class in fairseq2.nn)": [[37, "fairseq2.nn.Linear", false]], "llamaconfig (class in fairseq2.models.llama)": [[29, "fairseq2.models.llama.LLaMAConfig", false]], "llamatokenizerconfig (class in fairseq2.models.llama)": [[29, "fairseq2.models.llama.LLaMATokenizerConfig", false]], "load_custom_model() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.load_custom_model", false]], "load_custom_tokenizer() (fairseq2.data.tokenizers.hub.tokenizerhub method)": [[17, "fairseq2.data.tokenizers.hub.TokenizerHub.load_custom_tokenizer", false]], "load_model() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.load_model", false]], "load_model() (in module fairseq2.models.hub)": [[27, "fairseq2.models.hub.load_model", false]], "load_tokenizer() (fairseq2.data.tokenizers.hub.tokenizerhub method)": [[17, "fairseq2.data.tokenizers.hub.TokenizerHub.load_tokenizer", false]], "load_tokenizer() (in module fairseq2.data.tokenizers.hub)": [[17, "fairseq2.data.tokenizers.hub.load_tokenizer", false]], "max (fairseq2.gang.reduceoperation attribute)": [[22, "fairseq2.gang.ReduceOperation.MAX", false]], "max_num_steps (fairseq2.nn.incrementalstatebag property)": [[33, "fairseq2.nn.IncrementalStateBag.max_num_steps", false]], "max_seq_len (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.max_seq_len", false]], "max_seq_len (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.max_seq_len", false]], "max_seq_len (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.max_seq_len", false]], "maybe_get_arch_config() (fairseq2.models.hub.modelhub method)": [[27, "fairseq2.models.hub.ModelHub.maybe_get_arch_config", false]], "maybe_get_state() (fairseq2.nn.incrementalstatebag method)": [[33, "fairseq2.nn.IncrementalStateBag.maybe_get_state", false]], "maybe_raise_param_group_length_error() (in module fairseq2.recipe.optim)": [[23, "fairseq2.recipe.optim.maybe_raise_param_group_length_error", false]], "mean (fairseq2.gang.reduceoperation attribute)": [[22, "fairseq2.gang.ReduceOperation.MEAN", false]], "min (fairseq2.gang.reduceoperation attribute)": [[22, "fairseq2.gang.ReduceOperation.MIN", false]], "min_seq_len (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.min_seq_len", false]], "model_dim (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.model_dim", false]], "model_dim (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.model_dim", false]], "modelarchitecturenotknownerror": [[27, "fairseq2.models.hub.ModelArchitectureNotKnownError", false]], "modelfamilynotknownerror": [[27, "fairseq2.models.hub.ModelFamilyNotKnownError", false]], "modelhub (class in fairseq2.models.hub)": [[27, "fairseq2.models.hub.ModelHub", false]], "modelhubaccessor (class in fairseq2.models.hub)": [[27, "fairseq2.models.hub.ModelHubAccessor", false]], "modelnotknownerror": [[27, "fairseq2.models.hub.ModelNotKnownError", false]], "module": [[14, "module-fairseq2.assets", false], [22, "module-fairseq2.gang", false], [23, "module-fairseq2.recipe.optim", false], [24, "module-fairseq2.utils.validation", false]], "num_attn_heads (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.num_attn_heads", false]], "num_attn_heads (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.num_attn_heads", false]], "num_key_value_heads (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.num_key_value_heads", false]], "num_key_value_heads (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.num_key_value_heads", false]], "num_layers (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.num_layers", false]], "num_layers (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.num_layers", false]], "objectvalidator (class in fairseq2.utils.validation)": [[24, "fairseq2.utils.validation.ObjectValidator", false]], "of() (fairseq2.nn.batchlayout static method)": [[31, "fairseq2.nn.BatchLayout.of", false]], "open_custom_dataset() (fairseq2.datasets.hub.datasethub method)": [[19, "fairseq2.datasets.hub.DatasetHub.open_custom_dataset", false]], "open_dataset() (fairseq2.datasets.hub.datasethub method)": [[19, "fairseq2.datasets.hub.DatasetHub.open_dataset", false]], "packed (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.packed", false]], "pad_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.pad_idx", false]], "pad_idx (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.pad_idx", false]], "padded (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.padded", false]], "position_indices (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.position_indices", false]], "positionencoder (class in fairseq2.nn)": [[36, "fairseq2.nn.PositionEncoder", false]], "pp (fairseq2.gang.gangs attribute)": [[22, "fairseq2.gang.Gangs.pp", false]], "prefix_indices (fairseq2.data.tokenizers.tokenencoder property)": [[18, "fairseq2.data.tokenizers.TokenEncoder.prefix_indices", false]], "prepare_parameter_groups() (in module fairseq2.recipe.optim)": [[23, "fairseq2.recipe.optim.prepare_parameter_groups", false]], "processgroupgang (class in fairseq2.gang)": [[22, "fairseq2.gang.ProcessGroupGang", false]], "product (fairseq2.gang.reduceoperation attribute)": [[22, "fairseq2.gang.ReduceOperation.PRODUCT", false]], "projection (class in fairseq2.nn)": [[37, "fairseq2.nn.Projection", false]], "q_norm (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.q_norm", false]], "qkv_proj_bias (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.qkv_proj_bias", false]], "qwen_family (in module fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.QWEN_FAMILY", false]], "qwenconfig (class in fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.QwenConfig", false]], "qwenfactory (class in fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.QwenFactory", false]], "qwentokenizer (class in fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.QwenTokenizer", false]], "qwentokenizerconfig (class in fairseq2.models.qwen)": [[30, "fairseq2.models.qwen.QwenTokenizerConfig", false]], "raise_operational_gang_error() (in module fairseq2.gang)": [[22, "fairseq2.gang.raise_operational_gang_error", false]], "rank (fairseq2.gang.fakegang property)": [[22, "fairseq2.gang.FakeGang.rank", false]], "rank (fairseq2.gang.gang property)": [[22, "fairseq2.gang.Gang.rank", false]], "rank (fairseq2.gang.processgroupgang property)": [[22, "fairseq2.gang.ProcessGroupGang.rank", false]], "rdp (fairseq2.gang.gangs attribute)": [[22, "fairseq2.gang.Gangs.rdp", false]], "reduceoperation (class in fairseq2.gang)": [[22, "fairseq2.gang.ReduceOperation", false]], "reorder() (fairseq2.nn.incrementalstate method)": [[33, "fairseq2.nn.IncrementalState.reorder", false]], "reorder() (fairseq2.nn.incrementalstatebag method)": [[33, "fairseq2.nn.IncrementalStateBag.reorder", false]], "reset_non_persistent_buffers() (fairseq2.nn.rotaryencoder method)": [[36, "fairseq2.nn.RotaryEncoder.reset_non_persistent_buffers", false]], "reset_non_persistent_buffers() (fairseq2.nn.sinusoidalpositionencoder method)": [[36, "fairseq2.nn.SinusoidalPositionEncoder.reset_non_persistent_buffers", false]], "reset_parameters() (fairseq2.nn.learnedpositionencoder method)": [[36, "fairseq2.nn.LearnedPositionEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.linear method)": [[37, "fairseq2.nn.Linear.reset_parameters", false]], "reset_parameters() (fairseq2.nn.rmsnorm method)": [[35, "fairseq2.nn.RMSNorm.reset_parameters", false]], "reset_parameters() (fairseq2.nn.rotaryencoder method)": [[36, "fairseq2.nn.RotaryEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.shardedembedding method)": [[32, "fairseq2.nn.ShardedEmbedding.reset_parameters", false]], "reset_parameters() (fairseq2.nn.sinusoidalpositionencoder method)": [[36, "fairseq2.nn.SinusoidalPositionEncoder.reset_parameters", false]], "reset_parameters() (fairseq2.nn.standardembedding method)": [[32, "fairseq2.nn.StandardEmbedding.reset_parameters", false]], "reset_parameters() (fairseq2.nn.standardlayernorm method)": [[35, "fairseq2.nn.StandardLayerNorm.reset_parameters", false]], "residualconnect (class in fairseq2.nn)": [[38, "fairseq2.nn.ResidualConnect", false]], "result (fairseq2.utils.validation.validationerror attribute)": [[24, "fairseq2.utils.validation.ValidationError.result", false]], "rmsnorm (class in fairseq2.nn)": [[35, "fairseq2.nn.RMSNorm", false]], "root (fairseq2.gang.gangs attribute)": [[22, "fairseq2.gang.Gangs.root", false]], "rope_scale (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.rope_scale", false]], "rope_theta (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.rope_theta", false]], "rope_theta (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.rope_theta", false]], "rotaryencoder (class in fairseq2.nn)": [[36, "fairseq2.nn.RotaryEncoder", false]], "scaledresidualconnect (class in fairseq2.nn)": [[38, "fairseq2.nn.ScaledResidualConnect", false]], "sdp (fairseq2.gang.gangs attribute)": [[22, "fairseq2.gang.Gangs.sdp", false]], "seq_begin_indices (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.seq_begin_indices", false]], "seq_begin_indices_pt (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.seq_begin_indices_pt", false]], "seq_lens (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.seq_lens", false]], "seq_lens_pt (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.seq_lens_pt", false]], "set_state() (fairseq2.nn.incrementalstatebag method)": [[33, "fairseq2.nn.IncrementalStateBag.set_state", false]], "shard_embed_dim (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.shard_embed_dim", false]], "shardedembedding (class in fairseq2.nn)": [[32, "fairseq2.nn.ShardedEmbedding", false]], "sinusoidalpositionencoder (class in fairseq2.nn)": [[36, "fairseq2.nn.SinusoidalPositionEncoder", false]], "size (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.size", false]], "size (fairseq2.gang.fakegang property)": [[22, "fairseq2.gang.FakeGang.size", false]], "size (fairseq2.gang.gang property)": [[22, "fairseq2.gang.Gang.size", false]], "size (fairseq2.gang.processgroupgang property)": [[22, "fairseq2.gang.ProcessGroupGang.size", false]], "size_bytes() (fairseq2.nn.incrementalstate method)": [[33, "fairseq2.nn.IncrementalState.size_bytes", false]], "size_bytes() (fairseq2.nn.incrementalstatebag method)": [[33, "fairseq2.nn.IncrementalStateBag.size_bytes", false]], "split_regex (fairseq2.models.llama.llamatokenizerconfig attribute)": [[29, "fairseq2.models.llama.LLaMATokenizerConfig.split_regex", false]], "standardembedding (class in fairseq2.nn)": [[32, "fairseq2.nn.StandardEmbedding", false]], "standardlayernorm (class in fairseq2.nn)": [[35, "fairseq2.nn.StandardLayerNorm", false]], "standardobjectvalidator (class in fairseq2.utils.validation)": [[24, "fairseq2.utils.validation.StandardObjectValidator", false]], "step_nr (fairseq2.nn.incrementalstatebag property)": [[33, "fairseq2.nn.IncrementalStateBag.step_nr", false]], "sub_results (fairseq2.utils.validation.validationresult property)": [[24, "fairseq2.utils.validation.ValidationResult.sub_results", false]], "suffix_indices (fairseq2.data.tokenizers.tokenencoder property)": [[18, "fairseq2.data.tokenizers.TokenEncoder.suffix_indices", false]], "sum (fairseq2.gang.reduceoperation attribute)": [[22, "fairseq2.gang.ReduceOperation.SUM", false]], "supports_process_group (fairseq2.gang.fakegang property)": [[22, "fairseq2.gang.FakeGang.supports_process_group", false]], "supports_process_group (fairseq2.gang.gang property)": [[22, "fairseq2.gang.Gang.supports_process_group", false]], "supports_process_group (fairseq2.gang.processgroupgang property)": [[22, "fairseq2.gang.ProcessGroupGang.supports_process_group", false]], "tied_embeddings (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.tied_embeddings", false]], "tied_embeddings (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.tied_embeddings", false]], "tiedprojection (class in fairseq2.nn)": [[37, "fairseq2.nn.TiedProjection", false]], "to_embedding() (fairseq2.nn.shardedembedding method)": [[32, "fairseq2.nn.ShardedEmbedding.to_embedding", false]], "tokendecoder (class in fairseq2.data.tokenizers)": [[18, "fairseq2.data.tokenizers.TokenDecoder", false]], "tokenencoder (class in fairseq2.data.tokenizers)": [[18, "fairseq2.data.tokenizers.TokenEncoder", false]], "tokenizer (class in fairseq2.data.tokenizers)": [[18, "fairseq2.data.tokenizers.Tokenizer", false]], "tokenizerfamilynotknownerror": [[17, "fairseq2.data.tokenizers.hub.TokenizerFamilyNotKnownError", false]], "tokenizerhub (class in fairseq2.data.tokenizers.hub)": [[17, "fairseq2.data.tokenizers.hub.TokenizerHub", false]], "tokenizerhubaccessor (class in fairseq2.data.tokenizers.hub)": [[17, "fairseq2.data.tokenizers.hub.TokenizerHubAccessor", false]], "tokenizernotknownerror": [[17, "fairseq2.data.tokenizers.hub.TokenizerNotKnownError", false]], "tp (fairseq2.gang.gangs attribute)": [[22, "fairseq2.gang.Gangs.tp", false]], "unk_idx (fairseq2.data.tokenizers.vocabularyinfo attribute)": [[18, "fairseq2.data.tokenizers.VocabularyInfo.unk_idx", false]], "use_eot (fairseq2.models.llama.llamatokenizerconfig attribute)": [[29, "fairseq2.models.llama.LLaMATokenizerConfig.use_eot", false]], "use_im_end (fairseq2.models.qwen.qwentokenizerconfig attribute)": [[30, "fairseq2.models.qwen.QwenTokenizerConfig.use_im_end", false]], "use_scaled_rope (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.use_scaled_rope", false]], "validatable (class in fairseq2.utils.validation)": [[24, "fairseq2.utils.validation.Validatable", false]], "validate() (fairseq2.utils.validation.objectvalidator method)": [[24, "fairseq2.utils.validation.ObjectValidator.validate", false]], "validate() (fairseq2.utils.validation.standardobjectvalidator method)": [[24, "fairseq2.utils.validation.StandardObjectValidator.validate", false]], "validate() (fairseq2.utils.validation.validatable method)": [[24, "fairseq2.utils.validation.Validatable.validate", false]], "validationerror": [[24, "fairseq2.utils.validation.ValidationError", false]], "validationresult (class in fairseq2.utils.validation)": [[24, "fairseq2.utils.validation.ValidationResult", false]], "vocab_info (fairseq2.data.tokenizers.tokenizer property)": [[18, "fairseq2.data.tokenizers.Tokenizer.vocab_info", false]], "vocab_info (fairseq2.models.qwen.qwentokenizer property)": [[30, "fairseq2.models.qwen.QwenTokenizer.vocab_info", false]], "vocab_size (fairseq2.models.llama.llamaconfig attribute)": [[29, "fairseq2.models.llama.LLaMAConfig.vocab_size", false]], "vocab_size (fairseq2.models.qwen.qwenconfig attribute)": [[30, "fairseq2.models.qwen.QwenConfig.vocab_size", false]], "vocabularyinfo (class in fairseq2.data.tokenizers)": [[18, "fairseq2.data.tokenizers.VocabularyInfo", false]], "width (fairseq2.nn.batchlayout property)": [[31, "fairseq2.nn.BatchLayout.width", false]]}, "objects": {"fairseq2": [[14, 0, 0, "-", "assets"], [22, 0, 0, "-", "gang"]], "fairseq2.data.tokenizers": [[18, 1, 1, "", "TokenDecoder"], [18, 1, 1, "", "TokenEncoder"], [18, 1, 1, "", "Tokenizer"], [18, 1, 1, "", "VocabularyInfo"]], "fairseq2.data.tokenizers.TokenDecoder": [[18, 2, 1, "", "decode_from_tokens"]], "fairseq2.data.tokenizers.TokenEncoder": [[18, 2, 1, "", "encode_as_tokens"], [18, 3, 1, "", "prefix_indices"], [18, 3, 1, "", "suffix_indices"]], "fairseq2.data.tokenizers.Tokenizer": [[18, 2, 1, "", "create_decoder"], [18, 2, 1, "", "create_encoder"], [18, 2, 1, "", "create_raw_encoder"], [18, 3, 1, "", "vocab_info"]], "fairseq2.data.tokenizers.VocabularyInfo": [[18, 4, 1, "", "boh_idx"], [18, 4, 1, "", "bos_idx"], [18, 4, 1, "", "eoh_idx"], [18, 4, 1, "", "eos_idx"], [18, 4, 1, "", "pad_idx"], [18, 4, 1, "", "size"], [18, 4, 1, "", "unk_idx"]], "fairseq2.data.tokenizers.hub": [[17, 5, 1, "", "TokenizerFamilyNotKnownError"], [17, 1, 1, "", "TokenizerHub"], [17, 1, 1, "", "TokenizerHubAccessor"], [17, 5, 1, "", "TokenizerNotKnownError"], [17, 6, 1, "", "load_tokenizer"]], "fairseq2.data.tokenizers.hub.TokenizerHub": [[17, 2, 1, "", "get_tokenizer_config"], [17, 2, 1, "", "iter_cards"], [17, 2, 1, "", "load_custom_tokenizer"], [17, 2, 1, "", "load_tokenizer"]], "fairseq2.datasets.hub": [[19, 5, 1, "", "DatasetFamilyNotKnownError"], [19, 1, 1, "", "DatasetHub"], [19, 1, 1, "", "DatasetHubAccessor"], [19, 5, 1, "", "DatasetNotKnownError"]], "fairseq2.datasets.hub.DatasetHub": [[19, 2, 1, "", "get_dataset_config"], [19, 2, 1, "", "iter_cards"], [19, 2, 1, "", "open_custom_dataset"], [19, 2, 1, "", "open_dataset"]], "fairseq2.gang": [[22, 1, 1, "", "FakeGang"], [22, 1, 1, "", "Gang"], [22, 1, 1, "", "GangError"], [22, 1, 1, "", "Gangs"], [22, 1, 1, "", "ProcessGroupGang"], [22, 1, 1, "", "ReduceOperation"], [22, 6, 1, "", "all_sum"], [22, 6, 1, "", "broadcast_flag"], [22, 6, 1, "", "create_fake_gangs"], [22, 6, 1, "", "create_fsdp_gangs"], [22, 6, 1, "", "create_parallel_gangs"], [22, 6, 1, "", "raise_operational_gang_error"]], "fairseq2.gang.FakeGang": [[22, 2, 1, "", "all_gather"], [22, 2, 1, "", "all_gather_to_list"], [22, 2, 1, "", "all_reduce"], [22, 2, 1, "", "as_process_group"], [22, 2, 1, "", "barrier"], [22, 2, 1, "", "broadcast"], [22, 2, 1, "", "broadcast_objects"], [22, 2, 1, "", "close"], [22, 2, 1, "", "create_gang"], [22, 3, 1, "", "device"], [22, 3, 1, "", "rank"], [22, 3, 1, "", "size"], [22, 3, 1, "", "supports_process_group"]], "fairseq2.gang.Gang": [[22, 2, 1, "", "all_gather"], [22, 2, 1, "", "all_gather_to_list"], [22, 2, 1, "", "all_reduce"], [22, 2, 1, "", "as_process_group"], [22, 2, 1, "", "barrier"], [22, 2, 1, "", "broadcast"], [22, 2, 1, "", "broadcast_objects"], [22, 2, 1, "", "create_gang"], [22, 3, 1, "", "device"], [22, 3, 1, "", "rank"], [22, 3, 1, "", "size"], [22, 3, 1, "", "supports_process_group"]], "fairseq2.gang.Gangs": [[22, 2, 1, "", "close"], [22, 4, 1, "", "dp"], [22, 4, 1, "", "pp"], [22, 4, 1, "", "rdp"], [22, 4, 1, "", "root"], [22, 4, 1, "", "sdp"], [22, 4, 1, "", "tp"]], "fairseq2.gang.ProcessGroupGang": [[22, 2, 1, "", "all_gather"], [22, 2, 1, "", "all_gather_to_list"], [22, 2, 1, "", "all_reduce"], [22, 2, 1, "", "as_process_group"], [22, 2, 1, "", "barrier"], [22, 2, 1, "", "broadcast"], [22, 2, 1, "", "broadcast_objects"], [22, 2, 1, "", "close"], [22, 2, 1, "", "create_default_process_group"], [22, 2, 1, "", "create_gang"], [22, 3, 1, "", "device"], [22, 3, 1, "", "rank"], [22, 3, 1, "", "size"], [22, 3, 1, "", "supports_process_group"]], "fairseq2.gang.ReduceOperation": [[22, 4, 1, "", "MAX"], [22, 4, 1, "", "MEAN"], [22, 4, 1, "", "MIN"], [22, 4, 1, "", "PRODUCT"], [22, 4, 1, "", "SUM"]], "fairseq2.models.hub": [[27, 5, 1, "", "ModelArchitectureNotKnownError"], [27, 5, 1, "", "ModelFamilyNotKnownError"], [27, 1, 1, "", "ModelHub"], [27, 1, 1, "", "ModelHubAccessor"], [27, 5, 1, "", "ModelNotKnownError"], [27, 6, 1, "", "load_model"]], "fairseq2.models.hub.ModelHub": [[27, 2, 1, "", "create_new_model"], [27, 2, 1, "", "get_arch_config"], [27, 2, 1, "", "get_archs"], [27, 2, 1, "", "get_model_config"], [27, 2, 1, "", "iter_cards"], [27, 2, 1, "", "iter_checkpoint"], [27, 2, 1, "", "load_custom_model"], [27, 2, 1, "", "load_model"], [27, 2, 1, "", "maybe_get_arch_config"]], "fairseq2.models.llama": [[29, 1, 1, "", "LLaMAConfig"], [29, 1, 1, "", "LLaMATokenizerConfig"], [29, 6, 1, "", "get_llama_model_hub"], [29, 6, 1, "", "get_llama_tokenizer_hub"]], "fairseq2.models.llama.LLaMAConfig": [[29, 4, 1, "", "dropout_p"], [29, 4, 1, "", "ffn_inner_dim"], [29, 4, 1, "", "ffn_inner_dim_multiple_of"], [29, 4, 1, "", "ffn_inner_dim_multiplier"], [29, 4, 1, "", "ffn_inner_dim_scale"], [29, 4, 1, "", "init_std"], [29, 4, 1, "", "init_std_scale"], [29, 4, 1, "", "max_seq_len"], [29, 4, 1, "", "model_dim"], [29, 4, 1, "", "num_attn_heads"], [29, 4, 1, "", "num_key_value_heads"], [29, 4, 1, "", "num_layers"], [29, 4, 1, "", "pad_idx"], [29, 4, 1, "", "rope_scale"], [29, 4, 1, "", "rope_theta"], [29, 4, 1, "", "shard_embed_dim"], [29, 4, 1, "", "tied_embeddings"], [29, 4, 1, "", "use_scaled_rope"], [29, 4, 1, "", "vocab_size"]], "fairseq2.models.llama.LLaMATokenizerConfig": [[29, 4, 1, "", "impl"], [29, 4, 1, "", "split_regex"], [29, 4, 1, "", "use_eot"]], "fairseq2.models.qwen": [[30, 7, 1, "", "QWEN_FAMILY"], [30, 1, 1, "", "QwenConfig"], [30, 1, 1, "", "QwenFactory"], [30, 1, 1, "", "QwenTokenizer"], [30, 1, 1, "", "QwenTokenizerConfig"], [30, 6, 1, "", "convert_qwen_state_dict"], [30, 6, 1, "", "create_qwen_model"], [30, 6, 1, "", "export_qwen"], [30, 6, 1, "", "get_qwen_model_hub"], [30, 6, 1, "", "get_qwen_shard_specs"], [30, 6, 1, "", "get_qwen_tokenizer_hub"]], "fairseq2.models.qwen.QwenConfig": [[30, 4, 1, "", "dropout_p"], [30, 4, 1, "", "ffn_inner_dim"], [30, 4, 1, "", "head_dim"], [30, 4, 1, "", "k_norm"], [30, 4, 1, "", "max_seq_len"], [30, 4, 1, "", "model_dim"], [30, 4, 1, "", "num_attn_heads"], [30, 4, 1, "", "num_key_value_heads"], [30, 4, 1, "", "num_layers"], [30, 4, 1, "", "q_norm"], [30, 4, 1, "", "qkv_proj_bias"], [30, 4, 1, "", "rope_theta"], [30, 4, 1, "", "tied_embeddings"], [30, 4, 1, "", "vocab_size"]], "fairseq2.models.qwen.QwenFactory": [[30, 2, 1, "", "create_decoder"], [30, 2, 1, "", "create_decoder_frontend"], [30, 2, 1, "", "create_decoder_layer"], [30, 2, 1, "", "create_embedding"], [30, 2, 1, "", "create_ffn"], [30, 2, 1, "", "create_final_projection"], [30, 2, 1, "", "create_layer_norm"], [30, 2, 1, "", "create_model"], [30, 2, 1, "", "create_position_encoder"], [30, 2, 1, "", "create_self_attention"], [30, 2, 1, "", "get_std_scale_factor"]], "fairseq2.models.qwen.QwenTokenizer": [[30, 2, 1, "", "create_decoder"], [30, 2, 1, "", "create_encoder"], [30, 2, 1, "", "create_raw_encoder"], [30, 3, 1, "", "vocab_info"]], "fairseq2.models.qwen.QwenTokenizerConfig": [[30, 4, 1, "", "use_im_end"]], "fairseq2.nn": [[38, 1, 1, "", "AdditiveResidualConnect"], [31, 1, 1, "", "BatchLayout"], [32, 1, 1, "", "Embedding"], [33, 1, 1, "", "IncrementalState"], [33, 1, 1, "", "IncrementalStateBag"], [35, 1, 1, "", "LayerNorm"], [36, 1, 1, "", "LearnedPositionEncoder"], [37, 1, 1, "", "Linear"], [36, 1, 1, "", "PositionEncoder"], [37, 1, 1, "", "Projection"], [35, 1, 1, "", "RMSNorm"], [38, 1, 1, "", "ResidualConnect"], [36, 1, 1, "", "RotaryEncoder"], [38, 1, 1, "", "ScaledResidualConnect"], [32, 1, 1, "", "ShardedEmbedding"], [36, 1, 1, "", "SinusoidalPositionEncoder"], [32, 1, 1, "", "StandardEmbedding"], [35, 1, 1, "", "StandardLayerNorm"], [37, 1, 1, "", "TiedProjection"], [32, 6, 1, "", "init_scaled_embedding"]], "fairseq2.nn.AdditiveResidualConnect": [[38, 2, 1, "", "forward"]], "fairseq2.nn.BatchLayout": [[31, 4, 1, "", "compiled_max_seq_len"], [31, 3, 1, "", "max_seq_len"], [31, 3, 1, "", "min_seq_len"], [31, 2, 1, "", "of"], [31, 3, 1, "", "packed"], [31, 3, 1, "", "padded"], [31, 3, 1, "", "position_indices"], [31, 3, 1, "", "seq_begin_indices"], [31, 3, 1, "", "seq_begin_indices_pt"], [31, 3, 1, "", "seq_lens"], [31, 3, 1, "", "seq_lens_pt"], [31, 3, 1, "", "width"]], "fairseq2.nn.Embedding": [[32, 2, 1, "", "forward"]], "fairseq2.nn.IncrementalState": [[33, 2, 1, "", "capacity_bytes"], [33, 2, 1, "", "reorder"], [33, 2, 1, "", "size_bytes"]], "fairseq2.nn.IncrementalStateBag": [[33, 2, 1, "", "capacity_bytes"], [33, 3, 1, "", "capacity_increment"], [33, 2, 1, "", "increment_step_nr"], [33, 3, 1, "", "max_num_steps"], [33, 2, 1, "", "maybe_get_state"], [33, 2, 1, "", "reorder"], [33, 2, 1, "", "set_state"], [33, 2, 1, "", "size_bytes"], [33, 3, 1, "", "step_nr"]], "fairseq2.nn.LayerNorm": [[35, 2, 1, "", "forward"]], "fairseq2.nn.LearnedPositionEncoder": [[36, 2, 1, "", "forward"], [36, 2, 1, "", "reset_parameters"]], "fairseq2.nn.Linear": [[37, 2, 1, "", "forward"], [37, 2, 1, "", "reset_parameters"]], "fairseq2.nn.PositionEncoder": [[36, 2, 1, "", "forward"]], "fairseq2.nn.Projection": [[37, 2, 1, "", "forward"]], "fairseq2.nn.RMSNorm": [[35, 2, 1, "", "extra_repr"], [35, 2, 1, "", "forward"], [35, 2, 1, "", "reset_parameters"]], "fairseq2.nn.ResidualConnect": [[38, 2, 1, "", "forward"]], "fairseq2.nn.RotaryEncoder": [[36, 2, 1, "", "forward"], [36, 2, 1, "", "reset_non_persistent_buffers"], [36, 2, 1, "", "reset_parameters"]], "fairseq2.nn.ScaledResidualConnect": [[38, 2, 1, "", "forward"]], "fairseq2.nn.ShardedEmbedding": [[32, 2, 1, "", "forward"], [32, 2, 1, "", "from_embedding"], [32, 2, 1, "", "reset_parameters"], [32, 2, 1, "", "to_embedding"]], "fairseq2.nn.SinusoidalPositionEncoder": [[36, 2, 1, "", "forward"], [36, 2, 1, "", "reset_non_persistent_buffers"], [36, 2, 1, "", "reset_parameters"]], "fairseq2.nn.StandardEmbedding": [[32, 2, 1, "", "forward"], [32, 2, 1, "", "reset_parameters"]], "fairseq2.nn.StandardLayerNorm": [[35, 2, 1, "", "extra_repr"], [35, 2, 1, "", "forward"], [35, 2, 1, "", "reset_parameters"]], "fairseq2.nn.TiedProjection": [[37, 2, 1, "", "forward"]], "fairseq2.nn.utils.mask": [[39, 6, 1, "", "apply_mask"], [39, 6, 1, "", "compute_row_mask"]], "fairseq2.recipe": [[23, 0, 0, "-", "optim"]], "fairseq2.recipe.optim": [[23, 6, 1, "", "maybe_raise_param_group_length_error"], [23, 6, 1, "", "prepare_parameter_groups"]], "fairseq2.utils": [[24, 0, 0, "-", "validation"]], "fairseq2.utils.validation": [[24, 1, 1, "", "ObjectValidator"], [24, 1, 1, "", "StandardObjectValidator"], [24, 1, 1, "", "Validatable"], [24, 5, 1, "", "ValidationError"], [24, 1, 1, "", "ValidationResult"]], "fairseq2.utils.validation.ObjectValidator": [[24, 2, 1, "", "validate"]], "fairseq2.utils.validation.StandardObjectValidator": [[24, 2, 1, "", "validate"]], "fairseq2.utils.validation.Validatable": [[24, 2, 1, "", "validate"]], "fairseq2.utils.validation.ValidationError": [[24, 4, 1, "", "result"]], "fairseq2.utils.validation.ValidationResult": [[24, 2, 1, "", "add_error"], [24, 2, 1, "", "add_sub_result"], [24, 3, 1, "", "errors"], [24, 2, 1, "", "has_error"], [24, 3, 1, "", "sub_results"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "exception", "Python exception"], "6": ["py", "function", "Python function"], "7": ["py", "data", "Python data"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:exception", "6": "py:function", "7": "py:data"}, "terms": {"": [1, 2, 3, 4, 6, 8, 9, 10, 13, 16, 20, 22, 29, 31, 36, 38, 39], "0": [4, 17, 18, 22, 23, 24, 29, 30, 31, 32, 36, 39], "03762": 12, "05": 35, "064": 30, "06450": 12, "07467": 12, "09864": 12, "1": [4, 20, 22, 23, 24, 29, 30, 31, 32, 33, 35, 37], "10": 22, "100": 31, "10000": [29, 36], "1000000": 30, "10h": 20, "11477": 12, "11_008": 8, "12": [5, 6, 7, 13], "128": 8, "13971": 12, "14": [6, 7, 31, 39], "14b": 30, "15": [22, 39], "151_936": 8, "152": 30, "152064": 30, "16": [22, 33, 39], "1607": 12, "16384": [29, 30], "1706": 12, "18": 7, "18944": 30, "1910": 12, "1_000_000": [8, 30], "1d": 31, "1e": 35, "1t": 11, "2": [4, 5, 20, 22, 29, 30, 31, 32, 35, 36, 39], "20": [1, 22], "2006": 12, "2016": 12, "2019": 12, "2020": 12, "2023": 12, "2024": [7, 8], "2048": [8, 29, 30, 36], "21": 7, "2104": 12, "22": 7, "2302": 12, "24": [9, 30], "25": 31, "250": 31, "256": 29, "28": 30, "2d": 4, "2x4": 4, "3": [0, 4, 7, 11, 20, 22, 29, 30, 31, 32, 35, 36, 39], "32": [29, 30], "32000": [29, 32], "32768": [27, 30], "32_768": 8, "32b": 30, "3584": 30, "36": 8, "37": 31, "3b": [8, 30], "4": [4, 22, 29, 30, 31, 32, 36, 39], "400": 31, "4096": [0, 29, 30], "4b": 30, "5": [8, 10, 22, 29, 30, 31, 32, 35, 36, 39], "50": 31, "512": [31, 32, 36, 39], "5b": [27, 30], "6": [5, 7, 12, 31, 32, 35, 36], "65": 39, "6666666666666666": 29, "6899": 9, "6b": [8, 17, 18, 28, 30], "7": [5, 22], "70": 6, "75": 31, "768": 30, "7b": [0, 30], "8": [4, 6, 9, 22, 31], "80": [6, 9], "8084": 13, "8192": 0, "8b": [0, 11, 29, 30], "9": [7, 23, 31], "95": 8, "99": 23, "A": [0, 1, 4, 8, 11, 22, 23, 24, 33, 36], "And": 6, "As": [1, 6], "At": [4, 22], "By": [6, 13], "For": [0, 1, 3, 4, 5, 6, 8, 9, 13, 20, 22, 23, 24, 29, 31, 35], "If": [0, 4, 6, 8, 13, 18, 22, 23, 24, 29, 30, 32, 33, 35, 36, 37], "In": [0, 4, 6, 8, 9, 13, 22], "It": [4, 11, 16, 17, 19, 20, 29, 30, 31, 33, 34], "NOT": 24, "No": [0, 7, 11, 22, 29], "Not": 0, "ON": [6, 13], "On": 9, "One": [1, 2], "Or": [3, 18, 30], "That": 1, "The": [1, 2, 3, 4, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "Then": [1, 3, 6, 29], "There": 8, "These": [0, 2, 7, 24], "To": [0, 5, 6, 13, 24, 35], "Will": 29, "With": 7, "_": [0, 6, 31], "__init__": [1, 2, 3, 31], "__main__": 3, "__name__": 3, "__source__": 0, "__str__": 30, "__version__": 7, "_base": 0, "_chat": 0, "_devic": 22, "_eos_token": 29, "_file": 1, "_instruct": 0, "_legacy_pad_idx": 36, "_model": [1, 29], "_pg": 22, "_tok": 29, "a100": 6, "ab": [8, 12], "abbrevi": 2, "abc": [2, 18, 23, 24, 32, 33, 35, 36, 37, 38], "abdelrahman": 12, "abi": [5, 13], "abil": 11, "abl": 13, "about": [0, 1, 4, 6, 33], "abov": [5, 6, 7, 13], "absolut": 20, "abstract": [0, 2, 4, 16, 18, 21, 22, 24, 32, 33, 35, 36, 37, 38], "accept": [13, 35], "access": [2, 4, 8, 9, 17, 19, 20, 27, 29, 30], "accessor": [17, 19, 27], "accident": 7, "accompani": 13, "accord": 33, "accordingli": 22, "achiev": 6, "across": [0, 1, 11, 22, 27, 32], "act": 2, "activ": [6, 7, 11], "actual": [4, 6, 8, 22], "ad": [11, 13, 20, 27, 29, 30, 38], "adamw": 40, "adamwconfig": 23, "adamwgroupconfig": 23, "adapt": 18, "add": [0, 3, 7, 10, 13, 20, 24, 27, 29, 30, 35], "add_error": 24, "add_generation_prompt": 29, "add_sub_result": 24, "addit": [0, 4, 5, 7, 9, 13, 23, 30, 35, 37], "additiveresidualconnect": 38, "address": [4, 13], "adjac": 22, "adjust": 9, "advanc": [1, 6, 8, 18, 28], "advanced_open": 20, "advantag": [4, 11], "affin": 35, "after": [7, 8, 13, 20, 33], "aggreg": 26, "agnost": 17, "agre": 13, "ahm": 12, "ai": [17, 18, 29, 30], "aidan": 12, "aim": 29, "al": [29, 35, 36], "alexei": 12, "algorithm": [2, 18, 36], "all": [0, 2, 3, 4, 8, 9, 11, 12, 13, 17, 18, 19, 20, 22, 24, 27, 30, 31, 37], "all_gath": 22, "all_gather_to_list": 22, "all_reduc": [4, 22], "all_sum": 22, "alloc": [9, 22, 31], "allow": [0, 1, 2, 3, 4, 7, 10, 36], "allow_uneven": 1, "along": [2, 6, 22, 24], "alreadi": [6, 13, 22], "also": [5, 6, 13, 20, 28, 39], "altern": [4, 11, 13], "alwai": [7, 39], "amper": 6, "an": [0, 2, 4, 5, 6, 8, 9, 13, 18, 20, 22, 23, 24, 30, 32, 33, 35, 36, 37], "analysi": 11, "and_return": 1, "ani": [0, 1, 2, 3, 4, 6, 13, 20, 24, 27, 32, 33, 36, 39], "ann": 12, "annot": 2, "anoth": 37, "api": [0, 1, 2, 4, 5, 11, 13, 22, 27, 29, 30, 31, 36], "appear": [8, 9], "appli": [8, 29, 30, 31, 35, 37, 38, 39], "applic": 25, "apply_chat_templ": 29, "apply_mask": [31, 39], "approach": [1, 2, 4], "appropri": [8, 9, 27], "approx": 30, "apt": [5, 6], "ar": [0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 18, 20, 22, 24, 29, 30, 31, 35, 37], "arbitrari": 22, "arch": [3, 6, 8, 27, 30], "architectur": [0, 1, 2, 3, 4, 27, 28, 29, 34], "arg": [2, 22, 24, 35, 38], "argument": [1, 4, 9, 18, 23, 30, 36], "armand": 12, "around": [2, 3], "arrow": [5, 13], "art": 11, "arxiv": [8, 12], "as_": [1, 27, 28], "as_auto_regress": 1, "as_i": 29, "as_input": 1, "as_process_group": 22, "ashish": 12, "ask": 6, "aspect": 1, "assert": 29, "asset": [1, 2, 3, 7, 10, 11, 17, 18, 19, 24, 27, 28, 29, 30], "asset_nam": 0, "asset_stor": [0, 2, 17, 19, 27, 28], "assetcard": [17, 19, 27], "assetnotfounderror": 0, "assetstor": [2, 17, 19, 27], "assign": 23, "assist": 29, "associ": [4, 18, 30], "astral": 7, "async": 11, "asynchron": 11, "atmeta": [5, 7, 13], "attempt": [17, 19], "attent": [2, 8, 11, 12, 29, 30, 31], "attentionlay": 31, "attn_mask": 31, "attribut": 22, "audiocol": 16, "audiodataset": 16, "auli": 12, "aurelien": 12, "authent": 8, "auto": 2, "auto_activate_bas": 7, "autocomplet": 1, "automat": [1, 2, 27, 31], "avail": [0, 4, 6, 8, 11, 13, 17, 19, 22, 27, 29], "average_loss": 22, "avoid": 6, "awar": 11, "azhar": 12, "b": [6, 13], "ba": [12, 35], "back": [4, 7], "backend": [4, 22], "background": 1, "backward": 27, "baevski": 12, "bag": 33, "baptist": 12, "barrier": 22, "base": [1, 2, 4, 6, 7, 9, 11, 13, 16, 17, 19, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], "base_model": 0, "base_model_instruct": 0, "baselin": 11, "basic": [0, 1, 7, 8, 9, 20, 23], "batch": [1, 16, 22, 32, 33, 34, 36, 38, 39], "batch_first": 31, "batch_layout": [31, 32, 36, 39], "batch_siz": 31, "batch_tensor": [31, 39], "batchlayout": [1, 11, 16, 30, 32, 36, 39], "beam": 33, "becaus": [4, 13], "becom": [6, 7, 13], "been": 11, "befor": [0, 6, 9, 22, 24, 38], "begin": [4, 18, 29, 31], "begin_of_text": 29, "beginn": [1, 11], "behavior": 4, "behind": 18, "being": [10, 13, 14, 15, 21, 25, 26, 40, 41], "belong": [22, 23], "below": [0, 2, 7, 13, 22, 36], "benefici": 4, "benefit": [0, 4], "beta": 23, "better": [11, 31], "between": [0, 2, 5, 7, 13, 18, 30, 33], "beyond": 8, "bia": [8, 30, 35, 37], "biao": 12, "bibliographi": 10, "bibtex": 7, "bin": [6, 7], "binari": 13, "black": 13, "block": [22, 34], "bo": [12, 18, 29], "boh": 18, "boh_idx": 18, "boilerpl": 1, "bool": [2, 17, 18, 22, 24, 27, 29, 30, 31, 35, 37], "boolean": [22, 39], "bos_idx": 18, "both": [0, 1, 4, 7, 9, 11, 16, 20, 22, 31, 32, 35, 36, 37, 38], "boundari": [22, 31], "branch": 13, "brew": [5, 6], "broadcast": [4, 22, 39], "broadcast_flag": 22, "broadcast_object": 22, "broader": 11, "browser": 13, "budget": 11, "buffer": 30, "bug": 13, "build": [5, 7, 10, 13, 20, 34], "build_typ": 6, "builder": 1, "built": [0, 1, 2, 3, 4, 6, 13, 20], "byte": 33, "bytes_or_buff": 30, "c": [5, 6, 7, 8, 11, 13, 16], "cach": [0, 7, 11, 14, 17, 18, 33], "calcul": 4, "call": [4, 20, 22, 24, 33], "callabl": [32, 35, 36, 37], "caller": [2, 22], "can": [0, 1, 2, 3, 4, 6, 7, 9, 13, 17, 18, 19, 20, 22, 23, 24, 27, 28, 36], "capabl": [3, 8, 11], "capac": 33, "capacity_byt": 33, "capacity_incr": 33, "capit": 30, "card": [2, 11, 17, 18, 19, 28, 29, 30], "care": 31, "carefulli": 13, "case": [6, 8, 9, 20, 33], "cast_fp32": 35, "catalog": 14, "caus": [22, 36], "cc": 13, "cd": [5, 6, 7, 13], "cento": 5, "central": [0, 2, 17, 19], "chain": 16, "chang": [4, 7, 8, 11, 13, 33], "channel": 22, "chatbot": 1, "check": [0, 1, 7, 8, 11, 22, 28], "checkabl": 24, "checkpoint": [0, 1, 2, 4, 8, 10], "checkpoint_path": [27, 30], "chicken": 29, "choic": 30, "choos": [9, 13], "chosen": 9, "chunk": [1, 2], "ci": 7, "cl": 0, "cla": 13, "clang": 13, "class": [4, 16, 20, 23, 24, 29, 30, 31, 32, 33, 35, 36, 37, 38], "classmethod": [0, 22], "classvar": 31, "clean": [2, 4, 7], "clear": [0, 1, 2, 7, 13, 24], "clearer": 11, "cli": 1, "clip": 40, "clone": [5, 13], "closabl": 22, "close": 22, "cluster": [0, 6, 9, 20], "clusterscop": 7, "cmake": [6, 13], "cmake_cuda_architectur": 6, "cmakelist": 6, "code": [0, 1, 2, 3, 4, 6, 7, 8, 11, 13, 14, 15, 21, 25, 26, 27, 29, 30, 40, 41], "codebas": 3, "coeffici": [29, 30, 36], "cohes": 4, "collat": 16, "collect": [0, 2, 4, 22, 23], "column": 4, "com": [0, 5, 6, 7, 8, 9, 13], "combin": [4, 5, 22], "come": [0, 14, 15, 16, 21, 25, 26, 40, 41], "command": [0, 1, 5, 6, 7, 8, 9, 13, 18, 28], "comment": 0, "commit": [0, 5, 13], "common": [1, 20, 41], "commonsect": 1, "commun": [4, 11, 22], "companion": 20, "compar": 30, "comparison": [4, 31], "compat": [5, 7, 8, 13, 27, 31], "compil": [1, 6, 11], "compiled_max_seq_len": 31, "complet": [1, 3, 6, 7, 13], "complex": [1, 2, 4, 13, 17, 20, 22], "compon": [0, 1, 3, 8, 23], "compos": 2, "composit": [0, 1, 2, 3, 20, 24], "comprehens": [16, 31], "comput": [1, 4, 6, 9, 21, 22, 26, 31], "compute_loss": 22, "compute_row_mask": 39, "concaten": 22, "concept": 2, "concern": 7, "concret": [2, 17, 18, 19, 30], "conda": [6, 7], "condit": 11, "config": [0, 1, 3, 6, 7, 8, 9, 17, 18, 19, 20, 23, 24, 27, 29, 30], "config_kl": [1, 3, 17, 19, 23, 27], "config_registri": 3, "config_yaml": 9, "configregistrar": 3, "configur": [2, 6, 9, 11, 17, 18, 19, 20, 23, 24, 25, 27, 28, 40, 41], "conflict": [6, 7], "connect": [8, 9, 34], "consequ": 4, "consid": 36, "consist": [0, 1, 8, 11, 13, 22, 31], "consolid": [4, 11, 31], "constant": 38, "construct": [2, 18, 22, 30, 32], "constructor": 2, "consult": 6, "consum": 16, "contain": [1, 2, 3, 4, 13, 20, 22, 23, 24, 29], "content": [10, 27, 29], "context": [0, 1], "contigu": 22, "continu": 11, "continue_process": 22, "contract": [2, 18], "contrast": 4, "contribut": [6, 10, 22, 32], "control": [0, 1, 11, 18, 30], "conveni": [0, 6, 8], "convent": [8, 13], "convers": 22, "convert": [1, 11, 23, 24, 30, 32], "coordin": 4, "copi": [2, 22, 36], "core": [1, 3, 16, 34], "cornerston": 31, "correct": 23, "correctli": [4, 8, 24], "correspond": [4, 20, 23, 29, 30, 32, 33], "could": 20, "coupl": 2, "cover": [8, 13], "coverag": 11, "cpu": [4, 5, 7, 9, 13, 21, 22, 31, 39], "crash": [5, 13], "creat": [3, 6, 7, 13, 17, 18, 19, 22, 27, 29, 30, 32, 34, 39], "create_decod": [17, 18, 30], "create_decoder_frontend": 30, "create_decoder_lay": 30, "create_default_process_group": [4, 22], "create_embed": 30, "create_encod": [17, 18, 29, 30], "create_fake_gang": 22, "create_ffn": 30, "create_final_project": 30, "create_fsdp_gang": [4, 22], "create_gang": 22, "create_layer_norm": 30, "create_model": 30, "create_my_custom_model": [1, 3], "create_my_optim": 23, "create_new_model": [8, 27, 30], "create_parallel_gang": [4, 22], "create_position_encod": 30, "create_raw_encod": [18, 30], "create_read": [1, 20], "create_self_attent": 30, "create_train": 1, "creation": [0, 20], "critic": [2, 16], "cross": [21, 29], "csv": 16, "csvdataset": 16, "cu124": [5, 7], "cu126": 5, "cu128": [5, 6, 7, 13], "cuda": [4, 7, 13, 22, 31], "cuda_arch": 6, "cuda_vers": 6, "curl": 7, "current": [0, 22, 33], "custom": [1, 3, 7, 8, 10, 11, 17, 18, 19, 29, 35, 41], "custom_dataset": [1, 3, 19, 20], "custom_load": [1, 3], "custom_model": 8, "custom_open": [1, 3, 20], "custom_path": [17, 18], "custom_qwen": 0, "custom_token": [1, 3, 17, 18], "customdataset": [1, 3, 20], "customdatasetconfig": [1, 3, 20], "customiz": 1, "customtoken": [1, 3], "customtokenizerconfig": [1, 3], "cut": 11, "cxx": 13, "d0": [4, 22], "d1": [4, 22], "d2": [4, 22], "d3": [4, 22], "d4": [4, 22], "d5": [4, 22], "d6": [4, 22], "d7": [4, 22], "data": [0, 1, 7, 10, 19, 20, 22, 27, 29, 30, 34, 35, 37], "data_read": 1, "dataclass": [0, 1, 20, 23, 24], "dataload": 16, "datapipelin": [1, 16], "datapipelineread": 1, "dataread": [1, 20], "dataset": [3, 4, 10, 11, 16, 17, 27], "dataset_config": [0, 20], "dataset_famili": [0, 20], "datasetconfigt": 19, "datasetfamili": 19, "datasetsect": 1, "datasett": 19, "date": 13, "dclm": 11, "dcmake_build_typ": 6, "dcmake_cuda_architectur": 6, "dcp": 11, "ddp": 22, "de": [18, 30], "deadlock": 9, "debian": 5, "debug": [1, 4, 10, 22, 25], "decai": [29, 30, 36], "decid": 9, "decis": 22, "declar": 4, "decod": [17, 18, 29, 30, 33, 36], "decode_from_token": 18, "decor": [2, 8], "def": [0, 1, 2, 3, 4, 8, 20, 23, 24, 31], "default": [0, 1, 2, 3, 4, 6, 7, 13, 22, 23, 27, 29, 30], "default_dataset": 1, "default_encod": 29, "default_factori": [0, 1, 23], "defin": [0, 2, 7, 8, 18, 20, 22, 30, 36], "definit": [0, 20], "demand": 2, "demonstr": [0, 2], "denomin": 35, "denot": [4, 22], "dens": 11, "dep": 6, "depend": [0, 1, 3, 4, 5, 7, 8, 11, 13, 20, 23], "dependencycollectioncontain": 2, "dependencycollectionresolv": 2, "dependencycontain": [0, 1, 2, 3, 20, 23], "dependencyprovid": 2, "dependencyresolv": [2, 20, 23], "deploi": 0, "deploy": 0, "depth": 29, "deriv": 24, "describ": [0, 6, 8, 13, 18, 20, 29, 35, 36], "descript": [0, 13], "design": [0, 1, 3, 4, 7, 8, 9, 10, 11, 16, 31], "desir": [5, 6], "destroi": 22, "detail": [0, 1, 3, 17], "detect": [0, 21], "determin": [4, 23, 27], "determinist": [2, 11], "dev": [6, 7], "devel": [5, 6, 13], "develop": [0, 5, 6, 7, 8, 10, 11, 14, 15, 21, 25, 26, 40, 41], "deviat": 29, "devic": [2, 4, 6, 10, 13, 18, 22, 27, 28, 30, 31, 32, 35, 36, 37, 39], "device_mesh": 4, "dfairseq2n_perform_lto": 6, "dfairseq2n_python_devel": 6, "dfairseq2n_run_clang_tidi": 13, "dfairseq2n_sanit": 6, "dfairseq2n_treat_warnings_as_error": 6, "dfairseq2n_use_cuda": 6, "di": 2, "diagram": [2, 36], "dict": [1, 23, 30], "dictionari": [30, 32], "did": 29, "differ": [0, 2, 6, 8, 18, 20, 22, 29, 30, 31], "dim": [30, 31], "dimens": [4, 8, 22, 29, 30, 32, 35, 36, 37, 39], "dimension": [4, 8, 29, 30, 32, 36, 37, 38], "dir": [0, 1, 6, 17, 18, 20], "direct": [0, 4, 8], "directli": [11, 17, 18], "directori": [0, 1, 6, 13, 28, 29], "disabl": 7, "discov": [17, 19, 27], "discover": 11, "discoveri": 0, "disk": 11, "dist": 4, "distinct": 4, "distinguish": [18, 30], "distribut": [1, 4, 6, 11, 22, 30], "divers": 2, "dnf": [5, 6], "do": [1, 13, 32], "doc": [7, 9, 13], "docstr": 13, "document": [0, 6, 7, 11, 14, 15, 16, 17, 19, 21, 25, 26, 27, 40, 41], "doe": [4, 5, 22, 23, 33], "don": 20, "done": 18, "download": [0, 6, 7, 11, 14, 17, 18], "dp": [4, 22], "dp_mesh": 4, "driven": 11, "dropout": [0, 8, 29, 30], "dropout_p": [0, 8, 29, 30], "dtensor": 4, "dtype": [22, 27, 32, 35, 36, 37], "due": [6, 22, 27, 39], "dummi": 0, "dump": 1, "duplic": [2, 22], "dure": [4, 11, 15, 22, 31, 32, 33], "dynam": [0, 11, 31], "e": [0, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 20, 22, 23, 24, 27, 29, 30, 32, 35, 36], "each": [1, 2, 4, 7, 8, 22, 23, 24, 27, 31, 39], "earlier": 1, "eas": 11, "easi": [0, 1, 4, 8, 13], "easier": [11, 31], "easili": 7, "echo": [0, 9], "ecosystem": 11, "edit": [5, 7, 13], "edouard": 12, "effect": [6, 39], "effici": [1, 11, 12, 16, 22, 31, 34], "either": [4, 20], "element": [18, 31, 36, 39], "elementwise_affin": 35, "elimin": [1, 4], "els": [1, 4, 31], "emb": [30, 32], "embed": [8, 12, 29, 30, 34, 36], "embed_dim": 32, "empti": [6, 22, 24], "en": [18, 30], "enabl": [2, 11, 22], "encapsul": 4, "encod": [2, 17, 18, 29, 30, 34], "encode_as_token": 18, "encoder_decoder_attn": 2, "encoder_decoder_attn_layer_norm": 2, "encoding_dim": 36, "end": [0, 4, 6, 18, 22, 29], "end_header_id": 29, "end_of_text": 29, "enforc": 13, "enhanc": [9, 11, 12], "ensur": [2, 7, 8, 9, 13, 22, 24], "entir": [4, 8, 11, 13], "entri": [0, 3, 8, 32], "entry_point": 0, "env": [4, 9], "environ": [3, 4, 7, 9, 22], "eo": [18, 29], "eoh": 18, "eoh_idx": 18, "eos_idx": 18, "eos_token": 30, "eot_id": 29, "ep": 35, "equal": 22, "eric": 12, "error": [1, 7, 22, 24, 30], "especi": 11, "essenti": [0, 2, 23], "et": [29, 35, 36], "etc": [0, 2, 4, 7, 8, 9, 20], "eval": 30, "evalrecip": 20, "evalu": [0, 11, 16, 26], "even": 36, "everi": [22, 33], "everyth": [1, 4], "ex": 24, "exactli": [5, 13], "exampl": [0, 1, 2, 6, 7, 9, 11, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 31, 32, 35, 36, 39, 40, 41], "exce": 36, "except": [0, 8, 24], "exclud": 24, "exclus": 7, "execut": [1, 22], "exist": [0, 6, 7, 11, 31], "expand": [11, 31], "expandus": 1, "expect": [2, 9, 13, 33, 36], "expens": 2, "experi": [5, 9, 13], "experiment": [4, 7, 22], "explain": [7, 9], "explan": 9, "explicit": [4, 7], "explicitli": 4, "explor": [2, 9], "export": [3, 30], "expos": [8, 11, 24, 27, 30], "extend": 3, "extens": [0, 2, 10, 11, 20], "extensionerror": 3, "extra": [0, 3, 5, 6, 7, 13, 35], "extra_path": [0, 1, 20], "extra_repr": 35, "extract": 16, "f": [0, 1, 2, 4, 7, 8, 17, 18, 19, 22, 24, 27, 28, 30, 31], "face": [0, 13, 30], "facebook": [0, 13], "facebookresearch": [5, 6, 7, 13], "factor": [29, 38], "factori": [1, 3, 17, 19, 23, 29], "fail": [3, 6, 8, 22], "failur": [13, 22], "fair": [5, 6, 7, 13], "fairseq2": [0, 1, 2, 3, 5, 7, 8, 11, 31, 32, 33, 35, 36, 37, 38], "fairseq2_asset_dir": [0, 20], "fairseq2_cache_dir": 0, "fairseq2_ext": 0, "fairseq2_extension_trac": 3, "fairseq2_user_asset_dir": [0, 20], "fairseq2n": [7, 13], "fairseq2n_use_cuda": 6, "faisal": 12, "fake": [4, 22], "fakegang": [4, 22], "fallback": 0, "fals": [2, 7, 8, 18, 22, 27, 29, 30, 31, 35], "famili": [0, 1, 3, 17, 18, 19, 20, 30], "familiar": [6, 8, 9], "family_nam": [17, 19, 27], "fast": 7, "fault": 4, "favicon": 7, "featur": [2, 7, 9, 11, 13, 16, 31, 36], "fedora": [5, 6], "feed": [2, 8, 29, 30], "feedforwardnetwork": [2, 30], "few": 1, "ffn": 2, "ffn_inner_dim": [8, 29, 30], "ffn_inner_dim_multiple_of": 29, "ffn_inner_dim_multipli": 29, "ffn_inner_dim_scal": 29, "ffn_layer_norm": 2, "field": [1, 23, 24, 27, 28], "field1": 24, "field2": 24, "file": [1, 3, 9, 11, 13, 16, 20, 29], "file_rank": 1, "file_world_s": 1, "filesystem": 0, "fill_valu": [31, 39], "final": [0, 1, 2, 6, 17, 19, 22, 24, 27, 30, 31, 32, 33, 35, 36, 37, 38], "find": [0, 8, 24], "fine": [0, 11], "first": [1, 2, 3, 4, 6, 8, 11, 20, 22, 23, 36], "fix": [32, 36], "flag": 22, "flake8": 13, "flash3": 11, "flexibl": [0, 1, 3, 11, 16, 20], "float": [22, 23, 29, 30, 35, 36, 38, 39], "float32": 22, "focu": 1, "focus": [1, 8, 11], "follow": [0, 2, 5, 6, 9, 11, 13, 20, 24], "foo": [0, 24], "foo1": 0, "foo2": 0, "fooconfig": 24, "forg": 6, "fork": [2, 13], "form": [0, 6, 13], "format": [0, 1, 7, 8, 11, 16, 20, 24, 25, 29, 30], "formatt": 6, "formatted_text": 29, "formula": 30, "forward": [2, 8, 29, 30, 31, 32, 35, 36, 37, 38], "found": [0, 1, 6, 17, 18, 19, 27], "foundat": [7, 11, 12], "four": 1, "frac": [32, 37], "framework": [1, 2, 4, 11, 12], "franc": 30, "free": [0, 7], "freqs_init_fn": 36, "frequenc": [29, 36], "frequent": 33, "fresh": 7, "from": [0, 1, 2, 3, 5, 7, 8, 9, 11, 13, 15, 17, 18, 19, 20, 22, 23, 24, 27, 28, 29, 31, 32, 36, 37, 39], "from_embed": 32, "from_path": 0, "fs2_build_wheel": 6, "fs2_state_dict": 30, "fsdp": 22, "full": [1, 11, 13, 27, 31], "fulli": [4, 11, 22, 31], "function": [1, 3, 4, 8, 9, 18, 19, 20, 31], "furo": 7, "further": [4, 11], "futur": [11, 17, 18, 29, 30], "g": [0, 2, 4, 5, 6, 8, 9, 11, 13, 20, 22, 29, 30], "gang": [1, 10, 27, 32], "gangerror": 22, "gangsect": 1, "gather": 22, "gautier": 12, "gener": [0, 4, 6, 10, 11, 17, 18, 19, 27, 29, 30, 39], "generationrecip": 20, "generic_instruct": 0, "geoffrei": 12, "germani": 30, "get": [1, 4, 8, 9, 11, 13, 18, 19, 20, 27, 29, 30, 31, 33], "get_arch": [8, 27, 30], "get_arch_config": [8, 27, 30], "get_asset_stor": [0, 28], "get_dataset_config": 19, "get_default_devic": [4, 28, 30, 31], "get_dependency_resolv": 2, "get_llama_model_hub": 27, "get_mistral_model_hub": 27, "get_model_config": 27, "get_my_dataset_hub": 19, "get_qwen_model_hub": [8, 27], "get_qwen_tokenizer_hub": [17, 18], "get_rank": [4, 9], "get_start_lr": 23, "get_std_scale_factor": 30, "get_tokenizer_config": [17, 18], "get_world_s": 4, "getdefaultencod": 30, "git": [5, 6, 7, 13], "github": [5, 6, 7, 9, 13], "give": 11, "given": [8, 22, 30], "glob": 1, "global": [2, 4, 17], "gloo": [4, 22], "gninja": [6, 13], "go": 1, "goal": 2, "gomez": 12, "goyal": 12, "gpu": [1, 4, 6, 7, 9, 13, 21, 22, 31], "gqa": [8, 30], "grace": 1, "gradient": [32, 40], "gradual": 4, "grain": 11, "graph": [2, 24], "grave": 12, "greater": [11, 39], "greatli": 4, "grep": 8, "group": [0, 1, 4, 7, 8, 11, 22, 23, 29, 30], "group_config": 23, "guarante": 39, "guid": [4, 7], "guidanc": 11, "guidelin": 13, "guillaum": 12, "h": 35, "h_": 37, "ha": [2, 5, 6, 11, 13, 18, 22, 24, 27, 33], "hambro": 12, "handl": [1, 2, 8, 11, 17, 18, 22, 29, 30, 31, 36], "handler": 30, "hang": 9, "hardwar": 7, "has_error": 24, "hash": [5, 13], "hashabl": 2, "have": [0, 2, 4, 5, 6, 8, 9, 11, 13, 20, 22, 24, 36], "haven": 13, "head": [8, 29, 30, 31], "head_dim": [8, 30], "header": [18, 29], "hello": 29, "help": [11, 18, 29], "helper": [1, 4, 18, 22, 23, 24], "henri": 12, "here": [1, 3, 8, 9, 13, 18, 20, 22], "hf": [11, 17, 18], "hf_state_dict": 30, "hg": [0, 8, 11, 29], "hide": 31, "high": [4, 11, 16, 17, 22], "high_prior": 22, "hinton": 12, "hold": [22, 24, 29, 33, 36], "home": 0, "homebrew": 6, "host": [6, 9, 22], "hostnam": 9, "hour": 13, "how": [0, 1, 2, 3, 6, 7, 8, 9, 13, 18, 22], "howev": 6, "hsdp": 22, "html": 13, "http": [0, 5, 6, 7, 9, 12, 13], "hub": [0, 7, 11, 14, 18, 20, 28], "hug": [0, 30], "huggingfac": [17, 18], "huggingfaceexport": 30, "huggingfacetokenmodel": 30, "hugo": 12, "hybrid": [4, 22], "hyperparamet": 41, "i": [1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41], "icanon": 9, "id": 1, "idea": 2, "ideal": 13, "ident": 37, "identifi": [0, 1, 30], "ignor": 35, "illia": 12, "illustr": 2, "immedi": [5, 13], "impl": 29, "implement": [4, 11, 13, 16, 17, 18, 19, 20, 22, 24, 30, 35, 36, 39], "implementor": [17, 19, 27], "implicit": 4, "import": [0, 1, 2, 3, 4, 7, 8, 9, 17, 18, 19, 20, 22, 23, 24, 27, 28, 29, 30, 31, 32, 36, 39], "improv": [1, 2, 11], "includ": [0, 2, 3, 4, 9, 11, 13, 14, 15, 16, 21, 22, 25, 26, 28, 29, 30, 34, 36, 39, 40, 41], "incom": [35, 37], "incompat": 7, "increas": 29, "increment": [34, 36], "increment_step_nr": 33, "incrementalst": 33, "incrementalstatebag": [33, 36], "independ": 20, "index": [5, 6, 7, 10, 13, 18, 24, 29, 31], "index_select": 33, "indic": [0, 18, 22, 24, 30, 32], "individu": [1, 4, 11, 22, 23, 31], "induc": 9, "infer": [4, 16, 29, 30, 33], "inference_mod": 30, "inform": [0, 1, 3, 4, 6, 8, 18, 22, 30, 33, 35, 36], "init": [6, 7], "init_device_mesh": 4, "init_fairseq2": [0, 2, 3], "init_fn": [32, 35, 37], "init_scaled_embed": 32, "init_std": 29, "init_std_scal": 29, "initi": [1, 2, 4, 7, 8, 22, 23, 27, 29, 32, 35, 36, 37, 38], "inject": [1, 3, 11, 20], "inner": [8, 29, 30], "inp": 37, "input": [1, 4, 8, 22, 29, 30, 32, 33, 35, 36, 37, 38, 39], "input_batch": 1, "input_dim": 37, "input_tensor": 22, "insert": 9, "inspect": [2, 8, 11], "instal": [7, 8, 9, 10, 13], "instanc": [1, 2, 3, 4, 6, 17, 19, 20, 22, 23, 27, 30, 32, 37], "instanti": [4, 30], "instead": [2, 6, 11, 22, 29, 36], "instruct": [0, 5, 6, 8, 9, 13, 29], "int": [18, 22, 23, 24, 29, 30, 31, 32, 33, 35, 36, 37, 39], "integ": [8, 22, 24], "integr": [2, 13, 16, 20], "intent": 24, "inter": [4, 22], "interact": [0, 20], "interchang": 2, "interest": 13, "interfac": [1, 4, 8, 9, 18, 27, 28, 31], "intern": [11, 17, 32, 35, 36, 37, 38], "internet": 8, "intra": [4, 22], "intra_node_s": [4, 22], "introduc": [1, 2], "intuit": 11, "invalid": 3, "invalid_arch": 27, "invalidoperationerror": 22, "invok": 9, "is_avail": 7, "is_dir": 1, "isinst": 23, "isol": 6, "isort": 13, "issu": [0, 5, 6, 7], "item": 22, "iter": [2, 17, 19, 23], "iter_card": [17, 18, 19, 27, 30], "iter_checkpoint": 27, "iter_kei": 2, "its": [2, 3, 6, 18, 22, 23, 24, 27, 32], "izacard": 12, "jakob": 12, "jami": 12, "jepa_vith16": 0, "jepa_vith16_384": 0, "jepa_vitl16": 0, "jianlin": 12, "jimmi": 12, "job": [4, 9, 11], "joke": 29, "jone": 12, "joulin": 12, "json": [16, 29], "jsondataset": 16, "jsonl": [1, 16], "jupyt": 7, "just": [1, 13], "k": 37, "k_norm": 30, "kaiser": 12, "keep": [0, 33], "kei": [0, 2, 8, 11, 16, 24, 27, 29, 30, 31], "kernel": 6, "key_padding_mask": 31, "kind": [0, 7, 8, 18, 28], "kiro": 12, "kl": [1, 2, 3, 17, 19, 27, 33], "know": 0, "kw_onli": 1, "kwarg": [2, 22, 24, 35, 38], "l": [0, 6, 9], "la": 0, "lab": 7, "lachaux": 12, "lacroix": 12, "lambda": 1, "lampl": 12, "lang": [18, 30], "languag": [1, 8, 10, 11, 12, 18, 28, 29, 30], "larg": [2, 11, 16], "larger": 13, "last": [35, 36, 37], "later": [4, 22], "latest": [7, 13], "launch": 9, "lavril": 12, "layer": [0, 2, 4, 8, 12, 29, 30, 34], "layer_idx": 30, "layernorm": [2, 30, 35], "layout": [1, 11, 34, 39], "learn": [0, 1, 3, 4, 6, 8, 9, 12, 16, 23, 30, 35, 36, 37, 40, 41], "learnedpositionencod": [2, 36], "least": 39, "legaci": 7, "lei": 12, "len": 23, "length": [0, 8, 16, 22, 23, 29, 30, 31, 33, 36, 38, 39], "let": [1, 8], "level": [16, 17, 20, 23], "leverag": 11, "librari": [2, 6, 13], "librilight": 20, "libsndfil": [5, 6], "libsndfile1": 5, "lightweight": 11, "like": [4, 5, 6, 13, 17, 18, 22, 24, 27, 39], "line": [1, 8, 18, 28, 35], "linear": 37, "link": 8, "lint": 7, "linter": 6, "linux": 6, "list": [0, 1, 7, 8, 17, 19, 22, 23, 24, 27, 30, 31], "listen": 9, "liter": 29, "liu": 12, "ll": 8, "llama": [0, 8, 11, 12, 28], "llama2": 0, "llama2_13b": 0, "llama2_13b_chat": 0, "llama3": 29, "llama3_1_8b_instruct": 2, "llama3_2_1b": [8, 29], "llama3_2_1b_instruct": [1, 29], "llama3_70b": 8, "llama3_8b": [0, 8, 27], "llama3_8b_instruct": 0, "llamaropescaleconfig": 29, "llion": 12, "llm": [0, 9], "lm": [1, 9], "lm_train_dataset": 1, "lmtrainconfig": 1, "lmtraindataset": 1, "lmtraindatasetconfig": 1, "lmtraindatasetsect": 1, "lmtrainrecip": 1, "lmtrainunit": 1, "load": [0, 1, 4, 6, 11, 14, 15, 16, 17, 19, 29], "load_custom_model": [8, 27, 30], "load_custom_token": [17, 18, 29], "load_model": [2, 7, 8, 28, 29, 30], "load_token": [18, 29, 30], "loader": [0, 1, 2, 3, 16], "local": [0, 7, 9, 17, 18, 20, 22], "local_loss": 22, "localhost": 13, "locat": [0, 8, 20], "log": [1, 3, 10], "logic": [1, 4, 8], "long": [29, 30, 33, 36], "longer": [11, 36], "look": [0, 8, 24], "lookup": 11, "loos": 2, "loss": [1, 22], "lower": 39, "lr": 23, "lr_schedul": 1, "lrschedulersect": 1, "lssf": 7, "lto": 6, "lu": 12, "lukasz": 12, "m": [0, 1, 6, 7, 8, 9, 13, 18, 28, 30, 33, 38], "machin": [0, 6, 9, 16, 28, 41], "maco": 6, "made": 13, "mai": [8, 11, 31], "main": [0, 1, 4, 8, 9, 13, 17, 18, 19, 27], "maintain": [3, 4], "major": [2, 4, 11], "make": [0, 2, 6, 8, 11, 13, 20, 22, 24, 31], "manag": [0, 1, 2, 3, 4, 6, 7, 14, 15, 17, 19, 20, 21, 41], "mani": 11, "manual": [4, 6, 24], "manylinux_2_28_": 6, "map": [0, 1, 4, 24], "mari": 12, "mark": 31, "marker": 29, "martinet": 12, "masked_batch": [31, 39], "masked_fil": 31, "match": [0, 5, 6, 7, 8, 13, 20, 23, 33], "mathcal": [32, 37], "matter": 1, "max": [22, 31], "max_len": 31, "max_length": 0, "max_mask_prob": 39, "max_num_step": 33, "max_seq_len": [0, 8, 27, 29, 30, 31, 36], "maxim": 1, "maximum": [8, 29, 30, 33, 36], "maybe_get_arch_config": 27, "maybe_get_st": 33, "maybe_raise_param_group_length_error": 23, "me": 29, "mean": [2, 5, 12, 13, 22, 29, 35], "meaning": 0, "meantim": [14, 15, 21, 25, 26, 40, 41], "mechan": 20, "mel": 16, "memori": [1, 16, 18, 22, 30, 31, 32], "mermaid": 7, "mesh": 4, "messag": [0, 24, 29], "meta": [0, 9, 27, 29], "metadata": [0, 8, 14, 15, 31], "meth": 1, "method": [1, 2, 4, 8, 17, 18, 19, 22, 24, 27, 29, 33, 35], "metric": [1, 10], "metric_bag": 1, "metricbag": [1, 11], "mfcc": 16, "michael": 12, "might": [5, 13], "mileston": 11, "min": [11, 22, 31], "min_num_span": 39, "min_seq_len": 31, "minim": [1, 2, 4], "minut": 22, "mismatch": 7, "mistral": [0, 8, 28], "mistral_7b": [8, 27], "mistral_8x7b": 8, "mix": 7, "mkdir": 7, "mlm": 39, "mmap": 27, "mock": 4, "mode": [6, 7, 11, 18, 30, 31, 33, 36], "model": [1, 2, 3, 7, 10, 12, 14, 15, 16, 17, 19, 22, 23, 34, 38], "model_arch": [0, 8, 27, 28], "model_config": 0, "model_dim": [8, 29, 30], "model_famili": [0, 8, 28], "modelarchitecturenotknownerror": 27, "modelconfigt": [27, 29, 30], "modelfamili": 27, "modelfamilynotknownerror": 27, "modelhub": [29, 30], "modelnotknownerror": [8, 27], "modelsect": 1, "modelt": [27, 29, 30], "modern": 7, "modifi": [2, 3, 6, 8, 13, 22, 27, 30], "modul": [0, 1, 2, 3, 4, 6, 10, 11, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41], "moham": 12, "monolith": 2, "more": [0, 1, 2, 3, 4, 6, 8, 9, 11, 13, 18, 20, 22, 24, 27, 30, 31, 33], "most": [1, 4, 6, 8, 13, 20], "mqa": 8, "much": 1, "multi": [0, 4, 9, 35], "multihead": 2, "multiheadattent": [2, 30, 31], "multilingu": [18, 30], "multipl": [0, 2, 4, 8, 18, 29, 33], "multipli": 29, "murtadha": 12, "must": [5, 6, 8, 13, 20, 22, 24, 27, 30, 33, 39], "mutual": 7, "my": [0, 7, 8, 27, 30], "my_advanced_open": 20, "my_asset": 0, "my_clust": 0, "my_custom_arch_vari": 3, "my_custom_dataset": 0, "my_custom_llama": 0, "my_custom_model": [0, 1, 3], "my_data_family_nam": 19, "my_dataset": [0, 19, 20], "my_dataset_famili": 19, "my_extens": 3, "my_in_mem_sourc": 0, "my_model": [0, 8], "my_model_nam": 0, "my_optim": 23, "my_packag": [0, 3], "myclust": 20, "myconfig": 19, "mycustommodel": [1, 3], "mycustommodelconfig": [1, 3], "mydataset": [0, 19, 20], "mydatasetconfig": [0, 19, 20], "mylelrconfig": 23, "myoptim": 23, "myoptimizerconfig": 23, "myoptimizergroupconfig": 23, "mypi": [7, 13], "myrecip": 0, "myst": 7, "mytrainrecip": 23, "myvenv": 6, "n": [0, 12, 32, 33, 36, 38, 39], "naman": 12, "name": [0, 1, 3, 6, 7, 8, 17, 18, 19, 20, 22, 23, 24, 27, 29, 30], "nativ": [4, 5, 6, 11, 13], "navig": 8, "nbsphinx": 7, "nc": 9, "nccl": [4, 22], "nearest": 29, "necessari": [6, 8, 11], "need": [0, 1, 4, 8, 9, 11, 12, 13, 20, 27, 31, 33], "network": [2, 8, 16, 22, 29, 30, 34, 40], "neural": [16, 34, 40], "new": [1, 2, 3, 4, 6, 7, 8, 13, 22, 23, 27, 29, 30, 33], "new_group": 4, "new_model": 8, "new_ord": 33, "newli": [8, 27], "next": 33, "nf": 11, "nightli": [5, 6, 13], "niki": 12, "ninja": 6, "nll_loss": 1, "nllb": 28, "nlp": 11, "nltk": 7, "nn": [10, 11, 16, 30, 31, 32, 33, 35, 36, 37, 38], "noam": 12, "node": [4, 9, 22], "non": [4, 22, 24], "non_existent_dataset": 19, "none": [0, 1, 2, 3, 4, 17, 18, 19, 20, 22, 23, 24, 27, 29, 30, 31, 32, 33, 35, 36, 37, 39], "nonexistent_model": 27, "noreturn": 22, "normal": [9, 12, 30, 34], "normalized_shap": 35, "nosan": 6, "note": [6, 8, 20, 23, 24, 39], "notebook": 7, "notsupportederror": 22, "novel": 2, "now": [0, 11, 22], "ntask": 9, "num_attn_head": [8, 29, 30], "num_embed": 32, "num_head": 31, "num_key_value_head": [8, 29, 30], "num_lay": [8, 29, 30], "num_param_group": 23, "num_step": 1, "num_warmup_step": 1, "number": [4, 8, 18, 23, 29, 30, 33, 36, 39], "numel": 8, "numer": [11, 35], "nvidia": [6, 7], "o": 9, "obj": [2, 24], "object": [1, 2, 3, 4, 17, 18, 20, 22, 23, 24, 27, 29, 30, 31, 33, 39], "object_nam": 20, "objectvalid": 24, "observ": 13, "obtain": 9, "occur": [22, 24], "off": [6, 31], "offer": [4, 9, 11, 17, 19], "offlin": 11, "onboard": 11, "onc": [1, 6, 9, 13], "one": [2, 4, 6, 9, 13, 22, 24, 39], "ones": 4, "onli": [0, 1, 2, 4, 7, 8, 9, 11, 13, 20, 22, 29, 31, 33], "onlin": [10, 11], "op": 22, "open": [0, 1, 3, 9, 12, 13, 19], "open_custom_dataset": [19, 20], "open_dataset": 19, "open_lm_train_dataset": 1, "open_my_dataset": 0, "oper": [4, 11, 16, 18, 21, 22, 27, 28, 30, 31, 34, 36], "operationalerror": 22, "optim": [1, 10, 16, 31], "optimizersect": 1, "option": [0, 1, 7, 13, 20, 24], "orchestr": 2, "order": [0, 2, 13, 22, 23, 33], "org": [6, 7, 8, 12], "organ": [0, 11], "other": [0, 1, 3, 4, 6, 8, 9, 14, 16, 20, 21, 22, 30, 34, 40], "otherwis": [5, 13, 29, 30], "our": [1, 9, 10, 13], "out": [6, 13, 22, 37], "output": [0, 1, 8, 22, 29, 30, 31, 33, 35, 37, 38], "output_dim": 37, "output_dir": 9, "output_tensor": 22, "outsid": 24, "over": [4, 11, 13, 22, 32, 35], "overal": 11, "overhaul": 11, "overhead": 11, "overlap": 39, "overrid": [1, 6, 20, 23], "overridden": [0, 20, 37], "overview": 27, "own": [1, 10, 18, 27, 29, 30, 35], "p": [8, 9, 13], "pack": [1, 11, 31], "packag": [0, 3, 6, 7, 13], "packed_layout": 31, "packed_memori": 31, "pad": [11, 18, 29, 31, 39], "pad_idx": [18, 29, 32], "padded_layout": 31, "padded_memori": 31, "padding_mask": [31, 39], "page": 10, "pan": 12, "pane": 9, "paper": [8, 36], "parallel": [1, 22, 29], "param": [23, 30], "param_group": 23, "paramet": [1, 3, 4, 9, 18, 20, 23, 24, 27, 29, 30, 32, 33, 35, 36, 37, 38, 39], "parametergroupconfig": 23, "parent": 0, "pariti": 11, "parmar": 12, "parquet": 16, "parquetdataset": 16, "pars": 1, "parser": 7, "part": [20, 22], "parti": [6, 11], "particularli": 4, "partition": 11, "pass": [3, 6, 13, 22, 23, 31, 36], "past": 2, "path": [17, 18, 20, 27, 29, 30], "pathlib": [0, 8, 18, 27, 29, 30], "pattern": [0, 1, 4, 29], "pdb": 9, "pedant": 13, "pep517": 6, "per": [0, 9, 22, 29], "perform": [1, 4, 16, 22, 25], "persist": 13, "person": 0, "pg": 4, "phase": 2, "philosophi": [1, 3, 4, 8, 9, 10], "pickl": 22, "picklabl": 22, "pin": [1, 7, 18, 30], "pin_memori": [18, 30], "pip": [5, 7, 9, 13], "pipelin": [1, 4, 11, 22, 34, 41], "pkg": [5, 7, 13], "place": [13, 22], "plan": [6, 13], "plat": 6, "pleas": [0, 6, 9, 13, 14, 15, 21, 25, 26, 28, 40, 41], "pluggabl": [1, 2], "point": [3, 4, 8, 22], "polosukhin": 12, "port": 9, "portion": [6, 13], "pos_encod": [30, 36], "pos_indic": 31, "posit": [2, 8, 12, 24, 29, 30, 33, 34], "position_indic": [31, 39], "positionencod": [2, 30, 36], "possibl": [2, 13], "post": 11, "post1": 7, "potenti": 20, "power": [1, 2], "pp": [4, 22], "pre": [5, 6, 13, 14, 22, 28, 30, 34, 41], "prealloc": 33, "prefetch": 1, "prefix": 18, "prefix_indic": 18, "prepar": [22, 23, 29, 30], "prepare_parameter_group": 23, "preprocess": [1, 16], "prereleas": 7, "prerequisit": [8, 9], "present": 33, "preset": 8, "press": 9, "pretrain": [0, 1, 11], "pretrained_llm": [17, 18], "pretti": 13, "prevent": [7, 9, 11], "preview": 1, "previou": 33, "primarli": 24, "primit": [4, 22], "principl": [1, 2], "print": [0, 2, 4, 7, 8, 17, 18, 19, 22, 24, 27, 28, 30, 31, 35], "priorit": 13, "prioriti": 22, "probabl": [8, 29, 30, 39], "problem": 13, "proceed": 22, "process": [1, 4, 5, 7, 8, 9, 13, 22, 30, 34], "process_batch": [1, 31], "processgroup": 22, "processgroupgang": [4, 22], "produc": 33, "product": [0, 7, 22], "programmat": 18, "progress": [17, 27], "project": [3, 6, 8, 13, 29, 30, 34], "prompt": 29, "prompt_encod": 29, "prompt_respons": 29, "proper": [1, 8, 36, 39], "properli": 8, "properti": [1, 2, 18, 22, 24, 30, 31, 33], "protocol": [2, 24, 39], "provid": [0, 1, 2, 3, 4, 6, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 40, 41], "pt": [0, 8, 11, 27, 30], "pt2": [5, 7, 13], "ptx": 6, "public": 13, "publish": 13, "pudb": 10, "pure": 13, "purpos": [0, 4], "put": [3, 22], "py": [1, 3, 7, 8], "pyarrow": 7, "pyproject": [3, 7], "pytest": [6, 7, 13], "python": [0, 1, 3, 7, 8, 9, 13, 16, 18, 22, 28], "python3": 6, "python_vers": 6, "pytorch": [2, 7, 8, 11, 13, 22, 23, 31, 36], "q": 9, "q_norm": 30, "qkv_proj_bia": [8, 30], "qualiti": [7, 11], "qualnam": 22, "queri": [0, 8, 29, 30], "quick": [1, 4, 8], "quickli": 11, "quit": 9, "qwen": [0, 8, 11, 17, 18, 28], "qwen2": [0, 8, 30], "qwen25_0": 27, "qwen25_1": 27, "qwen25_14b": [8, 30], "qwen25_1_5b": 30, "qwen25_32b": 30, "qwen25_3b": [8, 27, 30], "qwen25_3b_instruct": 8, "qwen25_7b": [0, 27, 28, 30], "qwen25_7b_instruct": 0, "qwen3": [0, 17, 18, 30], "qwen3_0": [8, 17, 18, 28, 30], "qwen3_1": 30, "qwen3_14b": 30, "qwen3_32b": 30, "qwen3_4b": 30, "qwen3_8b": [0, 8, 30], "qwen_checkpoint": 30, "qwen_hf_checkpoint": 30, "qwenconfig": 8, "qwentoken": [17, 18], "qwentokenizerconfig": [17, 18], "r": [5, 6, 13], "race": 11, "rais": [3, 17, 19, 22, 23, 24, 27, 36], "raise_operational_gang_error": 22, "randint": 32, "randn": [31, 36, 39], "random": [8, 39], "random_mask": 39, "rang": [8, 11, 22], "rank": [1, 4, 9, 22], "rate": [1, 23, 40], "rather": 4, "raw": [18, 30], "rdp": [4, 22], "re": [8, 13, 35], "reach": [9, 22], "read": [1, 4, 6, 11, 13, 20], "read_fil": 1, "read_sequ": 1, "readabl": [8, 13], "reader": 1, "readi": 1, "readm": 13, "real": [4, 6, 22], "rearrang": 33, "reason": [5, 6, 13, 22], "receiv": 33, "recip": [0, 9, 10, 20, 24], "recipecontext": [1, 24], "recipemodel": [1, 23], "recogn": 8, "recognit": 28, "recommend": [6, 7, 20, 29], "recurs": [6, 20], "reduc": [4, 11, 22, 30], "reduceoper": [4, 22], "reduct": 22, "redund": 2, "refer": [1, 4, 8, 9, 14, 15, 18, 19, 21, 25, 26, 27, 29, 30, 36, 40, 41], "refrain": 13, "regex": 29, "regim": 1, "regimesect": 1, "regist": [0, 1, 2, 3, 8, 17, 19, 20, 23, 27], "register_compon": 23, "register_dataset_famili": [0, 1, 3, 20], "register_file_asset": [0, 3], "register_in_memory_asset": 0, "register_inst": 2, "register_model_famili": [1, 3], "register_package_asset": [0, 3], "register_tokenizer_famili": [1, 3], "register_typ": 2, "registr": 8, "registri": [2, 14], "regular": 11, "reinstal": 7, "rel": [0, 20, 36], "relat": [0, 8], "relationship": 0, "releas": [5, 6, 11, 13], "relev": [0, 4, 11], "reli": [4, 5, 13], "reliabl": 7, "remark": 1, "reorder": 33, "replac": [5, 9], "replic": [4, 22], "repo": [7, 9], "report": [13, 26], "repositori": [0, 2, 13], "repr": [24, 30], "repres": [4, 11, 18, 22, 24, 32, 38], "represent": [12, 35], "reproduc": [7, 13], "request": [8, 11, 27], "requir": [0, 4, 5, 6, 7, 8, 11, 13, 31], "research": [2, 4, 10], "reserv": 33, "reset_non_persistent_buff": 36, "reset_paramet": [32, 35, 36, 37], "reshard": 11, "residu": 34, "residualconnect": 38, "resolut": [2, 7], "resolv": [1, 2, 7, 20, 23, 29], "resolve_opt": 2, "resourc": [0, 2, 9], "respect": [2, 36], "respons": 24, "rest": [2, 22], "restart": [7, 8], "restrict": 27, "result": [22, 24, 30, 31], "resum": 15, "retrain": 11, "retriev": [2, 20], "retrieve_card": [0, 2, 28], "return": [0, 1, 2, 3, 4, 8, 20, 22, 23, 24, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39], "reus": 6, "revers": 9, "review": 8, "revis": [11, 13], "rf": 7, "rico": 12, "rm": 7, "rmsnorm": 35, "road": 29, "robust": 11, "rodriguez": 12, "roform": 12, "role": 29, "root": [4, 6, 12, 13, 22, 35], "root_gang": [4, 22], "rope": 8, "rope_scal": 29, "rope_theta": [8, 29, 30], "rotari": [12, 29, 30], "rotaryencod": [2, 36], "round": 29, "row": [4, 39], "row_len": 39, "rowmaskfactori": 39, "rozi\u00e8r": 12, "rst": 13, "ruff": 7, "run": [4, 5, 6, 7, 11, 13, 30], "runner": 2, "runtim": [0, 2, 10, 13, 20, 23, 24], "ryan": 12, "safe": 1, "safetensor": [0, 8], "safeti": 1, "salloc": 9, "same": [0, 4, 5, 6, 8, 13, 22, 35, 36, 37, 38, 39], "sampl": 16, "sampler": 16, "sanit": 6, "save": [1, 11, 15, 31], "scalar": 22, "scale": [4, 29, 38], "scaledresidualconnect": 38, "scatter": 4, "scenario": [4, 8, 22], "scene": 18, "schedul": [1, 23, 40], "scheme": 11, "scope": 13, "scratch": [6, 11], "screenshot": 9, "script": [3, 6], "scriptmodul": [32, 35, 36, 37, 38], "sdp": [4, 22], "seamless": [4, 11, 16, 20], "seamlessli": 31, "search": [0, 10, 33], "second": [8, 22], "section": [1, 7, 20, 36], "see": [4, 6, 7, 8, 22, 33], "segfault": [5, 13], "select": [1, 21, 33], "self": [0, 1, 2, 12, 20, 23, 24, 31], "self_attn": 2, "self_attn_layer_norm": 2, "semant": 4, "sennrich": [12, 35], "sensibl": 1, "sentencepiec": [0, 18, 29], "separ": [0, 4, 7], "seq": [1, 31, 32, 36, 38, 39], "seq_begin_indic": 31, "seq_begin_indices_pt": 31, "seq_boundari": 31, "seq_len": [1, 31, 32, 36, 39], "seq_lens_pt": [31, 39], "seq_lens_tensor": 31, "seqs_layout": [1, 30, 36], "sequenc": [0, 1, 2, 10, 16, 18, 22, 23, 24, 29, 30, 33, 35, 36, 38, 39], "sequencebatch": 1, "seri": 30, "serv": [4, 11], "server": 13, "servic": 20, "session": [8, 9], "set": [0, 1, 2, 3, 4, 7, 8, 9, 11, 20, 22, 23, 24, 27, 29, 33], "set_stat": 33, "set_trac": 9, "setup": [4, 5], "setup_fs2_extens": 0, "setup_my_fairseq2": 0, "setup_my_fairseq2_extens": 3, "setuptool": [0, 3], "sever": [2, 4, 9, 29, 30], "sh": [6, 7], "shape": [18, 22, 27, 31, 32, 33, 35, 36, 37, 38, 39], "shard": [1, 4, 22, 29, 32], "shard_embed_dim": 29, "shard_spec": 30, "shardedembed": 32, "shardspec": 30, "share": [8, 32, 35, 36, 37, 38], "shazeer": 12, "shell": 7, "shengfeng": 12, "short": [6, 11, 13], "shorter": 0, "should": [8, 11, 13, 22, 24, 29, 33, 35], "should_continu": 22, "show": [0, 1, 2, 3, 8, 9, 36], "showcas": 1, "shown": 6, "shuffl": 16, "shutdown": 1, "signific": 11, "significantli": [2, 11], "similar": [6, 11, 18, 22], "similarli": 6, "simpl": [1, 3, 4, 8, 20], "simpler": 31, "simplest": 6, "simpli": [5, 13], "simplif": 11, "simplifi": [1, 2, 11, 30], "simul": [4, 22], "sinc": [9, 13], "singl": [0, 1, 2, 4, 11, 22, 31, 35], "singleton": 2, "sinusoid": 36, "sinusoidalpositionencod": [2, 36], "size": [0, 4, 8, 9, 18, 22, 29, 30, 31, 32, 33, 35, 36, 38, 39], "size_byt": 33, "skeleton": 1, "skip_special_token": [18, 30], "slice": 4, "slurm": 9, "smi": 7, "so": [1, 6], "solid": 7, "solut": 4, "some": [8, 17, 18, 29, 30], "some_condit": 22, "some_distributed_funct": 4, "some_object": 20, "soon": [10, 14, 15, 16, 21, 25, 26, 40, 41], "sort": [1, 30], "sourc": [0, 1, 2, 5, 7, 9, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41], "source_rank": [4, 22], "sp": 29, "sp_llama": 29, "span": 39, "span_len": 39, "special": [0, 11, 16, 33], "special_tokens_map": 29, "specif": [1, 2, 4, 5, 6, 8, 11, 13, 17, 19, 20, 22, 27, 30, 39, 41], "specifi": [0, 1, 4, 7, 8, 9, 18, 22, 23, 27, 29, 30, 32, 39], "spectrogram": 16, "speech": [12, 28], "sphinx": [7, 13], "sphinxcontrib": 7, "split": [1, 4, 22], "split_group": 22, "split_regex": 29, "spuriou": [5, 13], "sqrt": 37, "squar": [12, 35], "src": [4, 7, 8, 28], "srun": 9, "stabil": [3, 35], "stack": 29, "stai": 11, "standalon": [3, 4], "standard": [0, 6, 9, 22, 24, 29, 30, 31], "standardembed": 32, "standardlayernorm": 35, "standardobjectvalid": 24, "standardtransformerdecoderlay": 2, "start": [1, 2, 9, 11, 22], "start_header_id": 29, "start_lr": 23, "state": [4, 11, 22, 24, 30, 32, 34, 35, 36, 37, 38], "state_bag": 36, "state_dict": 30, "static": [31, 32], "step": [6, 33], "step_nr": [33, 36], "stop": 9, "store": [1, 14, 17, 19, 22, 27, 32, 33], "str": [1, 17, 18, 19, 23, 24, 27, 28, 29, 30, 35], "straightforward": [1, 6, 8], "strategi": [4, 16, 22, 31], "stream": [16, 22], "streamlin": 11, "strict": 30, "string": [8, 24, 30, 35], "strong": 1, "strongli": 6, "structur": [0, 1, 4, 8, 25, 29], "stty": 9, "studi": 13, "su": [12, 36], "sub": [4, 22, 24], "sub_gang": 22, "sub_kl": 2, "sub_result": 24, "subclass": [2, 11, 18, 30, 37], "submit": 13, "submodul": 6, "subsystem": 5, "success": 8, "sudo": [5, 6], "suffici": [6, 13, 20], "suffix": [0, 18], "suffix_indic": 18, "suit": [6, 13], "sum": [4, 8, 22, 31, 38], "summar": 10, "super": 31, "supervis": 12, "support": [0, 1, 2, 4, 6, 7, 8, 9, 16, 20, 22, 23, 24, 30, 31], "supports_process_group": 22, "sure": [6, 13, 22], "surfac": 4, "swap": [1, 4], "switch": 7, "sy": 30, "symbol": [18, 29, 30], "sync": 7, "synchron": 22, "syntax": [0, 8, 13], "system": [1, 2, 3, 5, 8, 13, 14, 16, 17, 19, 20, 27, 29, 30, 31, 34, 41], "t": [2, 9, 13, 20, 33], "t_co": 2, "tabl": [29, 30, 32, 36], "take": [4, 20, 33], "target": [1, 18, 30], "target_batch": 1, "task": [0, 2, 4, 9, 10, 18, 20, 28, 30, 41], "team": 11, "technic": [2, 36], "tell": [8, 29], "tensor": [1, 4, 11, 18, 21, 22, 23, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39], "tensorboard": 7, "term": [29, 30, 33, 36], "term_siz": 9, "termin": 9, "test": [0, 2, 4, 6, 7, 8, 22], "testabl": 11, "text": [17, 18, 29, 30, 32, 37], "than": [4, 13, 36, 39], "thank": 11, "them": [6, 8, 13, 22, 24, 38], "therefor": [23, 32], "theta": [8, 36], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 33, 35, 37, 40, 41], "thibaut": 12, "third": 6, "thousand": 4, "three": 0, "through": [1, 2, 3, 4, 8, 20, 29, 30], "throughout": 1, "throughput": [11, 16], "thu": 33, "ti": [1, 29, 30], "tidi": 13, "tie": 8, "tied_embed": [8, 29, 30], "tiedproject": 37, "tightli": 11, "tiktoken": 18, "tiktoken_llama_instruct": 29, "time": [13, 33], "timedelta": 22, "timeout": 22, "timoth\u00e9": 12, "to_batch": 1, "to_embed": 32, "todo": 1, "togeth": [1, 8, 22], "token": [0, 1, 3, 8, 11, 14, 16, 19, 27, 32], "tokendecod": [18, 30], "tokenencod": [18, 30], "tokenizer_config": [0, 8, 29], "tokenizer_config_overrid": 29, "tokenizer_famili": [0, 8, 29], "tokenizer_hub": 30, "tokenizerconfigt": [17, 29, 30], "tokenizerfamili": 17, "tokenizerhub": [29, 30], "tokenizerhubaccessor": 18, "tokenizersect": 1, "tokenizert": [17, 29, 30], "toler": 4, "toml": [3, 7], "too": 13, "tool": [6, 7, 13, 16], "toolkit": [6, 10, 11, 13], "top": [4, 20, 23], "topologi": [4, 22], "torch": [1, 4, 6, 7, 11, 22, 23, 30, 32, 33, 36, 37, 39], "torch_vers": 6, "torchaudio": 7, "torchvis": 7, "total": [4, 22, 29, 31], "total_loss": 22, "touch": [3, 13], "touvron": [12, 29], "tp": [4, 22], "tp_mesh": 4, "tp_size": [4, 22], "trace": 3, "track": [0, 4, 13, 26, 33], "trade": 31, "train": [0, 1, 4, 7, 9, 10, 11, 14, 15, 16, 22, 26, 28, 30, 31, 32, 34, 39, 40, 41], "train_main": 1, "train_model": 7, "trainer": 1, "trainersect": 1, "trainrecip": [0, 1, 20, 23], "trainunit": 1, "transcript": [18, 30], "transform": [0, 8, 12, 16, 29, 30, 34, 35, 37, 38], "transformer_lm": 0, "transformerdecoderlay": 2, "transformerfrontend": 30, "transformerlm": 30, "transformerlmdecod": 30, "transformerlmdecoderlay": 30, "translat": [10, 18, 28, 30], "travers": 24, "treat": 24, "tree": 13, "tricki": 6, "trivial": 4, "troubleshoot": 11, "true": [17, 18, 22, 24, 27, 29, 30, 31, 35, 37], "try": [0, 8, 19, 24, 27], "tune": [0, 11], "tupl": [1, 23, 24, 27, 31, 39], "turn": [6, 29], "tutori": [1, 8, 9, 11, 27, 29, 30], "two": [3, 4, 8, 13, 22], "txt": [5, 6, 13], "type": [0, 1, 2, 8, 11, 16, 17, 19, 22, 24, 27, 29, 33], "typic": [4, 6, 18, 24, 30, 33], "u": [18, 30, 37], "ubuntu": [5, 6], "under": [11, 13, 31], "underli": [4, 8, 22], "understand": [27, 29, 30], "unexpect": 22, "unifi": [0, 4, 8, 11, 21, 27, 31, 34], "uniform": 31, "uniformli": 4, "uniniti": 27, "uniqu": [0, 22], "unit": [1, 11, 13], "unk": 18, "unk_idx": 18, "unknown": 18, "unknown_famili": 19, "unless": [6, 37], "unmask": 39, "unsqueez": 31, "until": 22, "up": [0, 2, 3, 4, 7, 11, 29], "updat": [1, 4, 6, 10, 11, 13, 32], "update_nll_loss_metr": 1, "update_seq_batch_metr": 1, "upgrad": [5, 11, 13], "uri": 0, "url": [0, 5, 6, 7, 12, 13], "us": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 17, 19, 20, 22, 23, 24, 27, 30, 31, 32, 33, 36, 37], "usag": [1, 4, 7, 11, 17, 19, 20, 32, 36, 39], "use_eot": 29, "use_im_end": [0, 8, 30], "use_scaled_rop": 29, "user": [0, 4, 6, 7, 8, 13, 20, 29], "usual": 9, "uszkoreit": 12, "util": [1, 4, 9, 10, 15, 16, 21, 25, 26, 28, 29, 30, 31, 34, 40], "uv": 5, "v": [4, 7, 31], "v0": [1, 2, 7, 10, 31], "v04": 7, "valid": [1, 10, 18, 22, 30, 31], "validat": 24, "validationerror": [23, 24], "validationresult": 24, "valu": [1, 8, 22, 23, 24, 29, 30, 33, 35], "valueerror": [22, 36], "vari": 8, "variabl": [0, 3, 4, 16, 31], "variant": [0, 6, 7, 8, 13, 20], "variou": [0, 11, 16, 20, 28, 34], "varlen": 11, "vaswani": 12, "ve": [1, 13], "venv": [6, 7], "verif": 8, "verifi": 7, "version": 30, "via": [0, 1, 2, 6, 13, 17, 20, 29], "view": 9, "virtual": 2, "visit": 13, "vllm": [7, 11], "vocab_info": [18, 30], "vocab_s": [8, 29, 30], "vocabulari": [18, 29, 30, 32], "vocabularyinfo": [18, 30], "volta": 6, "vstack": 30, "w": 20, "wa": 6, "wai": [3, 17, 19, 21], "wait": 9, "walk": 8, "want": [6, 8, 9, 13, 18, 24], "warn": 3, "wast": 31, "wav2vec": 12, "wav2vec2": 28, "wav2vec2_larg": 0, "wav2vec2_large_lv60k": 0, "we": [1, 4, 6, 9, 13, 22], "websit": 6, "weight": [8, 29, 37], "well": [2, 22, 24], "wen": 12, "what": [1, 2, 8, 9, 10, 22], "wheel": 6, "wheelhous": 6, "when": [0, 4, 6, 7, 8, 11, 17, 18, 19, 22, 23, 24, 27, 29, 33, 36], "whenev": 24, "where": [0, 3, 4, 7, 8, 9, 18, 20, 22, 32, 33, 35, 36, 37, 38, 39], "wherea": 4, "wherev": [2, 36], "whether": 29, "which": [1, 2, 3, 4, 5, 6, 8, 9, 13, 18, 23, 29, 30, 32, 33, 35], "while": [4, 11, 18, 20, 22, 30], "whl": [5, 6, 7, 13], "who": 6, "whose": 23, "why": 29, "wide": [0, 20], "width": 31, "wire": [1, 2], "within": [0, 2, 4, 11, 22], "without": [2, 3, 4, 6, 22, 27], "work": [0, 4, 6, 7, 11, 16, 17, 18, 19, 21, 22, 29, 30], "workflow": [11, 16], "workload": 16, "world": [4, 22, 29], "world_siz": 4, "worldinfo": 2, "would": [6, 9], "wrap": 22, "wrapper": 4, "write": [11, 22], "wsl": 5, "x": [31, 32, 35, 37], "x86_64": 6, "xavier": 12, "xxxxx": 8, "yaml": [1, 3, 8, 20], "ye": 0, "yet": [11, 13], "yet_other_asset": [0, 1], "yield_from": 1, "you": [0, 1, 3, 5, 6, 7, 8, 9, 12, 13, 18, 20, 28, 29, 35], "your": [3, 5, 6, 7, 9, 10, 18, 19, 20, 27, 29, 30, 35], "your_packag": 1, "yourrecip": 20, "yourself": 9, "yu": 12, "yunfeng": 12, "zhang": [12, 35], "zhou": 12}, "titles": ["<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-container\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.41.24l4.711 2.774A1.767 1.767 0 0116 4.54v5.01a1.77 1.77 0 01-.88 1.53l-7.753 4.521-.002.001a1.767 1.767 0 01-1.774 0H5.59L.873 12.85A1.762 1.762 0 010 11.327V6.292c0-.304.078-.598.22-.855l.004-.005.01-.019c.15-.262.369-.486.64-.643L8.641.239a1.75 1.75 0 011.765 0l.002.001zM9.397 1.534a.25.25 0 01.252 0l4.115 2.422-7.152 4.148a.267.267 0 01-.269 0L2.227 5.716l7.17-4.182zM7.365 9.402L8.73 8.61v4.46l-1.5.875V9.473a1.77 1.77 0 00.136-.071zm2.864 2.794V7.741l1.521-.882v4.45l-1.521.887zm3.021-1.762l1.115-.65h.002a.268.268 0 00.133-.232V5.264l-1.25.725v4.445zm-11.621 1.12l4.1 2.393V9.474a1.77 1.77 0 01-.138-.072L1.5 7.029v4.298c0 .095.05.181.129.227z\"></path></svg> Assets", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-rocket\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z\"></path></svg> Building Recipes", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-infinity\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.5 6c-1.086 0-2 .914-2 2 0 1.086.914 2 2 2 .525 0 1.122-.244 1.825-.727.51-.35 1.025-.79 1.561-1.273-.536-.483-1.052-.922-1.56-1.273C4.621 6.244 4.025 6 3.5 6zm4.5.984c-.59-.533-1.204-1.066-1.825-1.493-.797-.548-1.7-.991-2.675-.991C1.586 4.5 0 6.086 0 8s1.586 3.5 3.5 3.5c.975 0 1.878-.444 2.675-.991.621-.427 1.235-.96 1.825-1.493.59.533 1.204 1.066 1.825 1.493.797.547 1.7.991 2.675.991 1.914 0 3.5-1.586 3.5-3.5s-1.586-3.5-3.5-3.5c-.975 0-1.878.443-2.675.991-.621.427-1.235.96-1.825 1.493zM9.114 8c.536.483 1.052.922 1.56 1.273.704.483 1.3.727 1.826.727 1.086 0 2-.914 2-2 0-1.086-.914-2-2-2-.525 0-1.122.244-1.825.727-.51.35-1.025.79-1.561 1.273z\"></path></svg> Design Philosophy", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-plug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M10.276 3.09a.25.25 0 01.192-.09h.782a.25.25 0 01.25.25v8.5a.25.25 0 01-.25.25h-.782a.25.25 0 01-.192-.09l-.95-1.14a.75.75 0 00-.483-.264l-3.124-.39a.25.25 0 01-.219-.249V5.133a.25.25 0 01.219-.248l3.124-.39a.75.75 0 00.483-.265l.95-1.14zM4 8v1.867a1.75 1.75 0 001.533 1.737l2.83.354.761.912c.332.4.825.63 1.344.63h.782A1.75 1.75 0 0013 11.75V11h2.25a.75.75 0 000-1.5H13v-4h2.25a.75.75 0 000-1.5H13v-.75a1.75 1.75 0 00-1.75-1.75h-.782c-.519 0-1.012.23-1.344.63l-.76.913-2.831.353A1.75 1.75 0 004 5.133V6.5H2.5A2.5 2.5 0 000 9v5.25a.75.75 0 001.5 0V9a1 1 0 011-1H4z\"></path></svg> Runtime Extension", "What is a Gang?", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-download\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.47 10.78a.75.75 0 001.06 0l3.75-3.75a.75.75 0 00-1.06-1.06L8.75 8.44V1.75a.75.75 0 00-1.5 0v6.69L4.78 5.97a.75.75 0 00-1.06 1.06l3.75 3.75zM3.75 13a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5z\"></path></svg> Installation", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-file-binary\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0114.25 15h-9a.75.75 0 010-1.5h9a.25.25 0 00.25-.25V6h-2.75A1.75 1.75 0 0110 4.25V1.5H5.75a.25.25 0 00-.25.25v2a.75.75 0 01-1.5 0v-2zm7.5-.188V4.25c0 .138.112.25.25.25h2.688a.252.252 0 00-.011-.013l-2.914-2.914a.272.272 0 00-.013-.011zM0 7.75C0 6.784.784 6 1.75 6h1.5C4.216 6 5 6.784 5 7.75v2.5A1.75 1.75 0 013.25 12h-1.5A1.75 1.75 0 010 10.25v-2.5zm1.75-.25a.25.25 0 00-.25.25v2.5c0 .138.112.25.25.25h1.5a.25.25 0 00.25-.25v-2.5a.25.25 0 00-.25-.25h-1.5zm5-1.5a.75.75 0 000 1.5h.75v3h-.75a.75.75 0 000 1.5h3a.75.75 0 000-1.5H9V6.75A.75.75 0 008.25 6h-1.5z\"></path></svg> Installing from Source", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-lock\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4 4v2h-.25A1.75 1.75 0 002 7.75v5.5c0 .966.784 1.75 1.75 1.75h8.5A1.75 1.75 0 0014 13.25v-5.5A1.75 1.75 0 0012.25 6H12V4a4 4 0 10-8 0zm6.5 2V4a2.5 2.5 0 00-5 0v2h5zM12 7.5h.25a.25.25 0 01.25.25v5.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-5.5a.25.25 0 01.25-.25H12z\"></path></svg> UV Setup", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-ruby\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M3.637 2.291A.75.75 0 014.23 2h7.54a.75.75 0 01.593.291l3.48 4.5a.75.75 0 01-.072.999l-7.25 7a.75.75 0 01-1.042 0l-7.25-7a.75.75 0 01-.072-.999l3.48-4.5zM4.598 3.5L1.754 7.177 8 13.207l6.246-6.03L11.402 3.5H4.598z\"></path></svg> Add Your Own Model", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-bug\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.72.22a.75.75 0 011.06 0l1 .999a3.492 3.492 0 012.441 0l.999-1a.75.75 0 111.06 1.061l-.775.776c.616.63.995 1.493.995 2.444v.327c0 .1-.009.197-.025.292.408.14.764.392 1.029.722l1.968-.787a.75.75 0 01.556 1.392L13 7.258V9h2.25a.75.75 0 010 1.5H13v.5c0 .409-.049.806-.141 1.186l2.17.868a.75.75 0 01-.557 1.392l-2.184-.873A4.997 4.997 0 018 16a4.997 4.997 0 01-4.288-2.427l-2.183.873a.75.75 0 01-.558-1.392l2.17-.868A5.013 5.013 0 013 11v-.5H.75a.75.75 0 010-1.5H3V7.258L.971 6.446a.75.75 0 01.558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.684 1.684 0 01-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 010-1.06zM6.173 5h3.654A.173.173 0 0010 4.827V4.5a2 2 0 10-4 0v.327c0 .096.077.173.173.173zM5.25 6.5a.75.75 0 00-.75.75V11a3.5 3.5 0 107 0V7.25a.75.75 0 00-.75-.75h-5.5z\"></path></svg> Debugging with PuDB", "Welcome to fairseq2 Documentation", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-report\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M1.75 1.5a.25.25 0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75 0 01.75.75v2.19l2.72-2.72a.75.75 0 01.53-.22h6.5a.25.25 0 00.25-.25v-9.5a.25.25 0 00-.25-.25H1.75zM0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v9.5A1.75 1.75 0 0114.25 13H8.06l-2.573 2.573A1.457 1.457 0 013 14.543V13H1.75A1.75 1.75 0 010 11.25v-9.5zM9 9a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z\"></path></svg> What\u2019s New in v0.5", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-book\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M0 1.75A.75.75 0 01.75 1h4.253c1.227 0 2.317.59 3 1.501A3.744 3.744 0 0111.006 1h4.245a.75.75 0 01.75.75v10.5a.75.75 0 01-.75.75h-4.507a2.25 2.25 0 00-1.591.659l-.622.621a.75.75 0 01-1.06 0l-.622-.621A2.25 2.25 0 005.258 13H.75a.75.75 0 01-.75-.75V1.75zm8.755 3a2.25 2.25 0 012.25-2.25H14.5v9h-3.757c-.71 0-1.4.201-1.992.572l.004-7.322zm-1.504 7.324l.004-5.073-.002-2.253A2.25 2.25 0 005.003 2.5H1.5v9h3.757a3.75 3.75 0 011.994.574z\"></path></svg> Bibliography", "<svg version=\"1.1\" width=\"1.0em\" height=\"1.0em\" class=\"sd-octicon sd-octicon-heart\" viewBox=\"0 0 16 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z\"></path></svg> Contributing to fairseq2", "fairseq2.assets", "fairseq2.checkpoint", "fairseq2.data", "fairseq2.data.tokenizers.hub", "fairseq2.data.tokenizers", "fairseq2.datasets.hub", "fairseq2.datasets", "fairseq2.device", "fairseq2.gang", "fairseq2.recipe.optim", "fairseq2.utils.validation", "fairseq2.logging", "fairseq2.metrics", "fairseq2.models.hub", "fairseq2.models", "fairseq2.models.llama", "fairseq2.models.qwen", "Batch Layout", "Embeddings", "Incremental State", "fairseq2.nn", "Normalization Layers", "Position Encoders", "Projection Layers", "Residual Connections", "fairseq2.nn.utils", "fairseq2.optim", "fairseq2.recipe"], "titleterms": {"": [11, 18], "0": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "00": [0, 1, 3, 5, 6, 7, 9, 11, 12], "000": [3, 5, 6], "001": [1, 3, 5, 11, 13], "0010": 9, "0012": 7, "0013": 3, "0014": [1, 7], "0016": 1, "001a1": 0, "001zm9": 0, "002": [0, 7, 12, 13], "002a": 0, "002l8": 13, "002zm12": 1, "003": [12, 13], "003a": 1, "003h": 13, "004": [0, 3, 12], "005": [0, 1, 12], "006": [12, 13], "008": [6, 13], "009": 9, "01": [0, 1, 3, 6, 7, 8, 9, 11, 12, 13], "010": [0, 6, 9, 11], "011": [0, 3, 6, 9, 12], "0110": 6, "0111": 12, "0114": [1, 6, 11], "0116": 0, "011zm0": 6, "012": [1, 3, 9, 11, 12], "013": [6, 9, 11], "013l": 6, "014": 8, "018": [9, 13], "019c": 0, "01a1": 0, "01a7": 13, "02": [1, 13], "021": 0, "025": [2, 9], "026": 9, "029": [9, 13], "029v4": 0, "02l": 1, "03": 9, "037": 1, "03l11": 8, "042": 8, "045": 13, "046": 1, "047": 1, "049": 9, "05": 0, "051": 1, "052": 2, "058": 1, "06": [1, 5, 9, 12], "061l": 9, "063": 1, "064": 1, "066": 2, "066zm3": 1, "06l": 11, "06l3": 5, "06l8": 5, "06zm6": 9, "071zm2": 0, "072": 8, "072l1": 0, "073": 12, "075": 13, "077": 9, "078": 0, "079": 1, "08": 13, "086": [2, 13], "088": 1, "09": 1, "094": 1, "095": 0, "096": 9, "09a": 3, "09h": 3, "09l": 3, "0a8": 1, "0c6": 13, "0em": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "0h": 1, "0h12": 11, "0h5": [0, 6], "0l": [0, 8, 9, 12, 13], "0l1": 9, "0l2": 0, "0l3": 5, "0l4": 0, "0l8": 13, "0v": [6, 9, 11], "0v2": 11, "0v2h5zm12": 7, "0v6": 5, "0v7": 9, "0v9a1": 3, "0zm": [1, 11], "0zm6": 7, "1": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "10": [1, 5, 6, 7, 9, 13], "102": 1, "102a": 1, "103": 1, "107": 9, "11": [0, 1, 3, 11, 13], "111": 9, "112": [6, 11], "114": 2, "115": 0, "116l5": 1, "117": 1, "118": 1, "119": 1, "119l": 1, "11l3": 1, "11v": 9, "12": [0, 1], "122": 2, "123": 1, "124": [1, 3], "125l": 1, "127l": 1, "129": 0, "12c": 1, "12h": 6, "12l4": 0, "13": [7, 8, 13], "133": 0, "133a": 3, "133v6": 3, "135": 13, "136": 0, "138": [0, 6, 11], "13a": 5, "13h": 12, "13h8": 11, "14": [9, 11, 13], "141": 9, "143": 1, "144": 13, "145": 1, "145l2": 1, "148a": 0, "148z": 1, "14a": 3, "14zm4": 3, "15": [0, 1, 13], "152": 0, "153": 13, "15h": 6, "16": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "164": 13, "16a4": 9, "17": [0, 9, 13], "173": 9, "173zm5": 9, "175l": 1, "176": 1, "177": [1, 8], "178": 1, "181": 0, "182zm7": 0, "183": 9, "184": [6, 9], "186a": 1, "186a7": 1, "186l2": 9, "186zm10": 1, "187": 1, "188v4": 6, "192": 3, "197": 9, "19l2": 11, "1a": 9, "1h4": 12, "1h4z": 3, "2": [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13], "20": 13, "201": 12, "203": 13, "204": 2, "207l6": 8, "21": 1, "211c12": 13, "213": 1, "213v": 1, "216": [6, 11], "219": 3, "22": [0, 13], "227": [0, 12], "227z": 0, "22a": 9, "22h6": 11, "23": [1, 3, 8], "231": 13, "232v5": 0, "235": 2, "237": 6, "237v8": 6, "239a1": 0, "244": 2, "245a": 12, "246": 8, "248l3": 3, "249v5": 3, "24l4": 0, "25": [0, 1, 3, 6, 7, 8, 9, 11, 12, 13], "252": [0, 6], "253a2": 12, "253c1": 12, "258": 12, "258l": 9, "258v9h2": 9, "25a": [3, 6, 7, 9, 11], "25a1": 7, "25c0": 6, "25h": [3, 6, 7], "25h1": [6, 11], "25h12z": 7, "25h14": 12, "25h2": 6, "25h2a": 11, "25l": 13, "25v": [1, 6, 7, 11], "25v1": 6, "25v2": 6, "25v2a": 6, "25v5": 7, "25v6h": 6, "25v8": 3, "25v9": 11, "25z": 13, "25zm0": 13, "26": 1, "262": 0, "264l": [0, 3], "265": [1, 9], "265c": 1, "265l": 3, "266": 1, "266h3": 1, "267": 0, "268": 0, "269": 0, "272": 6, "273": [1, 2], "273c4": 2, "273z": 2, "276": 3, "288": [1, 9], "28a": 9, "291a": 8, "291l3": 8, "292": 9, "292c0": 0, "292v4": 9, "298c0": 0, "2a": 1, "2h7": 8, "2v4a2": 7, "2zm7": 6, "3": [1, 2, 3, 5, 6, 8, 9, 12, 13], "304": 0, "309a": 1, "31": 13, "314": 1, "317": [1, 12], "317a15": 1, "31a1": 1, "322zm": 12, "324l": 12, "327c0": 9, "327v6": 0, "328": 6, "329": 6, "33": 9, "332": [1, 3], "336": 13, "338": 1, "344": 3, "345": 13, "35": [1, 2, 13], "353a1": 3, "354": 3, "365": [0, 13], "369": 0, "373": 13, "38": 9, "392": 9, "392l": 9, "392l1": 9, "392l13": 9, "392l2": 9, "393a20": 13, "393v9": 0, "397": 0, "39a": 3, "3a2": 12, "4": [0, 1, 2, 3, 6, 7, 8, 9, 12, 13], "402": 8, "402l8": 0, "408": 9, "409": 9, "41": 0, "414": 13, "414c2": 13, "416": 1, "418": 1, "418l2": 1, "422": 0, "427": 2, "427l": 9, "428c": 1, "429": 1, "434": 13, "44": 1, "441": 9, "442": 13, "443": 2, "444": 2, "444l4": 9, "444v": 9, "445zm": 0, "446a": 9, "44v1": 5, "456a": 13, "457": 11, "458": 1, "458a15": 1, "458c": 1, "458h": 1, "459": 1, "459a8": 1, "45l": 0, "464": 6, "46l": 0, "47": 5, "473a1": 0, "474a1": 0, "48": 8, "483": [2, 3], "485c": 1, "486": [0, 13], "49": 1, "492": 9, "493": [2, 9], "493a7": 1, "493zm9": 2, "499": 1, "49v9": 1, "4h2": 3, "4v2h": 7, "5": [0, 1, 2, 3, 5, 6, 7, 9, 11, 12, 13], "501a3": 12, "504": 12, "507a2": 12, "51": 2, "513": 6, "513l2": 6, "519": 3, "521": [0, 1], "525": 2, "53": 11, "533": [2, 3], "534a": 0, "536": 2, "53l": 0, "543v13h1": 11, "547": 2, "547zm5": 1, "548": [1, 2], "54a": 8, "54v5": 0, "556": 9, "557": 9, "558": 9, "56": 2, "561": [2, 13], "563l": 1, "565": 13, "56a1": 1, "572l": 12, "573": 11, "573a1": 11, "574z": 12, "58": 13, "583": 9, "584l": 13, "586": 2, "586a1": 6, "586c": 6, "59": [1, 2, 12], "591": 12, "593": 8, "598": [0, 8], "598z": 8, "59l": 0, "5a": [3, 5, 6, 7, 8, 9, 11, 12], "5a1": [1, 6, 7, 11], "5a2": [3, 9], "5c": [2, 13], "5c0": [6, 7, 9, 11, 13], "5c15": 11, "5c4": 6, "5h": [1, 5, 6, 7, 9], "5h1": 12, "5h13v": [3, 9], "5h2": 3, "5h3": 9, "5h3a": 6, "5h3v7": 9, "5h4": 8, "5h5": 6, "5h8": 5, "5h9a": 6, "5h9v6": 6, "5l": 1, "5l1": 8, "5v9h": 12, "5v9h3": 12, "5z": [5, 6, 9, 11], "5zm1": 6, "5zm4": 8, "5zm5": 6, "5zm8": 13, "5zm9": 11, "6": [1, 2, 6, 8, 9, 13], "607a": 1, "609": 13, "616": [1, 9], "61v4": 0, "62": 9, "621": [0, 2], "621a": 12, "621a2": 12, "622": 12, "623": 13, "625c": 1, "63": [3, 9], "637": 8, "63h": 3, "63l": 3, "64": 0, "641": [0, 1], "643": 13, "643l8": 0, "644": 13, "65": 13, "654a": 9, "659l": 12, "65h": 0, "665": 1, "666": 13, "666a": 13, "671": 1, "675": 2, "678": 1, "682a20": 13, "684": 9, "688a": 6, "69": 13, "69l4": 5, "6c": 2, "6h": 6, "6h1": 6, "6h12v4a4": 7, "6zm4": 2, "7": [0, 1, 2, 6, 7, 8, 9, 12, 13], "704": 2, "707a1": 1, "71": 12, "711": 0, "716l7": 0, "72": [9, 11], "722a1": 9, "722l1": 9, "725v4": 0, "727": 2, "72a": 11, "73": [0, 1], "731": 13, "734": 1, "737l2": 3, "741l1": 0, "744": [12, 13], "75": [0, 1, 3, 5, 6, 7, 8, 9, 11, 12, 13], "752": 13, "753": 0, "754": 8, "755": 12, "757a3": 12, "757c": 12, "75a": [5, 6, 9, 12], "75a1": [1, 3, 6, 11], "75c0": [6, 11], "75c4": 6, "75h": [3, 9, 12], "75h8": 7, "75v1": 12, "75v10": 12, "75v11a3": 9, "75v11h2": 3, "75v2": [6, 11], "75v3h": 6, "75v5": 7, "75v9": 11, "75zm0": 11, "75zm3": 5, "75zm8": 12, "76": 3, "761": 3, "762": 0, "762l1": 0, "764": 9, "765": 0, "766c": 1, "767": 0, "77": 0, "773": 6, "774": [0, 1], "774a1": 0, "775": 9, "776c": 9, "78": 5, "782": 1, "782a": 3, "782a1": 3, "782c": 3, "783": 1, "784": [6, 7, 11], "787a": 9, "787c": 9, "78a": 5, "79": 2, "794v7": 0, "797": [2, 13], "7a": 8, "8": [0, 1, 5, 7, 8, 13], "802": 13, "806": 9, "814": 9, "818a22": 13, "825": [2, 3], "826": 2, "827v4": 9, "83": 3, "831": 3, "833": 1, "833l": 1, "836": 13, "847": 13, "85": 13, "855l": 0, "859": 13, "85a1": 0, "864": 0, "867a1": 3, "868a": 9, "868a5": 9, "873": 0, "873a": 9, "873a4": 9, "875v9": 0, "878": 2, "88": 0, "882v4": 0, "885": 13, "887zm3": 0, "8c": 2, "8s1": 2, "8v1": 3, "9": [0, 1, 11, 13], "904": 1, "904l": 1, "909": 6, "912c": 3, "913": 3, "914": [2, 6, 13], "914a": 6, "914c": 6, "92": 13, "922": 2, "936v1": 1, "949": 1, "95": [1, 3], "951": 9, "954": 1, "954c": 1, "96": 2, "966": 7, "967": 9, "968": 9, "971": 9, "975": 2, "979": 1, "979h3": 1, "97a": 5, "984c": 2, "986": 13, "991": 2, "991c1": 2, "992": 12, "994": 12, "995": 9, "997": 9, "999": 9, "999a3": 9, "999l": 8, "999l3": 8, "9a": 6, "9a1": 11, "9v5": 3, "A": 7, "Not": 8, "The": 0, "ad": [0, 8], "add": 8, "advanc": [0, 5, 11, 20, 27], "agreement": 13, "also": [0, 1, 2, 3, 16, 17, 19, 27, 29, 30, 34], "api": 10, "appl": 5, "architectur": [6, 8, 11, 30], "aria": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "asset": [0, 8, 14, 20], "audio": 16, "author": 11, "avail": [18, 28, 30], "base": [0, 18], "basic": [2, 3, 10, 30], "batch": [11, 31], "batchlayout": 31, "best": [0, 7], "bibliographi": 12, "binari": 6, "book": 12, "breakpoint": 9, "bug": 9, "build": [1, 6], "card": [0, 8, 20, 27], "chat": 29, "check": [6, 13], "checkpoint": [11, 15, 27, 30], "class": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 17, 18, 19, 22, 27], "cli": 0, "clone": 6, "code": 9, "common": [0, 7, 8, 27], "comparison": 30, "compil": 31, "complet": [8, 29, 30], "compon": [2, 16], "concept": [7, 10], "configur": [0, 1, 7, 8, 29, 30], "connect": 38, "consider": 31, "constant": 30, "contain": 0, "contribut": 13, "contributor": 13, "convent": 2, "convert_qwen_state_dict": 30, "core": [2, 8, 17, 19, 27], "cpu": 6, "creat": [0, 1, 4, 8, 20, 31], "create_qwen_model": 30, "cuda": [5, 6], "custom": [0, 20, 27, 30], "d": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "data": [4, 11, 16, 17, 18], "dataset": [0, 1, 19, 20], "datasetfamilynotknownerror": 19, "datasethub": 19, "datasethubaccessor": 19, "datasetnotknownerror": 19, "debug": 9, "debugg": 9, "defin": 1, "depend": [2, 6], "design": 2, "detail": [7, 8], "develop": 13, "devic": 21, "devicemesh": 4, "differ": 4, "document": [10, 13], "download": [5, 8], "edit": 6, "embed": 32, "encod": 36, "entri": 1, "enum": 22, "environ": [0, 6, 13], "error": [3, 8, 27], "evenodd": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "exampl": [3, 8, 27, 29, 30], "except": [17, 19, 22, 27], "execut": 2, "exist": 8, "exit": 9, "experi": 11, "export_qwen": 30, "extens": 3, "face": [8, 11], "factori": [22, 30], "fairseq2": [4, 6, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 34, 39, 40, 41], "fairseq2n": 6, "famili": [8, 27, 28], "featur": 20, "field": 0, "file": [0, 6, 8], "fill": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "flow": 2, "format": 13, "found": 8, "from": [4, 6, 30], "function": [17, 22, 23, 27], "gang": [4, 22], "get": [10, 28], "get_llama_model_hub": 29, "get_llama_tokenizer_hub": 29, "get_qwen_model_hub": 30, "get_qwen_shard_spec": 30, "get_qwen_tokenizer_hub": 30, "global": 27, "guid": [8, 10, 11], "handl": [3, 27], "heart": 13, "height": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "hidden": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "how": 4, "http": 8, "hub": [8, 17, 19, 27, 29, 30], "hug": [8, 11], "huggingfac": 29, "i": 4, "implement": [1, 2, 8, 29], "increment": 33, "indic": [10, 31], "infin": 2, "inform": [28, 31], "inherit": 0, "initi": 9, "inject": 2, "inspect": 27, "instal": [5, 6], "integr": [8, 11, 31], "interfac": 2, "interoper": 30, "invers": 2, "issu": 13, "iter": 27, "kei": [7, 20], "latest": 10, "layer": [31, 35, 37], "layout": 31, "licens": 13, "lint": 13, "linux": 5, "list": [13, 18, 28], "llama": [27, 29], "llamaconfig": 29, "llamatokenizerconfig": 29, "load": [8, 18, 27, 28, 30], "load_model": 27, "load_token": 17, "local": 8, "lock": 7, "log": 25, "m0": 12, "m1": 11, "m10": [0, 3], "m14": 1, "m3": [2, 8], "m4": [6, 7, 9, 13], "m7": 5, "maco": 5, "maintain": 11, "manag": 11, "mask": [31, 39], "memori": 11, "metric": [11, 26], "migrat": 11, "mistral": 27, "mode": 29, "model": [0, 4, 8, 11, 18, 27, 28, 29, 30], "modelhub": 27, "modelhubaccessor": 27, "monitor": 11, "network": 31, "neural": 31, "new": [10, 11], "next": 11, "nn": [34, 39], "normal": 35, "octicon": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "onli": 6, "open": 20, "optim": [11, 23, 40], "option": [6, 8], "other": 10, "over": 27, "overrid": 0, "overview": [1, 3, 7, 8], "own": 8, "parallel": 4, "paramet": 8, "path": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "perform": [11, 31], "philosophi": 2, "pip": 6, "pipelin": 16, "place": 9, "plug": 3, "point": 1, "posit": [31, 36], "practic": [0, 7], "prerequisit": 7, "process": [11, 16], "processgroup": 4, "programmat": 0, "project": [7, 37], "pudb": 9, "pull": 13, "python": 6, "pytorch": [4, 5, 6], "quick": [5, 7, 17, 18, 27, 28, 29, 30], "qwen": [27, 30], "qwen_famili": 30, "qwenconfig": 30, "qwenfactori": 30, "qwentoken": 30, "qwentokenizerconfig": 30, "recip": [1, 2, 11, 23, 41], "recommend": 8, "refer": [0, 10, 17], "registr": [0, 20], "remot": 9, "report": 11, "repositori": 6, "request": 13, "residu": 38, "rocket": 1, "rubi": 8, "rule": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "run": [1, 9], "runtim": 3, "saniti": 6, "sd": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "see": [0, 1, 2, 3, 16, 17, 19, 27, 29, 30, 34], "sequenc": [8, 31], "set": [6, 13], "setup": [1, 3, 7], "shard": [11, 30], "silicon": 5, "socket": 9, "sourc": [6, 8], "special": 29, "specif": [0, 18], "start": [7, 10, 18, 27, 28, 29, 30], "state": 33, "step": [1, 8], "store": 0, "structur": 16, "support": [5, 11, 28, 29], "svg": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "system": [0, 6], "tabl": 10, "templat": 29, "test": 13, "text": 16, "tiktoken": 29, "tip": 7, "token": [17, 18, 29, 30], "tokenizerfamilynotknownerror": 17, "tokenizerhub": [17, 18], "tokenizerhubaccessor": 17, "tokenizernotknownerror": 17, "torch": 31, "train": 8, "troubleshoot": [0, 7, 8], "true": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "understand": [0, 8], "up": [6, 13], "url": 8, "us": [4, 18, 29], "usag": [0, 2, 3, 27, 30], "user": 11, "util": [22, 24, 39], "uv": 7, "v0": 11, "valid": [8, 24], "variant": 5, "verifi": 8, "version": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "viewbox": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "virtual": 6, "vocabulari": 8, "welcom": 10, "what": [4, 11], "width": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13], "window": 5, "work": [8, 13, 27, 31], "workflow": 7, "yaml": 0, "your": [1, 8, 13]}})