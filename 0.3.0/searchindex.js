Search.setIndex({"docnames": ["bibliography", "index", "reference/abc", "reference/all", "reference/asset", "reference/classes", "reference/data", "reference/enums", "reference/functions", "reference/generated/abc/fairseq2.gang.Gang", "reference/generated/classes/fairseq2.optim.lr_scheduler.CosineAnnealingLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.MyleLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.NoamLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.PolynomialDecayLR", "reference/generated/data/fairseq2.assets.AssetCard", "reference/generated/data/fairseq2.assets.AssetMetadataProvider", "reference/generated/data/fairseq2.assets.AssetStore", "reference/generated/data/fairseq2.data.ByteStreamError", "reference/generated/data/fairseq2.data.CollateOptionsOverride", "reference/generated/data/fairseq2.data.Collater", "reference/generated/data/fairseq2.data.DataPipeline", "reference/generated/data/fairseq2.data.DataPipelineBuilder", "reference/generated/data/fairseq2.data.DataPipelineError", "reference/generated/data/fairseq2.data.FileMapper", "reference/generated/data/fairseq2.data.RecordError", "reference/generated/data/fairseq2.data.VocabularyInfo", "reference/generated/data/fairseq2.data.get_last_failed_example", "reference/generated/data/fairseq2.data.list_files", "reference/generated/data/fairseq2.data.read_sequence", "reference/generated/data/fairseq2.data.read_zipped_records", "reference/generated/data/fairseq2.data.text.read_text", "reference/generated/data_text/fairseq2.data.text.LineEnding", "reference/generated/data_text/fairseq2.data.text.SentencePieceDecoder", "reference/generated/data_text/fairseq2.data.text.SentencePieceEncoder", "reference/generated/data_text/fairseq2.data.text.SentencePieceModel", "reference/generated/data_text/fairseq2.data.text.StrSplitter", "reference/generated/data_text/fairseq2.data.text.StrToIntConverter", "reference/generated/data_text/fairseq2.data.text.StrToTensorConverter", "reference/generated/data_text/fairseq2.data.text.TextTokenDecoder", "reference/generated/data_text/fairseq2.data.text.TextTokenEncoder", "reference/generated/data_text/fairseq2.data.text.TextTokenizer", "reference/generated/data_text/fairseq2.data.text.vocab_info_from_sentencepiece", "reference/generated/enums/fairseq2.nn.transformer.TransformerNormOrder", "reference/generated/functions/fairseq2.nn.utils.mask.to_float_mask"], "filenames": ["bibliography.rst", "index.rst", "reference/abc.rst", "reference/all.rst", "reference/asset.rst", "reference/classes.rst", "reference/data.rst", "reference/enums.rst", "reference/functions.rst", "reference/generated/abc/fairseq2.gang.Gang.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.CosineAnnealingLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.MyleLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.NoamLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.PolynomialDecayLR.rst", "reference/generated/data/fairseq2.assets.AssetCard.rst", "reference/generated/data/fairseq2.assets.AssetMetadataProvider.rst", "reference/generated/data/fairseq2.assets.AssetStore.rst", "reference/generated/data/fairseq2.data.ByteStreamError.rst", "reference/generated/data/fairseq2.data.CollateOptionsOverride.rst", "reference/generated/data/fairseq2.data.Collater.rst", "reference/generated/data/fairseq2.data.DataPipeline.rst", "reference/generated/data/fairseq2.data.DataPipelineBuilder.rst", "reference/generated/data/fairseq2.data.DataPipelineError.rst", "reference/generated/data/fairseq2.data.FileMapper.rst", "reference/generated/data/fairseq2.data.RecordError.rst", "reference/generated/data/fairseq2.data.VocabularyInfo.rst", "reference/generated/data/fairseq2.data.get_last_failed_example.rst", "reference/generated/data/fairseq2.data.list_files.rst", "reference/generated/data/fairseq2.data.read_sequence.rst", "reference/generated/data/fairseq2.data.read_zipped_records.rst", "reference/generated/data/fairseq2.data.text.read_text.rst", "reference/generated/data_text/fairseq2.data.text.LineEnding.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceDecoder.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceEncoder.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceModel.rst", "reference/generated/data_text/fairseq2.data.text.StrSplitter.rst", "reference/generated/data_text/fairseq2.data.text.StrToIntConverter.rst", "reference/generated/data_text/fairseq2.data.text.StrToTensorConverter.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenDecoder.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenEncoder.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenizer.rst", "reference/generated/data_text/fairseq2.data.text.vocab_info_from_sentencepiece.rst", "reference/generated/enums/fairseq2.nn.transformer.TransformerNormOrder.rst", "reference/generated/functions/fairseq2.nn.utils.mask.to_float_mask.rst"], "titles": ["Bibliography", "fairseq2 documentation", "ABCs and Protocols", "All", "fairseq2.assets", "Classes", "fairseq2.data", "Enums", "Functions", "Gang", "CosineAnnealingLR", "MyleLR", "NoamLR", "PolynomialDecayLR", "AssetCard", "AssetMetadataProvider", "AssetStore", "fairseq2.data.ByteStreamError", "CollateOptionsOverride", "Collater", "DataPipeline", "DataPipelineBuilder", "fairseq2.data.DataPipelineError", "FileMapper", "fairseq2.data.RecordError", "VocabularyInfo", "get_last_failed_example", "list_files", "read_sequence", "read_zipped_records", "read_text", "LineEnding", "SentencePieceDecoder", "SentencePieceEncoder", "SentencePieceModel", "StrSplitter", "StrToIntConverter", "StrToTensorConverter", "TextTokenDecoder", "TextTokenEncoder", "TextTokenizer", "vocab_info_from_sentencepiece", "TransformerNormOrder", "to_float_mask"], "terms": {"lh17": [0, 10], "ilya": 0, "loshchilov": [0, 10], "frank": 0, "hutter": [0, 10], "sgdr": 0, "stochast": 0, "gradient": 0, "descent": 0, "warm": 0, "restart": [0, 10], "2017": 0, "arxiv": 0, "1608": 0, "03983": 0, "swo21": [0, 42], "sam": 0, "shleifer": [0, 42], "jason": 0, "weston": 0, "myle": [0, 11], "ott": [0, 11], "normform": 0, "improv": 0, "transform": [0, 42], "pretrain": 0, "extra": 0, "normal": [0, 42], "2021": 0, "url": 0, "http": 0, "org": 0, "ab": 0, "2110": 0, "09456": 0, "doi": 0, "10": [0, 6, 21, 36], "48550": 0, "vsp": [0, 12, 42], "17": [0, 12, 42], "ashish": 0, "vaswani": [0, 12, 42], "noam": [0, 11, 12], "shazeer": [0, 12], "niki": 0, "parmar": 0, "jakob": 0, "uszkoreit": 0, "llion": 0, "jone": 0, "aidan": 0, "n": 0, "gomez": 0, "lukasz": 0, "kaiser": 0, "illia": 0, "polosukhin": 0, "attent": 0, "i": [0, 1, 4, 6, 10, 11, 12, 13, 19, 20, 21, 23, 24, 25, 33, 39, 40], "all": [0, 1, 4, 9, 10, 11, 13, 16, 18, 19, 20, 21, 23, 27, 35], "you": [0, 6, 23], "need": [0, 19], "1706": 0, "03762": 0, "xyh": [0, 42], "20": [0, 42], "ruibin": 0, "xiong": [0, 42], "yunchang": 0, "yang": 0, "di": 0, "he": 0, "kai": 0, "zheng": 0, "shuxin": 0, "chen": 0, "xing": 0, "huishuai": 0, "zhang": 0, "yanyan": 0, "lan": 0, "liwei": 0, "wang": 0, "tie": 0, "yan": 0, "liu": 0, "On": 0, "layer": [0, 42], "architectur": 0, "2020": 0, "2002": 0, "04745": 0, "sequenc": [1, 9, 10, 11, 13, 19, 20, 21, 25, 28, 32, 35, 38], "model": [1, 12, 32, 33, 41], "toolkit": 1, "allow": [1, 4, 19, 20], "research": 1, "develop": 1, "train": [1, 10, 11, 12, 13], "custom": 1, "translat": [1, 40], "summar": 1, "languag": [1, 40], "other": [1, 6, 20], "content": [1, 23], "gener": [1, 20, 21, 40], "task": [1, 40], "data": [1, 4, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43], "asset": [1, 14, 15, 16], "bibliographi": 1, "provid": [4, 6, 9, 15, 21], "api": [4, 21], "load": [4, 10, 11, 12, 13, 21], "differ": [4, 19, 40], "us": [4, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 40, 43], "from": [4, 6, 9, 10, 11, 12, 13, 14, 19, 20, 21, 22, 32, 38], "A": [4, 19, 20, 23], "place": 4, "where": [4, 10, 20, 33, 39], "ar": [4, 9, 20, 40], "In": [4, 10, 12], "access": [4, 10, 11, 12, 13], "via": 4, "assetstor": 4, "multipl": [4, 6, 18, 19], "By": 4, "default": [4, 14, 35, 43], "look": [4, 6, 23], "up": [4, 19, 23], "follow": [4, 6, 19, 23, 27], "system": [4, 23], "share": [4, 20], "user": [4, 16, 21], "etc": 4, "thi": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23], "can": [4, 6, 17, 20, 21, 23], "chang": 4, "environ": [4, 16], "variabl": [4, 10, 11, 12, 13], "fairseq2_asset_dir": 4, "onli": [4, 6, 20, 21, 35], "avail": [4, 16], "config": 4, "fairseq2_user_asset_dir": 4, "To": 4, "regist": 4, "new": [4, 9, 21], "implement": [4, 10, 11, 40], "assetmetadataprovid": 4, "add": 4, "them": [4, 6, 9, 21], "asset_stor": 4, "here": 4, "an": [4, 10, 11, 12, 13, 14, 20, 22, 23, 25], "exampl": [4, 6, 19, 20, 21, 35], "directori": [4, 23], "pathlib": 4, "import": [4, 6], "path": [4, 23, 27, 29, 30, 34], "fileassetmetadataprovid": 4, "my_dir": 4, "model_stor": 4, "metadata_provid": 4, "append": 4, "yaml": 4, "file": [4, 6, 17, 23, 27, 29, 30, 35], "contain": [4, 10, 11, 12, 13, 14, 16, 20], "inform": [4, 14, 40, 41], "about": [4, 10, 14], "instruct": 4, "util": [4, 43], "generic_load": 4, "modelload": 4, "how": [4, 18], "memori": [4, 21, 23, 40], "each": [4, 9, 10, 11, 13, 14, 19, 20, 21, 29, 42], "must": [4, 9, 20], "have": [4, 6, 19, 20], "2": [4, 6, 10, 11, 12, 13, 19, 21, 35, 42], "mandatori": 4, "attribut": 4, "name": [4, 11, 14, 15, 16, 20, 23, 31, 35, 42], "checkpoint": 4, "identifi": 4, "uniqu": 4, "_across_": 4, "differen": 4, "llm": 4, "assetcard": [4, 16], "altern": 4, "one": [4, 20, 30, 35], "call": [4, 10, 11, 12, 13, 20, 21, 35, 36, 37], "get_metadata": [4, 15], "str": [4, 6, 14, 15, 16, 18, 20, 21, 27, 32, 33, 35, 38, 39, 40], "get": [4, 23, 33, 39], "meta": 4, "given": [4, 23, 31, 35, 36, 42], "python": [6, 20, 23], "build": 6, "c": 6, "datapipelin": [6, 21], "The": [6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 27, 28, 32, 33, 35, 38, 39, 40, 43], "dataload": [6, 20, 35], "abl": 6, "leverag": 6, "sever": [6, 20, 21, 23], "thread": 6, "work": [6, 9], "around": [6, 20], "global": [6, 16], "interpret": 6, "lock": 6, "limit": 6, "also": [6, 10, 20, 23], "better": 6, "perform": [6, 10, 11, 12, 13], "than": [6, 21], "pure": 6, "like": 6, "read_text": [6, 35], "tsv": [6, 35], "map": [6, 14, 20, 21, 23, 35], "lambda": [6, 21, 35], "x": [6, 21, 35], "split": [6, 35], "t": [6, 10, 11, 12, 13, 17, 35], "1": [6, 10, 11, 12, 13, 18, 19, 20, 21, 31, 33, 35, 42], "lower": 6, "filter": [6, 21], "len": 6, "function": [6, 20, 21, 35, 36, 37], "item": [6, 14], "go": [6, 35], "through": 6, "don": 6, "flat": 6, "tensor": [6, 9, 19, 32, 33, 37, 38, 39, 40, 43], "tupl": [6, 19], "dictionari": [6, 19, 20, 35], "oper": [6, 9, 20], "specifi": [6, 14, 15, 16, 18, 20, 21, 23, 42], "specif": [6, 14, 19, 40], "input": [6, 9, 19, 21, 35], "notabl": 6, "datapipelinebuild": [6, 20, 27, 28, 29, 30], "ha": [6, 10, 15, 21], "selector": [6, 18, 21], "argument": [6, 40], "choos": 6, "appli": [6, 18, 21, 42], "If": [6, 14, 16, 19, 20, 21, 27, 40, 43], "3": [6, 12, 19, 21], "select": [6, 21], "third": 6, "foo": 6, "valu": [6, 10, 14, 19, 20, 31, 42], "correspond": [6, 11, 12, 13, 35], "kei": [6, 14, 19, 20, 23, 30], "nest": 6, "separ": [6, 21], "For": [6, 19, 23], "y": 6, "4": [6, 10, 11, 12, 13, 19], "z": 6, "5": [6, 12, 19, 21], "bar": 6, "6": 6, "refer": [6, 10, 12, 40], "accept": 6, "comma": 6, "list": [6, 9, 10, 11, 12, 13, 15, 16, 19, 20, 21, 27, 33, 35, 39], "multipli": 6, "leav": 6, "unmodifi": 6, "count": [6, 20], "constant": [6, 20], "static": [6, 20], "method": 6, "creat": [6, 9, 18, 19, 20, 21, 35, 40], "when": [6, 17, 19, 20, 22, 24], "combin": [6, 20, 21], "e": [6, 10, 20], "g": [6, 20], "sampl": [6, 20, 21], "round_robin": [6, 20], "zip": [6, 20, 29], "thei": [6, 21], "yield": [6, 20, 21], "long": [6, 19, 20], "read_sequ": 6, "pipeline1": 6, "0": [6, 9, 10, 11, 13, 19, 20, 21, 33, 35, 42], "and_return": [6, 21, 35], "pipeline2": 6, "print": 6, "produc": [6, 21], "repeat": [6, 20, 21], "do": 6, "exhibit": 6, "behavior": 6, "indefinit": 6, "even": 6, "helper": 6, "tool": 6, "token": [6, 25, 32, 33, 38, 39, 40], "convert": [6, 35, 43], "byte": [6, 23], "class": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42], "fairseq2": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "sourc": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "base": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42], "abc": [9, 15, 16, 38, 39, 40], "repres": [9, 10, 11, 12, 13, 16, 25, 40], "set": 9, "process": [9, 21], "collect": 9, "abstract": [9, 15, 16, 38, 39, 40], "all_gath": 9, "output_tensor": 9, "input_tensor": 9, "gather": 9, "put": 9, "paramet": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 27, 28, 32, 33, 35, 38, 39, 40, 43], "output": [9, 21], "accomod": 9, "all_gather_to_list": 9, "all_reduc": 9, "op": 9, "reduc": 9, "across": 9, "reduceoper": 9, "element": [9, 25, 28], "wise": 9, "as_process_group": 9, "return": [9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43], "group": [9, 10, 11, 12, 13], "type": [9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43], "processgroup": 9, "barrier": 9, "synchron": 9, "broadcast": 9, "source_rank": 9, "sent": 9, "int": [9, 10, 11, 12, 13, 19, 20, 21, 23, 25, 35, 36], "rank": 9, "which": [9, 10, 11, 12, 13, 15, 16, 40], "broadcast_object": 9, "object": [9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 34, 35, 36, 37], "picklabl": 9, "ani": [9, 14, 15, 19, 20, 21, 23, 26, 28, 43], "equal": 9, "size": [9, 20, 21, 25, 37], "close": 9, "destroi": 9, "create_gang": 9, "part": [9, 20], "none": [9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 25, 27, 30, 31, 33, 34, 35, 37, 39, 40, 42, 43], "properti": [9, 14, 20, 33, 39, 40], "devic": [9, 33, 40], "associ": [9, 10, 11, 12, 13, 40], "number": [9, 10, 11, 12, 13, 20, 21, 33, 39], "final": [10, 11, 12, 13, 14, 19, 20, 21, 23, 25, 32, 33, 34, 35, 36, 37], "optim": [10, 11, 12, 13], "lr_schedul": [10, 11, 12, 13], "cycle_len": 10, "num_warmup_step": [10, 11, 12, 13], "cycle_mul": 10, "lr_mul": 10, "start_lr": [10, 11, 13], "final_lr": [10, 13], "last_epoch": [10, 11, 12, 13], "abstractlrschedul": [10, 11, 12, 13], "learn": [10, 11, 12, 13], "rate": [10, 11, 12, 13], "schedul": [10, 11, 12, 13], "describ": [10, 12, 19, 25, 42], "dure": [10, 13], "warmup": [10, 11, 12, 13], "eta_t": [10, 11, 12, 13], "eta_": [10, 11, 12, 13], "frac": [10, 11, 12, 13], "t_": [10, 11, 12, 13], "after": [10, 12, 13, 20, 42], "text": [10, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "co": 10, "pi": 10, "current": [10, 11, 12, 13, 20, 21], "anneal": 10, "cycl": 10, "t_i": 10, "step": [10, 11, 12, 13, 20], "taken": 10, "sinc": [10, 11, 12, 13], "last": [10, 11, 12, 13, 19, 21, 23], "total": [10, 13], "within": 10, "th": 10, "length": [10, 19], "cosin": 10, "effect": 10, "start": [10, 20, 31, 42], "larg": [10, 20], "rel": [10, 23], "rapidli": 10, "decreas": [10, 11, 12, 13], "minimum": [10, 21], "befor": 10, "being": [10, 21], "increas": [10, 11, 12, 13, 20], "again": 10, "pleas": [10, 11, 12, 13], "paper": [10, 12], "more": [10, 20, 21, 40], "detail": [10, 18, 20, 21], "addit": 10, "origin": [10, 11, 19], "support": 10, "phase": 10, "linearli": [10, 11, 12, 13], "first": [10, 11, 12, 13, 20, 35], "chainabl": [10, 11, 12, 13], "float": [10, 11, 12, 13, 20, 21, 43], "factor": 10, "grow": 10, "scale": [10, 11], "end": [10, 20, 25], "union": [10, 11, 13], "initi": [10, 11, 13], "respect": [10, 11, 13], "index": [10, 11, 12, 13, 21, 25], "epoch": [10, 11, 12, 13], "get_last_lr": [10, 11, 12, 13], "comput": [10, 11, 12, 13], "get_lr": [10, 11, 12, 13], "form": [10, 11, 12, 13], "load_state_dict": [10, 11, 12, 13, 20], "state_dict": [10, 11, 12, 13, 20], "": [10, 11, 12, 13, 20, 21, 33, 35, 36, 37, 39, 42], "state": [10, 11, 12, 13, 20], "arg": [10, 11, 12, 13], "dict": [10, 11, 12, 13, 15, 19, 20, 23, 35], "should": [10, 11, 12, 13, 14, 18], "print_lr": [10, 11, 12, 13], "is_verbos": [10, 11, 12, 13], "lr": [10, 11, 12, 13], "displai": [10, 11, 12, 13], "deprec": [10, 11, 12, 13], "version": [10, 11, 12, 13, 21], "It": [10, 11, 12, 13, 20], "entri": [10, 11, 12, 13, 35], "everi": [10, 11, 12, 13, 21, 28], "self": [10, 11, 12, 13, 21, 35, 36, 37], "__dict__": [10, 11, 12, 13], "noamlr": 11, "preserv": [11, 19], "min": [11, 12], "sqrt": [11, 12], "essenti": 11, "squar": [11, 12], "root": [11, 12, 23], "wa": [11, 19], "propos": 11, "fairseq": 11, "under": [11, 27], "inversesquarerootlr": 11, "thereaft": [11, 12, 13], "proportion": [11, 12], "invers": [11, 12], "section": 12, "et": [12, 42], "al": [12, 42], "author": 12, "dimension": 12, "commonli": 12, "second": [12, 35], "num_step": 13, "power": 13, "polynomi": 13, "decai": 13, "p": 13, "degre": 13, "includ": 13, "over": [13, 20], "expon": 13, "metadata": [14, 15], "value_convert": 14, "hold": 14, "mutablemap": 14, "held": 14, "card": [14, 16], "piec": 14, "option": [14, 19, 23, 35], "deriv": 14, "valueconvert": 14, "instanc": [14, 21], "field": 14, "doe": [14, 20], "its": [14, 20], "check": 14, "recurs": [14, 27], "assetcardfield": 14, "clear_cach": 15, "clear": 15, "cach": [15, 23], "get_nam": 15, "store": 16, "retrieve_card": 16, "env": 16, "scope": 16, "retriev": 16, "liter": 16, "para": 16, "order": [16, 31, 42], "preced": 16, "resolv": 16, "automat": [16, 21], "retrieve_nam": 16, "except": [17, 22, 24], "rais": [17, 20, 22, 24], "dataset": [17, 24], "read": [17, 20, 21, 22, 23, 24, 28, 29, 30, 35], "pad_valu": [18, 19, 21], "pad_to_multipl": [18, 19, 21], "overrid": [18, 19, 21], "collat": [18, 21], "batch": [18, 19, 21], "particular": [18, 21], "column": [18, 19, 21, 35], "same": [18, 19, 20, 21, 23], "pad": [18, 19, 25], "idx": 18, "see": [18, 20, 21], "syntax": [18, 21, 27], "concaten": [19, 20, 21], "singl": [19, 21], "dimens": 19, "otherwis": [19, 20], "requir": 19, "made": 19, "enough": 19, "fit": 19, "longest": 19, "round": [19, 20], "is_rag": 19, "true": [19, 20, 21, 40], "fals": [19, 20, 21, 30, 32, 33, 35, 40], "seq": [19, 28], "seq_len": 19, "shape": [19, 21, 33, 39, 43], "shortest": [19, 20], "alwai": 19, "collateoptionsoverrid": 19, "__call__": [19, 23, 32, 33, 35, 36, 37, 38, 39], "nativ": 20, "pipelin": [20, 21, 22, 30], "persist": 20, "disk": 20, "resum": 20, "later": 20, "iter": 20, "twice": 20, "two": 20, "so": [20, 23], "behav": 20, "inconcist": 20, "__iter__": [20, 31, 42], "modifi": 20, "intern": 20, "safe": 20, "concat": 20, "repeatedli": 20, "pseudo": 20, "infinit": [20, 21], "restor": 20, "previous": 20, "reset": [20, 21], "reset_rng": [20, 21], "move": 20, "back": 20, "bool": [20, 21, 40], "random": [20, 21], "stop_at_shortest": 20, "allow_repeat": 20, "extract": 20, "robin": 20, "stop": 20, "reach": [20, 21], "circl": 20, "finish": 20, "until": 20, "weight": 20, "seed": [20, 21], "least": 20, "onc": [20, 21], "data_pipelin": 20, "desir": 20, "distribut": 20, "uniform": 20, "strict": 20, "posit": 20, "pass": 20, "buffer": [20, 21], "save": 20, "ensur": 20, "preemption": 20, "lost": 20, "significantli": 20, "time": [20, 21], "zip_to_shortest": 20, "flatten": 20, "disable_parallel": 20, "togeth": 20, "assign": 20, "termin": 20, "non": [20, 27], "sequenti": 20, "is_broken": 20, "broken": 20, "futur": 20, "datapipelineerror": 20, "max_num_warn": 21, "bucket": 21, "bucket_s": 21, "drop_remaind": 21, "consecut": 21, "drop": 21, "case": 21, "fewer": 21, "bucket_by_length": 21, "min_data_len": 21, "skip_below_min_exampl": 21, "skip_above_max_exampl": 21, "similar": 21, "equival": 21, "dynamic_bucket": 21, "threshold": 21, "cost_fn": 21, "min_num_exampl": 21, "max_num_exampl": 21, "cumul": 21, "cost": 21, "measur": 21, "meet": 21, "exce": 21, "trigger": 21, "callabl": 21, "per": [21, 35], "maximum": 21, "yet": 21, "predic": 21, "keep": [21, 35], "those": 21, "who": 21, "match": [21, 27], "fn": 21, "num_parallel_cal": 21, "usag": [21, 35], "12": 21, "15": 21, "8": 21, "result": 21, "core": 21, "b": 21, "11": 21, "13": 21, "chain": 21, "f1": 21, "f2": 21, "effici": 21, "parallel": 21, "prefetch": 21, "num_exampl": 21, "background": 21, "while": [21, 22, 24, 40], "num_repeat": 21, "upon": 21, "shard": 21, "shard_idx": 21, "num_shard": 21, "allow_uneven": 21, "shuffl": 21, "shuffle_window": 21, "fix": 21, "intermedi": 21, "randomli": 21, "replac": 21, "full": 21, "skip": 21, "take": 21, "most": 21, "yield_from": 21, "error": 22, "occur": 22, "root_dir": 23, "cached_fd_count": 23, "slice": 23, "big_fil": 23, "txt": 23, "1024": 23, "48": 23, "offset": 23, "warn": 23, "enforc": 23, "happili": 23, "enabl": 23, "lru": 23, "especi": 23, "pathnam": 23, "pars": [23, 36], "memoryblock": 23, "block": 23, "regular": 23, "filemapperoutput": 23, "corrupt": 24, "record": 24, "encount": 24, "unk_idx": 25, "bos_idx": 25, "eos_idx": 25, "pad_idx": 25, "vocabulari": [25, 40, 41], "symbol": [25, 40], "begin": [25, 42], "bo": 25, "eo": 25, "unknown": 25, "unk": 25, "pattern": 27, "travers": 27, "empti": 27, "fnmatch": 27, "archiv": 29, "encod": [30, 33, 39, 40], "line_end": 30, "lineend": 30, "infer": 30, "ltrim": 30, "rtrim": 30, "skip_empti": 30, "memory_map": 30, "block_siz": 30, "open": 30, "line": 30, "modul": [31, 42], "qualnam": [31, 42], "boundari": [31, 42], "enum": [31, 42], "classmethod": [31, 42], "member": [31, 42], "definit": [31, 42], "revers": [32, 33], "texttokendecod": [32, 40], "token_indic": [32, 38], "indic": [32, 33, 35, 38, 39, 40], "decod": [32, 38, 40], "decode_from_token": [32, 38], "prefix_token": 33, "suffix_token": 33, "enable_sampl": 33, "nbest_siz": 33, "alpha": 33, "pin_memori": [33, 40], "texttokenencod": [33, 40], "encode_as_token": [33, 39], "prefix_indic": [33, 39], "prefix": [33, 39], "suffix_indic": [33, 39], "suffix": [33, 39], "control_symbol": 34, "sep": 35, "exclud": 35, "string": 35, "charact": 35, "tab": 35, "Will": 35, "va": 35, "cc": 35, "BY": 35, "franc": 35, "tatoeba": 35, "en": [35, 40], "fr": 35, "integ": 36, "dtype": [37, 43], "create_decod": 40, "create_encod": 40, "lang": 40, "mode": 40, "valid": 40, "concret": 40, "subclass": 40, "typic": 40, "distinguish": 40, "between": 40, "transcript": 40, "multilingu": 40, "u": 40, "de": 40, "target": 40, "construct": 40, "pin": 40, "create_raw_encod": 40, "raw": 40, "control": 40, "vocab_info": 40, "vocabularyinfo": [40, 41], "nn": [42, 43], "post": 42, "residu": 42, "connect": 42, "pre": 42, "pre_with_normform": 42, "mask": 43, "boolean": 43, "point": 43}, "objects": {"fairseq2.assets": [[14, 0, 1, "", "AssetCard"], [15, 0, 1, "", "AssetMetadataProvider"], [16, 0, 1, "", "AssetStore"]], "fairseq2.assets.AssetCard": [[14, 1, 1, "", "base"], [14, 2, 1, "", "field"], [14, 1, 1, "", "metadata"], [14, 1, 1, "", "name"]], "fairseq2.assets.AssetMetadataProvider": [[15, 2, 1, "", "clear_cache"], [15, 2, 1, "", "get_metadata"], [15, 2, 1, "", "get_names"]], "fairseq2.assets.AssetStore": [[16, 2, 1, "", "retrieve_card"], [16, 2, 1, "", "retrieve_names"]], "fairseq2.data": [[17, 3, 1, "", "ByteStreamError"], [18, 0, 1, "", "CollateOptionsOverride"], [19, 0, 1, "", "Collater"], [20, 0, 1, "", "DataPipeline"], [21, 0, 1, "", "DataPipelineBuilder"], [22, 3, 1, "", "DataPipelineError"], [23, 0, 1, "", "FileMapper"], [24, 3, 1, "", "RecordError"], [25, 0, 1, "", "VocabularyInfo"], [26, 5, 1, "", "get_last_failed_example"], [27, 5, 1, "", "list_files"], [28, 5, 1, "", "read_sequence"], [29, 5, 1, "", "read_zipped_records"]], "fairseq2.data.Collater": [[19, 2, 1, "", "__call__"]], "fairseq2.data.DataPipeline": [[20, 2, 1, "", "__iter__"], [20, 2, 1, "", "concat"], [20, 2, 1, "", "constant"], [20, 2, 1, "", "count"], [20, 1, 1, "", "is_broken"], [20, 2, 1, "", "load_state_dict"], [20, 2, 1, "", "reset"], [20, 2, 1, "", "round_robin"], [20, 2, 1, "", "sample"], [20, 2, 1, "", "state_dict"], [20, 2, 1, "", "zip"]], "fairseq2.data.DataPipelineBuilder": [[21, 2, 1, "", "and_return"], [21, 2, 1, "", "bucket"], [21, 2, 1, "", "bucket_by_length"], [21, 2, 1, "", "collate"], [21, 2, 1, "", "dynamic_bucket"], [21, 2, 1, "", "filter"], [21, 2, 1, "", "map"], [21, 2, 1, "", "prefetch"], [21, 2, 1, "", "repeat"], [21, 2, 1, "", "shard"], [21, 2, 1, "", "shuffle"], [21, 2, 1, "", "skip"], [21, 2, 1, "", "take"], [21, 2, 1, "", "yield_from"]], "fairseq2.data.FileMapper": [[23, 2, 1, "", "__call__"]], "fairseq2.data.VocabularyInfo": [[25, 4, 1, "", "bos_idx"], [25, 4, 1, "", "eos_idx"], [25, 4, 1, "", "pad_idx"], [25, 4, 1, "", "size"], [25, 4, 1, "", "unk_idx"]], "fairseq2.data.text": [[31, 0, 1, "", "LineEnding"], [32, 0, 1, "", "SentencePieceDecoder"], [33, 0, 1, "", "SentencePieceEncoder"], [34, 0, 1, "", "SentencePieceModel"], [35, 0, 1, "", "StrSplitter"], [36, 0, 1, "", "StrToIntConverter"], [37, 0, 1, "", "StrToTensorConverter"], [38, 0, 1, "", "TextTokenDecoder"], [39, 0, 1, "", "TextTokenEncoder"], [40, 0, 1, "", "TextTokenizer"], [30, 5, 1, "", "read_text"], [41, 5, 1, "", "vocab_info_from_sentencepiece"]], "fairseq2.data.text.LineEnding": [[31, 2, 1, "", "__iter__"]], "fairseq2.data.text.SentencePieceDecoder": [[32, 2, 1, "", "__call__"], [32, 2, 1, "", "decode_from_tokens"]], "fairseq2.data.text.SentencePieceEncoder": [[33, 2, 1, "", "__call__"], [33, 2, 1, "", "encode_as_tokens"], [33, 1, 1, "", "prefix_indices"], [33, 1, 1, "", "suffix_indices"]], "fairseq2.data.text.StrSplitter": [[35, 2, 1, "", "__call__"]], "fairseq2.data.text.StrToIntConverter": [[36, 2, 1, "", "__call__"]], "fairseq2.data.text.StrToTensorConverter": [[37, 2, 1, "", "__call__"]], "fairseq2.data.text.TextTokenDecoder": [[38, 2, 1, "", "__call__"], [38, 2, 1, "", "decode_from_tokens"]], "fairseq2.data.text.TextTokenEncoder": [[39, 2, 1, "", "__call__"], [39, 2, 1, "", "encode_as_tokens"], [39, 1, 1, "", "prefix_indices"], [39, 1, 1, "", "suffix_indices"]], "fairseq2.data.text.TextTokenizer": [[40, 2, 1, "", "create_decoder"], [40, 2, 1, "", "create_encoder"], [40, 2, 1, "", "create_raw_encoder"], [40, 1, 1, "", "vocab_info"]], "fairseq2.gang": [[9, 0, 1, "", "Gang"]], "fairseq2.gang.Gang": [[9, 2, 1, "", "all_gather"], [9, 2, 1, "", "all_gather_to_list"], [9, 2, 1, "", "all_reduce"], [9, 2, 1, "", "as_process_group"], [9, 2, 1, "", "barrier"], [9, 2, 1, "", "broadcast"], [9, 2, 1, "", "broadcast_objects"], [9, 2, 1, "", "close"], [9, 2, 1, "", "create_gang"], [9, 1, 1, "", "device"], [9, 1, 1, "", "rank"], [9, 1, 1, "", "size"]], "fairseq2.nn.transformer": [[42, 0, 1, "", "TransformerNormOrder"]], "fairseq2.nn.transformer.TransformerNormOrder": [[42, 4, 1, "", "POST"], [42, 4, 1, "", "PRE"], [42, 4, 1, "", "PRE_WITH_NORMFORMER"], [42, 2, 1, "", "__iter__"]], "fairseq2.nn.utils.mask": [[43, 5, 1, "", "to_float_mask"]], "fairseq2.optim.lr_scheduler": [[10, 0, 1, "", "CosineAnnealingLR"], [11, 0, 1, "", "MyleLR"], [12, 0, 1, "", "NoamLR"], [13, 0, 1, "", "PolynomialDecayLR"]], "fairseq2.optim.lr_scheduler.CosineAnnealingLR": [[10, 2, 1, "", "get_last_lr"], [10, 2, 1, "", "get_lr"], [10, 2, 1, "", "load_state_dict"], [10, 2, 1, "", "print_lr"], [10, 2, 1, "", "state_dict"], [10, 2, 1, "", "step"]], "fairseq2.optim.lr_scheduler.MyleLR": [[11, 2, 1, "", "get_last_lr"], [11, 2, 1, "", "get_lr"], [11, 2, 1, "", "load_state_dict"], [11, 2, 1, "", "print_lr"], [11, 2, 1, "", "state_dict"], [11, 2, 1, "", "step"]], "fairseq2.optim.lr_scheduler.NoamLR": [[12, 2, 1, "", "get_last_lr"], [12, 2, 1, "", "get_lr"], [12, 2, 1, "", "load_state_dict"], [12, 2, 1, "", "print_lr"], [12, 2, 1, "", "state_dict"], [12, 2, 1, "", "step"]], "fairseq2.optim.lr_scheduler.PolynomialDecayLR": [[13, 2, 1, "", "get_last_lr"], [13, 2, 1, "", "get_lr"], [13, 2, 1, "", "load_state_dict"], [13, 2, 1, "", "print_lr"], [13, 2, 1, "", "state_dict"], [13, 2, 1, "", "step"]]}, "objtypes": {"0": "py:class", "1": "py:property", "2": "py:method", "3": "py:exception", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "property", "Python property"], "2": ["py", "method", "Python method"], "3": ["py", "exception", "Python exception"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"bibliographi": 0, "fairseq2": [1, 4, 6, 17, 22, 24], "document": 1, "refer": 1, "misc": 1, "abc": [2, 3], "protocol": [2, 3], "all": 3, "class": [3, 5, 6], "enum": [3, 7], "function": [3, 8], "asset": 4, "model": 4, "store": 4, "card": 4, "data": [6, 17, 22, 24], "column": 6, "syntax": 6, "pseudo": 6, "infinit": 6, "pipelin": 6, "public": 6, "us": 6, "api": 6, "text": 6, "gang": 9, "cosineannealinglr": 10, "mylelr": 11, "noamlr": 12, "polynomialdecaylr": 13, "assetcard": 14, "assetmetadataprovid": 15, "assetstor": 16, "bytestreamerror": 17, "collateoptionsoverrid": 18, "collat": 19, "datapipelin": 20, "datapipelinebuild": 21, "datapipelineerror": 22, "filemapp": 23, "recorderror": 24, "vocabularyinfo": 25, "get_last_failed_exampl": 26, "list_fil": 27, "read_sequ": 28, "read_zipped_record": 29, "read_text": 30, "lineend": 31, "sentencepiecedecod": 32, "sentencepieceencod": 33, "sentencepiecemodel": 34, "strsplitter": 35, "strtointconvert": 36, "strtotensorconvert": 37, "texttokendecod": 38, "texttokenencod": 39, "texttoken": 40, "vocab_info_from_sentencepiec": 41, "transformernormord": 42, "to_float_mask": 43}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9, "sphinx": 57}, "alltitles": {"Bibliography": [[0, "bibliography"]], "fairseq2 documentation": [[1, "fairseq2-documentation"]], "fairseq2 Reference": [[1, null]], "Misc": [[1, null]], "ABCs and Protocols": [[2, "abcs-and-protocols"], [3, "abcs-and-protocols"]], "All": [[3, "all"]], "Classes": [[3, "classes"], [5, "classes"]], "Enums": [[3, "enums"], [7, "enums"]], "Functions": [[3, "functions"], [8, "functions"]], "fairseq2.assets": [[4, "fairseq2-assets"]], "Model store": [[4, "model-store"]], "Model card": [[4, "model-card"]], "fairseq2.data": [[6, "fairseq2-data"]], "Column syntax": [[6, "column-syntax"]], "Pseudo-infinite and Infinite Pipelines": [[6, "pseudo-infinite-and-infinite-pipelines"]], "Public classes used in fairseq2 API:": [[6, "public-classes-used-in-fairseq2-api"]], "fairseq2.data.text": [[6, "fairseq2-data-text"]], "Gang": [[9, "gang"]], "CosineAnnealingLR": [[10, "cosineannealinglr"]], "MyleLR": [[11, "mylelr"]], "NoamLR": [[12, "noamlr"]], "PolynomialDecayLR": [[13, "polynomialdecaylr"]], "AssetCard": [[14, "assetcard"]], "AssetMetadataProvider": [[15, "assetmetadataprovider"]], "AssetStore": [[16, "assetstore"]], "fairseq2.data.ByteStreamError": [[17, "fairseq2-data-bytestreamerror"]], "CollateOptionsOverride": [[18, "collateoptionsoverride"]], "Collater": [[19, "collater"]], "DataPipeline": [[20, "datapipeline"]], "DataPipelineBuilder": [[21, "datapipelinebuilder"]], "fairseq2.data.DataPipelineError": [[22, "fairseq2-data-datapipelineerror"]], "FileMapper": [[23, "filemapper"]], "fairseq2.data.RecordError": [[24, "fairseq2-data-recorderror"]], "VocabularyInfo": [[25, "vocabularyinfo"]], "get_last_failed_example": [[26, "get-last-failed-example"]], "list_files": [[27, "list-files"]], "read_sequence": [[28, "read-sequence"]], "read_zipped_records": [[29, "read-zipped-records"]], "read_text": [[30, "read-text"]], "LineEnding": [[31, "lineending"]], "SentencePieceDecoder": [[32, "sentencepiecedecoder"]], "SentencePieceEncoder": [[33, "sentencepieceencoder"]], "SentencePieceModel": [[34, "sentencepiecemodel"]], "StrSplitter": [[35, "strsplitter"]], "StrToIntConverter": [[36, "strtointconverter"]], "StrToTensorConverter": [[37, "strtotensorconverter"]], "TextTokenDecoder": [[38, "texttokendecoder"]], "TextTokenEncoder": [[39, "texttokenencoder"]], "TextTokenizer": [[40, "texttokenizer"]], "vocab_info_from_sentencepiece": [[41, "vocab-info-from-sentencepiece"]], "TransformerNormOrder": [[42, "transformernormorder"]], "to_float_mask": [[43, "to-float-mask"]]}, "indexentries": {"gang (class in fairseq2.gang)": [[9, "fairseq2.gang.Gang"]], "all_gather() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.all_gather"]], "all_gather_to_list() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.all_gather_to_list"]], "all_reduce() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.all_reduce"]], "as_process_group() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.as_process_group"]], "barrier() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.barrier"]], "broadcast() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.broadcast"]], "broadcast_objects() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.broadcast_objects"]], "close() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.close"]], "create_gang() (fairseq2.gang.gang method)": [[9, "fairseq2.gang.Gang.create_gang"]], "device (fairseq2.gang.gang property)": [[9, "fairseq2.gang.Gang.device"]], "rank (fairseq2.gang.gang property)": [[9, "fairseq2.gang.Gang.rank"]], "size (fairseq2.gang.gang property)": [[9, "fairseq2.gang.Gang.size"]], "cosineannealinglr (class in fairseq2.optim.lr_scheduler)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.get_last_lr"]], "get_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.get_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.state_dict"]], "step() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[10, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.step"]], "mylelr (class in fairseq2.optim.lr_scheduler)": [[11, "fairseq2.optim.lr_scheduler.MyleLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.get_last_lr"]], "get_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.get_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.state_dict"]], "step() (fairseq2.optim.lr_scheduler.mylelr method)": [[11, "fairseq2.optim.lr_scheduler.MyleLR.step"]], "noamlr (class in fairseq2.optim.lr_scheduler)": [[12, "fairseq2.optim.lr_scheduler.NoamLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.get_last_lr"]], "get_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.get_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.state_dict"]], "step() (fairseq2.optim.lr_scheduler.noamlr method)": [[12, "fairseq2.optim.lr_scheduler.NoamLR.step"]], "polynomialdecaylr (class in fairseq2.optim.lr_scheduler)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.get_last_lr"]], "get_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.get_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.state_dict"]], "step() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[13, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.step"]], "assetcard (class in fairseq2.assets)": [[14, "fairseq2.assets.AssetCard"]], "base (fairseq2.assets.assetcard property)": [[14, "fairseq2.assets.AssetCard.base"]], "field() (fairseq2.assets.assetcard method)": [[14, "fairseq2.assets.AssetCard.field"]], "metadata (fairseq2.assets.assetcard property)": [[14, "fairseq2.assets.AssetCard.metadata"]], "name (fairseq2.assets.assetcard property)": [[14, "fairseq2.assets.AssetCard.name"]], "assetmetadataprovider (class in fairseq2.assets)": [[15, "fairseq2.assets.AssetMetadataProvider"]], "clear_cache() (fairseq2.assets.assetmetadataprovider method)": [[15, "fairseq2.assets.AssetMetadataProvider.clear_cache"]], "get_metadata() (fairseq2.assets.assetmetadataprovider method)": [[15, "fairseq2.assets.AssetMetadataProvider.get_metadata"]], "get_names() (fairseq2.assets.assetmetadataprovider method)": [[15, "fairseq2.assets.AssetMetadataProvider.get_names"]], "assetstore (class in fairseq2.assets)": [[16, "fairseq2.assets.AssetStore"]], "retrieve_card() (fairseq2.assets.assetstore method)": [[16, "fairseq2.assets.AssetStore.retrieve_card"]], "retrieve_names() (fairseq2.assets.assetstore method)": [[16, "fairseq2.assets.AssetStore.retrieve_names"]], "bytestreamerror": [[17, "fairseq2.data.ByteStreamError"]], "collateoptionsoverride (class in fairseq2.data)": [[18, "fairseq2.data.CollateOptionsOverride"]], "collater (class in fairseq2.data)": [[19, "fairseq2.data.Collater"]], "__call__() (fairseq2.data.collater method)": [[19, "fairseq2.data.Collater.__call__"]], "datapipeline (class in fairseq2.data)": [[20, "fairseq2.data.DataPipeline"]], "__iter__() (fairseq2.data.datapipeline method)": [[20, "fairseq2.data.DataPipeline.__iter__"]], "concat() (fairseq2.data.datapipeline static method)": [[20, "fairseq2.data.DataPipeline.concat"]], "constant() (fairseq2.data.datapipeline static method)": [[20, "fairseq2.data.DataPipeline.constant"]], "count() (fairseq2.data.datapipeline static method)": [[20, "fairseq2.data.DataPipeline.count"]], "is_broken (fairseq2.data.datapipeline property)": [[20, "fairseq2.data.DataPipeline.is_broken"]], "load_state_dict() (fairseq2.data.datapipeline method)": [[20, "fairseq2.data.DataPipeline.load_state_dict"]], "reset() (fairseq2.data.datapipeline method)": [[20, "fairseq2.data.DataPipeline.reset"]], "round_robin() (fairseq2.data.datapipeline static method)": [[20, "fairseq2.data.DataPipeline.round_robin"]], "sample() (fairseq2.data.datapipeline static method)": [[20, "fairseq2.data.DataPipeline.sample"]], "state_dict() (fairseq2.data.datapipeline method)": [[20, "fairseq2.data.DataPipeline.state_dict"]], "zip() (fairseq2.data.datapipeline static method)": [[20, "fairseq2.data.DataPipeline.zip"]], "datapipelinebuilder (class in fairseq2.data)": [[21, "fairseq2.data.DataPipelineBuilder"]], "and_return() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.and_return"]], "bucket() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.bucket"]], "bucket_by_length() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.bucket_by_length"]], "collate() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.collate"]], "dynamic_bucket() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.dynamic_bucket"]], "filter() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.filter"]], "map() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.map"]], "prefetch() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.prefetch"]], "repeat() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.repeat"]], "shard() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.shard"]], "shuffle() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.shuffle"]], "skip() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.skip"]], "take() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.take"]], "yield_from() (fairseq2.data.datapipelinebuilder method)": [[21, "fairseq2.data.DataPipelineBuilder.yield_from"]], "datapipelineerror": [[22, "fairseq2.data.DataPipelineError"]], "filemapper (class in fairseq2.data)": [[23, "fairseq2.data.FileMapper"]], "__call__() (fairseq2.data.filemapper method)": [[23, "fairseq2.data.FileMapper.__call__"]], "recorderror": [[24, "fairseq2.data.RecordError"]], "vocabularyinfo (class in fairseq2.data)": [[25, "fairseq2.data.VocabularyInfo"]], "bos_idx (fairseq2.data.vocabularyinfo attribute)": [[25, "fairseq2.data.VocabularyInfo.bos_idx"]], "eos_idx (fairseq2.data.vocabularyinfo attribute)": [[25, "fairseq2.data.VocabularyInfo.eos_idx"]], "pad_idx (fairseq2.data.vocabularyinfo attribute)": [[25, "fairseq2.data.VocabularyInfo.pad_idx"]], "size (fairseq2.data.vocabularyinfo attribute)": [[25, "fairseq2.data.VocabularyInfo.size"]], "unk_idx (fairseq2.data.vocabularyinfo attribute)": [[25, "fairseq2.data.VocabularyInfo.unk_idx"]], "get_last_failed_example() (in module fairseq2.data)": [[26, "fairseq2.data.get_last_failed_example"]], "list_files() (in module fairseq2.data)": [[27, "fairseq2.data.list_files"]], "read_sequence() (in module fairseq2.data)": [[28, "fairseq2.data.read_sequence"]], "read_zipped_records() (in module fairseq2.data)": [[29, "fairseq2.data.read_zipped_records"]], "read_text() (in module fairseq2.data.text)": [[30, "fairseq2.data.text.read_text"]], "lineending (class in fairseq2.data.text)": [[31, "fairseq2.data.text.LineEnding"]], "__iter__() (fairseq2.data.text.lineending class method)": [[31, "fairseq2.data.text.LineEnding.__iter__"]], "sentencepiecedecoder (class in fairseq2.data.text)": [[32, "fairseq2.data.text.SentencePieceDecoder"]], "__call__() (fairseq2.data.text.sentencepiecedecoder method)": [[32, "fairseq2.data.text.SentencePieceDecoder.__call__"]], "decode_from_tokens() (fairseq2.data.text.sentencepiecedecoder method)": [[32, "fairseq2.data.text.SentencePieceDecoder.decode_from_tokens"]], "sentencepieceencoder (class in fairseq2.data.text)": [[33, "fairseq2.data.text.SentencePieceEncoder"]], "__call__() (fairseq2.data.text.sentencepieceencoder method)": [[33, "fairseq2.data.text.SentencePieceEncoder.__call__"]], "encode_as_tokens() (fairseq2.data.text.sentencepieceencoder method)": [[33, "fairseq2.data.text.SentencePieceEncoder.encode_as_tokens"]], "prefix_indices (fairseq2.data.text.sentencepieceencoder property)": [[33, "fairseq2.data.text.SentencePieceEncoder.prefix_indices"]], "suffix_indices (fairseq2.data.text.sentencepieceencoder property)": [[33, "fairseq2.data.text.SentencePieceEncoder.suffix_indices"]], "sentencepiecemodel (class in fairseq2.data.text)": [[34, "fairseq2.data.text.SentencePieceModel"]], "strsplitter (class in fairseq2.data.text)": [[35, "fairseq2.data.text.StrSplitter"]], "__call__() (fairseq2.data.text.strsplitter method)": [[35, "fairseq2.data.text.StrSplitter.__call__"]], "strtointconverter (class in fairseq2.data.text)": [[36, "fairseq2.data.text.StrToIntConverter"]], "__call__() (fairseq2.data.text.strtointconverter method)": [[36, "fairseq2.data.text.StrToIntConverter.__call__"]], "strtotensorconverter (class in fairseq2.data.text)": [[37, "fairseq2.data.text.StrToTensorConverter"]], "__call__() (fairseq2.data.text.strtotensorconverter method)": [[37, "fairseq2.data.text.StrToTensorConverter.__call__"]], "texttokendecoder (class in fairseq2.data.text)": [[38, "fairseq2.data.text.TextTokenDecoder"]], "__call__() (fairseq2.data.text.texttokendecoder method)": [[38, "fairseq2.data.text.TextTokenDecoder.__call__"]], "decode_from_tokens() (fairseq2.data.text.texttokendecoder method)": [[38, "fairseq2.data.text.TextTokenDecoder.decode_from_tokens"]], "texttokenencoder (class in fairseq2.data.text)": [[39, "fairseq2.data.text.TextTokenEncoder"]], "__call__() (fairseq2.data.text.texttokenencoder method)": [[39, "fairseq2.data.text.TextTokenEncoder.__call__"]], "encode_as_tokens() (fairseq2.data.text.texttokenencoder method)": [[39, "fairseq2.data.text.TextTokenEncoder.encode_as_tokens"]], "prefix_indices (fairseq2.data.text.texttokenencoder property)": [[39, "fairseq2.data.text.TextTokenEncoder.prefix_indices"]], "suffix_indices (fairseq2.data.text.texttokenencoder property)": [[39, "fairseq2.data.text.TextTokenEncoder.suffix_indices"]], "texttokenizer (class in fairseq2.data.text)": [[40, "fairseq2.data.text.TextTokenizer"]], "create_decoder() (fairseq2.data.text.texttokenizer method)": [[40, "fairseq2.data.text.TextTokenizer.create_decoder"]], "create_encoder() (fairseq2.data.text.texttokenizer method)": [[40, "fairseq2.data.text.TextTokenizer.create_encoder"]], "create_raw_encoder() (fairseq2.data.text.texttokenizer method)": [[40, "fairseq2.data.text.TextTokenizer.create_raw_encoder"]], "vocab_info (fairseq2.data.text.texttokenizer property)": [[40, "fairseq2.data.text.TextTokenizer.vocab_info"]], "vocab_info_from_sentencepiece() (in module fairseq2.data.text)": [[41, "fairseq2.data.text.vocab_info_from_sentencepiece"]], "post (fairseq2.nn.transformer.transformernormorder attribute)": [[42, "fairseq2.nn.transformer.TransformerNormOrder.POST"]], "pre (fairseq2.nn.transformer.transformernormorder attribute)": [[42, "fairseq2.nn.transformer.TransformerNormOrder.PRE"]], "pre_with_normformer (fairseq2.nn.transformer.transformernormorder attribute)": [[42, "fairseq2.nn.transformer.TransformerNormOrder.PRE_WITH_NORMFORMER"]], "transformernormorder (class in fairseq2.nn.transformer)": [[42, "fairseq2.nn.transformer.TransformerNormOrder"]], "__iter__() (fairseq2.nn.transformer.transformernormorder class method)": [[42, "fairseq2.nn.transformer.TransformerNormOrder.__iter__"]], "to_float_mask() (in module fairseq2.nn.utils.mask)": [[43, "fairseq2.nn.utils.mask.to_float_mask"]]}})