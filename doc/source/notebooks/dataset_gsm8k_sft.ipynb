{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœŽ Datasets\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to interact with pre-defined datasets in fairseq2.\n",
    "We use the `gsm8k_sft` (generic instruction finetuning) dataset as an example.\n",
    "\n",
    "> Make sure that you have followed the End to End Fine-Tuning and the basics assets tutorial.\n",
    "> For example, you should have the following lines (change the path to the actual path on your machine) in your asset yaml file:\n",
    "\n",
    "```yaml\n",
    "name: gsm8k_sft\n",
    "dataset_family: generic_instruction\n",
    "\n",
    "name: gsm8k_sft@user\n",
    "data: \"/data/gsm8k_data/sft\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq2 import setup_fairseq2\n",
    "from fairseq2.data.text import load_text_tokenizer\n",
    "from fairseq2.datasets import Batching, LengthBatching, StaticBatching\n",
    "from fairseq2.datasets.instruction import (\n",
    "    GenericInstructionDataset,\n",
    "    load_instruction_dataset,\n",
    ")\n",
    "from fairseq2.gang import FakeGang\n",
    "from fairseq2.recipes.lm.instruction_finetune import _llama3_1_instruct\n",
    "from fairseq2.recipes.utils.asset import retrieve_asset_card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "We first need to initialize fairseq2 -- `setup_fairseq2()`.\n",
    "This will load the configuration and register the assets, which allows us to interact with pre-defined datasets and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup fairseq2\n",
    "setup_fairseq2()\n",
    "\n",
    "# Load the configuration\n",
    "config = _llama3_1_instruct()\n",
    "\n",
    "# pin the dataset to what we added in `src/fairseq2_ext/cards/datasets/gsm8k.yaml`\n",
    "config.dataset = \"gsm8k_sft\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the assets\n",
    "\n",
    "We will load both the dataset and the model card. The `retrieve_asset_card` function is used to load the asset card from the asset store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_name: gsm8k_sft\n",
      "_metadata: {'dataset_family': 'generic_instruction', '__base_path__': PosixPath('/opt/hpcaas/.mounts/fs-0565f60d669b6a2d3/home/yaoj/projects/fair/fairseq2-ext/src/fairseq2_ext/cards/datasets'), '__source__': 'package:fairseq2_ext.cards', 'data': '/fsx-ram/shared/fair_conference_2024/gsm8k_data/sft', 'name': 'gsm8k_sft'}\n",
      "_base_card: None\n",
      "_base_path: /opt/hpcaas/.mounts/fs-0565f60d669b6a2d3/home/yaoj/projects/fair/fairseq2-ext/src/fairseq2_ext/cards/datasets\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "dataset_card = retrieve_asset_card(config.dataset)\n",
    "for k, v in dataset_card.__dict__.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_name: llama3_1_8b_instruct\n",
      "_metadata: {'base': 'llama3_instruct', 'model_arch': 'llama3_1_8b', '__base_path__': PosixPath('/opt/hpcaas/.mounts/fs-0565f60d669b6a2d3/home/yaoj/projects/fair/fairseq2-ext/src/fairseq2_ext/cards/models'), '__source__': 'package:fairseq2_ext.cards', 'checkpoint': '/fsx-ram/shared/Meta-Llama-3.1-8B-Instruct/original/consolidated.00.pth', 'name': 'llama3_1_8b_instruct'}\n",
      "_base_card: {'base': 'llama3', 'model_config': {'vocab_info': {'eos_idx': 128009}}, '__base_path__': PosixPath('/opt/hpcaas/.mounts/fs-0565f60d669b6a2d3/home/yaoj/projects/fair/fairseq2-ext/.venv/lib/python3.10/site-packages/fairseq2/assets/cards/models'), '__source__': 'package:fairseq2.assets.cards', 'name': 'llama3_instruct'}\n",
      "_base_path: /opt/hpcaas/.mounts/fs-0565f60d669b6a2d3/home/yaoj/projects/fair/fairseq2-ext/src/fairseq2_ext/cards/models\n"
     ]
    }
   ],
   "source": [
    "# prepare the model\n",
    "model_card = retrieve_asset_card(config.model)\n",
    "for k, v in model_card.__dict__.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the actual dataset and model from the asset cards, by calling `load_instruction_dataset` and `load_text_tokenizer` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fairseq2.datasets.instruction.GenericInstructionDataset object at 0x7f70a94619f0>\n",
      "{'_splits': {'default': ([PosixPath('/opt/hpcaas/.mounts/fs-0e3f1457c6d924fc0/shared/fair_conference_2024/gsm8k_data/sft/train.jsonl')], [1.0])}}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_instruction_dataset(dataset_card)\n",
    "print(dataset)\n",
    "print(dataset.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama3_1_8b_instruct tokenizer.\n",
      "Tokenizer loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer.\n",
    "print(f\"Loading {model_card.name} tokenizer.\")\n",
    "tokenizer = load_text_tokenizer(model_card)\n",
    "print(\"Tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Reader\n",
    "\n",
    "To create a data reader, we need to prepare the gang and the batching options as well.\n",
    "If you dig into the `create_reader` method, you will see that it implements the data pipeline that is covered in `notebooks/data/datapipeline.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the seed\n",
    "seed = 42\n",
    "\n",
    "# prepare the gang\n",
    "gang = FakeGang(rank=2, size=5)\n",
    "\n",
    "try:\n",
    "    batching: Batching\n",
    "\n",
    "    if config.batch_size is not None:\n",
    "        batching = StaticBatching(config.batch_size)\n",
    "    else:\n",
    "        batching = LengthBatching(config.max_num_tokens)\n",
    "\n",
    "    data_reader = dataset.create_reader(\n",
    "        config.train_split,\n",
    "        tokenizer,\n",
    "        gang,\n",
    "        config.max_seq_len,\n",
    "        batching=batching,\n",
    "        example_shuffle_window=config.example_shuffle_window,\n",
    "        batch_shuffle_window=config.batch_shuffle_window,\n",
    "        num_accumulate=config.gradient_accumulation,\n",
    "        num_prefetch=config.num_prefetch,\n",
    "        src_encode_mode=config.src_encode_mode,\n",
    "        tgt_encode_mode=config.tgt_encode_mode,\n",
    "        seed=seed,\n",
    "    )\n",
    "except ValueError as ex:\n",
    "    raise ValueError(\n",
    "        \"The data reader cannot be initialized. See nested exception for details.\"\n",
    "    ) from ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the batches\n",
    "\n",
    "Now that we have the data reader, we can iterate over the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===batch_nr===0===\n",
      "SequenceBatch(seqs=tensor([[128000, 128006,    882,  ...,    220,  10132, 128009],\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0],\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0],\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0],\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0]]), padding_mask=<fairseq2.nn.padding.PaddingMask object at 0x7f6f630faf20>, target_mask=tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), example={'id': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'indices': {'is_ragged': True, 'seqs': tensor([[128000, 128006,    882,  ...,    220,  10132, 128009],\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0],\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0],\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0],\n",
      "        [128000, 128006,    882,  ...,      0,      0,      0]]), 'seq_lens': tensor([338, 332, 329, 329, 330, 333, 334, 333, 331, 329, 328, 334, 324, 322,\n",
      "        327, 323, 324, 323, 322, 325, 322, 326, 326, 322, 327, 325, 325, 322,\n",
      "        319, 321, 318, 320, 321, 317, 321, 316, 316, 319, 318, 317, 320, 316,\n",
      "        319, 321, 320, 321, 316, 311])}, 'target_mask': {'is_ragged': True, 'seqs': tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), 'seq_lens': tensor([338, 332, 329, 329, 330, 333, 334, 333, 331, 329, 328, 334, 324, 322,\n",
      "        327, 323, 324, 323, 322, 325, 322, 326, 326, 322, 327, 325, 325, 322,\n",
      "        319, 321, 318, 320, 321, 317, 321, 316, 316, 319, 318, 317, 320, 316,\n",
      "        319, 321, 320, 321, 316, 311])}})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    batches = next(data_reader)\n",
    "except StopIteration:\n",
    "    batches = None\n",
    "\n",
    "if batches is not None:\n",
    "    for batch_nr, batch in enumerate(batches):\n",
    "        print(f\"===batch_nr==={batch_nr}===\")\n",
    "        print(batch)\n",
    "        print(\"\")\n",
    "else:\n",
    "    print(\"No more batches\")\n",
    "    data_reader.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
